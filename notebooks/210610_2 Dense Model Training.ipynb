{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lovely-landing",
   "metadata": {},
   "source": [
    "# Training an ML Model on Tensorflow Datasets\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worth-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Callable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from mmproteo.utils import log, paths, visualization\n",
    "from mmproteo.utils.formats.tf_dataset import DatasetLoader\n",
    "from mmproteo.utils.ml import callbacks, evaluation, layers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "circular-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "certified-gibson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Printing to Stdout\n"
     ]
    }
   ],
   "source": [
    "logger = log.DummyLogger(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-playlist",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "norwegian-therapist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/workspace/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aac43a97",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "os.chdir(os.path.join('workspace', 'notebooks'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "02d57e9a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "genuine-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"PXD010000\"\n",
    "DUMP_PATH = os.path.join(\"..\", \"dumps\", PROJECT)\n",
    "TRAINING_COLUMNS_DUMP_PATH = os.path.join(DUMP_PATH, \"training_columns\")\n",
    "FILES_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"*_mzmlid.parquet\")\n",
    "STATISTICS_FILE_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"statistics.parquet\")\n",
    "DATASET_DUMP_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"tf_datasets\")\n",
    "PROCESSING_FILE_PATH = os.path.join(DATASET_DUMP_PATH, \"processing_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "interesting-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ = 'peptide_sequence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93c29d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'padding_characters': {'peptide_sequence': '_',\n",
       "  'mz_array': 0.0,\n",
       "  'intensity_array': 0.0},\n",
       " 'padding_lengths': {'mz_array': 2354,\n",
       "  'intensity_array': 2354,\n",
       "  'peptide_sequence': 50},\n",
       " 'idx_to_char': {'0': 'A',\n",
       "  '1': 'C',\n",
       "  '2': 'D',\n",
       "  '3': 'E',\n",
       "  '4': 'F',\n",
       "  '5': 'G',\n",
       "  '6': 'H',\n",
       "  '7': 'I',\n",
       "  '8': 'K',\n",
       "  '9': 'L',\n",
       "  '10': 'M',\n",
       "  '11': 'M(Oxidation)',\n",
       "  '12': 'N',\n",
       "  '13': 'P',\n",
       "  '14': 'Q',\n",
       "  '15': 'R',\n",
       "  '16': 'S',\n",
       "  '17': 'T',\n",
       "  '18': 'V',\n",
       "  '19': 'W',\n",
       "  '20': 'Y',\n",
       "  '21': '_'},\n",
       " 'normalization': {'intensity_array': '<function base_peak_normalize at 0x7fa6046d5158>'},\n",
       " 'split_value_columns': ['species', 'istrain'],\n",
       " 'training_data_columns': ['mz_array', 'intensity_array'],\n",
       " 'target_data_columns': ['peptide_sequence']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(PROCESSING_FILE_PATH, 'r') as file:\n",
    "    PROCESSING_INFO = json.loads(file.read())\n",
    "PROCESSING_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a1f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_char = {int(idx): char for idx, char in PROCESSING_INFO[\"idx_to_char\"].items()}\n",
    "char_to_idx = {char: idx for idx, char in idx_to_char.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-proceeding",
   "metadata": {},
   "source": [
    "## Loading Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee8aadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_CACHE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ee8ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_TYPE = 'Train'\n",
    "TEST_TYPE = 'Test'\n",
    "EVAL_TYPE = 'Eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d696d51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: found file paths dump '../dumps/PXD010000/training_columns/tf_datasets/dataset_file_paths.json'\n",
      "\n",
      "assigned dataset files:\n",
      "#Train = 89\n",
      "e.g.: ../dumps/PXD010000/training_columns/tf_datasets/Biodiversity_C_indologenes_LIB_aerobic_02_03May16_Samwise_16-03-32_mzmlid.parquet/Chryseobacterium_indologenes/Train\n",
      "#Test = 17\n",
      "e.g.: ../dumps/PXD010000/training_columns/tf_datasets/Biodiversity_A_cryptum_FeTSB_anaerobic_1_01Jun16_Pippin_16-03-39_mzmlid.parquet/Acidiphilium_cryptum_JF-5/Train\n",
      "#Eval = 29\n",
      "e.g.: ../dumps/PXD010000/training_columns/tf_datasets/Biodiversity_B_fragilis_CMcarb_anaerobic_01_01Feb16_Arwen_15-07-13_mzmlid.parquet/Bacteroides_fragilis_638R/Train\n"
     ]
    }
   ],
   "source": [
    "dataset_file_paths = paths.assign_wildcard_paths_to_splits_grouped_by_path_position_value(\n",
    "    wildcard_path = os.path.join(\n",
    "        DATASET_DUMP_PATH, \n",
    "        '*',  # filename\n",
    "        '*',  # species\n",
    "        '*'   # istrain\n",
    "    ),\n",
    "    path_position = -2,\n",
    "    splits = {\n",
    "            TRAINING_TYPE: 0.4,\n",
    "            TEST_TYPE: 0.5,\n",
    "            EVAL_TYPE: 0.6\n",
    "        },\n",
    "    paths_dump_file = os.path.join(\n",
    "            DATASET_DUMP_PATH,\n",
    "            \"dataset_file_paths.json\"\n",
    "        ),\n",
    "    skip_existing = KEEP_CACHE,\n",
    "    logger = logger\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"assigned dataset files:\")\n",
    "visualization.print_list_length_in_dict(dataset_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec611252",
   "metadata": {},
   "source": [
    "### Loading corresponding TF datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0d829d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(2354,), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(2354,), dtype=tf.float32, name=None)),\n",
       " (TensorSpec(shape=(50,), dtype=tf.int8, name=None),))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_spec = (\n",
    "    tuple(tf.TensorSpec(shape=(PROCESSING_INFO['padding_lengths'][col], ), dtype=tf.float32)\n",
    "     for col in PROCESSING_INFO['training_data_columns']),\n",
    "    tuple(tf.TensorSpec(shape=(PROCESSING_INFO['padding_lengths'][col], ), dtype=tf.int8)\n",
    "     for col in PROCESSING_INFO['target_data_columns'])\n",
    ")\n",
    "element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b34d7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbef3700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:1640: UserWarning: The `deterministic` argument has no effect unless the `num_parallel_calls` argument is specified.\n",
      "  warnings.warn(\"The `deterministic` argument has no effect unless the \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Train': <BatchDataset shapes: (((32, 2354), (32, 2354)), ((32, 50),)), types: ((tf.float32, tf.float32), (tf.int8,))>,\n",
       " 'Test': <BatchDataset shapes: (((32, 2354), (32, 2354)), ((32, 50),)), types: ((tf.float32, tf.float32), (tf.int8,))>,\n",
       " 'Eval': <BatchDataset shapes: (((32, 2354), (32, 2354)), ((32, 50),)), types: ((tf.float32, tf.float32), (tf.int8,))>}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = DatasetLoader(\n",
    "    element_spec=element_spec,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle_buffer_size=100_000,\n",
    "    keep_cache=KEEP_CACHE,\n",
    "    logger=logger\n",
    ").load_datasets_by_type(dataset_file_paths)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-company",
   "metadata": {},
   "source": [
    "## Building the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce5d17de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor: shape=(None, 2354) dtype=float32 (created by layer 'mz_array')>, <KerasTensor: shape=(None, 2354) dtype=float32 (created by layer 'intensity_array')>]\n",
      "[<KerasTensor: shape=(None, 2354) dtype=float32 (created by layer 'masked_mz_array')>, <KerasTensor: shape=(None, 2354) dtype=float32 (created by layer 'masked_intensity_array')>]\n"
     ]
    }
   ],
   "source": [
    "input_layers_list, masked_input_layers_list = layers.create_masked_input_layers(\n",
    "    [\n",
    "        layers.InputLayerConfiguration(\n",
    "            name=col,\n",
    "            shape=PROCESSING_INFO['padding_lengths'][col],\n",
    "            mask_value=PROCESSING_INFO['padding_characters'][col]\n",
    "        )\n",
    "        for col in PROCESSING_INFO['training_data_columns']\n",
    "    ]\n",
    ")\n",
    "print(input_layers_list)\n",
    "print(masked_input_layers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03ed2a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_loss = losses.MaskedLoss(\n",
    "    loss_function=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    masking_value=tf.constant(\n",
    "        value=char_to_idx[PROCESSING_INFO['padding_characters'][SEQ]],\n",
    "        dtype=tf.int8\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b445c7a",
   "metadata": {},
   "source": [
    "masked_loss(y_eval[:2], y_pred[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "developmental-geneva",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mmproteo\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mz_array (InputLayer)           [(None, 2354)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "intensity_array (InputLayer)    [(None, 2354)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_mz_array (Masking)       (None, 2354)         0           mz_array[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "masked_intensity_array (Masking (None, 2354)         0           intensity_array[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 2354)         0           masked_mz_array[0][0]            \n",
      "                                                                 masked_intensity_array[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flattened_masked_inputs (Flatte (None, 2354)         0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         4823040     flattened_masked_inputs[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2048)         4196352     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2048)         4196352     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2048)         4196352     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 2048)         0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1100)         2253900     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (None, 50, 22)       0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.nn.softmax (TFOpLa (None, 50, 22)       0           tf.reshape[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 19,665,996\n",
      "Trainable params: 19,665,996\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = tf.stack(\n",
    "    values=masked_input_layers_list, \n",
    "    axis=-1,\n",
    ")\n",
    "\n",
    "x = tf.keras.layers.Flatten(name=\"flattened_masked_inputs\")(x)\n",
    "\n",
    "for _ in range(4):\n",
    "    x = tf.keras.layers.Dense(2**11)(x)\n",
    "    #x = tf.keras.layers.Dropout(0.1)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(PROCESSING_INFO['padding_lengths'][SEQ]*len(idx_to_char))(x)\n",
    "\n",
    "x = tf.reshape(x,(-1, PROCESSING_INFO['padding_lengths'][SEQ], len(idx_to_char)))\n",
    "\n",
    "x = tf.keras.activations.softmax(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_layers_list, outputs=x, name=f\"mmproteo_dense_{utils.get_current_time_str()}\")\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=masked_loss,\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "                  tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "              ]\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = os.path.join(DUMP_PATH, \"models\", model.name)\n",
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.ensure_dir_exists(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1535da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model=model,\n",
    "    to_file=os.path.join(MODEL_PATH, \"model.png\"),\n",
    "    show_shapes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6584fb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(MODEL_PATH, \"summary.txt\"), 'w') as file:\n",
    "    def write_lines(line: str) -> None:\n",
    "        file.write(line)\n",
    "        file.write(\"\\n\")\n",
    "    model.summary(print_fn=write_lines)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43df6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(MODEL_PATH, \"model.json\"), 'w') as file:\n",
    "    file.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b3a6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(MODEL_PATH, \"model.yaml\"), 'w') as file:\n",
    "    file.write(model.to_yaml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-queue",
   "metadata": {},
   "source": [
    "## Training the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "630d443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05152e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/workspace/dumps/PXD010000/tensorboard/logs'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSORBOARD_LOG_DIR = os.path.join(DUMP_PATH, \"tensorboard\", \"logs\")\n",
    "os.path.realpath(TENSORBOARD_LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe45638f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 109), started 1 day, 0:11:47 ago. (Use '!kill 109' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e7eaca4bcc702b54\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e7eaca4bcc702b54\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $TENSORBOARD_LOG_DIR --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "funded-commons",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 10s 8ms/step - loss: 15.3050 - sparse_categorical_accuracy: 0.0489 - sparse_categorical_crossentropy: 4899257.5000 - val_loss: 15.3927 - val_sparse_categorical_accuracy: 0.0342 - val_sparse_categorical_crossentropy: 11885863.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fccc1fce4e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=datasets[TRAINING_TYPE].repeat(),\n",
    "          validation_data=datasets[TEST_TYPE].repeat(), \n",
    "          validation_steps=500,\n",
    "          epochs=1,\n",
    "          steps_per_epoch=1_000,\n",
    "          callbacks=[\n",
    "              callbacks.create_tensorboard_callback(\n",
    "                  tensorboard_log_dir = TENSORBOARD_LOG_DIR,\n",
    "                  keep_logs = KEEP_CACHE\n",
    "              )\n",
    "          ]\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-laser",
   "metadata": {},
   "source": [
    "## Evaluating the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9aab9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_idx: Callable[[np.ndarray], np.ndarray] = np.vectorize(idx_to_char.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3013c477",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = evaluation.SequenceEvaluator(\n",
    "    dataset=datasets[EVAL_TYPE],\n",
    "    decode_func=decode_idx,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    separator=\" \",\n",
    "    padding_character=PROCESSING_INFO['padding_characters'][SEQ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a30b848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250/1250 [==============================] - 4s 2ms/step - loss: 15.4001 - sparse_categorical_accuracy: 0.0337 - sparse_categorical_crossentropy: 11811841.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15.40013313293457, 0.033735498785972595, 11811841.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "917eb62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>W I D F K A K P Y Q R M Q</td>\n",
       "      <td>V K A G E V I V K I P R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W I E F K A K P Y Q I M Q Q Q G W S Y T P A</td>\n",
       "      <td>Y G N T H V V A G Y I H G A E P K G E L K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>W I D F K A K P Y Q I</td>\n",
       "      <td>N G L G I V Y V Q R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>W I D F K A K P Y Q I M</td>\n",
       "      <td>I V H T V I E S D R R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>W I D F K A K P Y Q R M Q Q Q G W S Y T P T</td>\n",
       "      <td>S Y G N H I I E P A S G E L A S H L V G K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>W I E F K A K P</td>\n",
       "      <td>M(Oxidation) I Q V E S R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>W I E F K A K P Y Q I M Q</td>\n",
       "      <td>S I A G E V K P D F A K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>W S D F K Y K P R Q R Y Q Q Q G Y S Y T P T L</td>\n",
       "      <td>T L H P D N M(Oxidation) A A G P A S Y G M T D T M G R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>W I E F K A K P Y Q I M Q Q Q G W S Y T P A</td>\n",
       "      <td>T E T G A P V V T K Q P T A S K K D G V K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>W I A F K A K P Y</td>\n",
       "      <td>I G I F Y A A K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>W I E F K A K P Y Q I</td>\n",
       "      <td>E Q F E L S S F K R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>W I A F K A K P Y Q I M Q Q Q G</td>\n",
       "      <td>M S Y A T S D E N I V E A I R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>W I E F K A K P Y Q I M Q Q Q G W S Y T P T L W M F N S</td>\n",
       "      <td>Y N D V E L S D E E K P Q N A H N A V T N I G D D L K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>W I D F K A K P Y Q</td>\n",
       "      <td>L T S T Y F M E R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>W I D F K A K P Y Q I M Q Q Q G W S Y</td>\n",
       "      <td>A V E G A A T Q S V A D Q E A I Q K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>W I E F K A K P Y Q I M Q Q</td>\n",
       "      <td>L Y E K N N N P Q D L Q R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>W I A F K A K P Y Q I M Q Q Q G W</td>\n",
       "      <td>I I V E K P F G Y D L E S A E K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>W I E F K A K P Y Q I M Q Q</td>\n",
       "      <td>I V E L E L N A D E K A K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>W I E F K A K P Y Q I M Q Q Q G W S Y T</td>\n",
       "      <td>V D V N N V A S N F A H P T P N S E R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>W I E F K A K P Y Q I M Q Q Q G W S Y T P T L W</td>\n",
       "      <td>R I V N E P T A A A L A Y G L D K A H K D M K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  predicted  \\\n",
       "0                                 W I D F K A K P Y Q R M Q   \n",
       "1               W I E F K A K P Y Q I M Q Q Q G W S Y T P A   \n",
       "2                                     W I D F K A K P Y Q I   \n",
       "3                                   W I D F K A K P Y Q I M   \n",
       "4               W I D F K A K P Y Q R M Q Q Q G W S Y T P T   \n",
       "5                                           W I E F K A K P   \n",
       "6                                 W I E F K A K P Y Q I M Q   \n",
       "7             W S D F K Y K P R Q R Y Q Q Q G Y S Y T P T L   \n",
       "8               W I E F K A K P Y Q I M Q Q Q G W S Y T P A   \n",
       "9                                         W I A F K A K P Y   \n",
       "10                                    W I E F K A K P Y Q I   \n",
       "11                          W I A F K A K P Y Q I M Q Q Q G   \n",
       "12  W I E F K A K P Y Q I M Q Q Q G W S Y T P T L W M F N S   \n",
       "13                                      W I D F K A K P Y Q   \n",
       "14                    W I D F K A K P Y Q I M Q Q Q G W S Y   \n",
       "15                              W I E F K A K P Y Q I M Q Q   \n",
       "16                        W I A F K A K P Y Q I M Q Q Q G W   \n",
       "17                              W I E F K A K P Y Q I M Q Q   \n",
       "18                  W I E F K A K P Y Q I M Q Q Q G W S Y T   \n",
       "19          W I E F K A K P Y Q I M Q Q Q G W S Y T P T L W   \n",
       "\n",
       "                                                      true  \n",
       "0                                  V K A G E V I V K I P R  \n",
       "1                Y G N T H V V A G Y I H G A E P K G E L K  \n",
       "2                                      N G L G I V Y V Q R  \n",
       "3                                    I V H T V I E S D R R  \n",
       "4                S Y G N H I I E P A S G E L A S H L V G K  \n",
       "5                                 M(Oxidation) I Q V E S R  \n",
       "6                                  S I A G E V K P D F A K  \n",
       "7   T L H P D N M(Oxidation) A A G P A S Y G M T D T M G R  \n",
       "8                T E T G A P V V T K Q P T A S K K D G V K  \n",
       "9                                          I G I F Y A A K  \n",
       "10                                     E Q F E L S S F K R  \n",
       "11                           M S Y A T S D E N I V E A I R  \n",
       "12   Y N D V E L S D E E K P Q N A H N A V T N I G D D L K  \n",
       "13                                       L T S T Y F M E R  \n",
       "14                     A V E G A A T Q S V A D Q E A I Q K  \n",
       "15                               L Y E K N N N P Q D L Q R  \n",
       "16                         I I V E K P F G Y D L E S A E K  \n",
       "17                               I V E L E L N A D E K A K  \n",
       "18                   V D V N N V A S N F A H P T P N S E R  \n",
       "19           R I V N E P T A A A L A Y G L D K A H K D M K  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df, (x_eval, y_eval, y_pred) = evaluator.evaluate_model_visually(\n",
    "    model=model,\n",
    "    sample_size=20,\n",
    "    keep_separator=True,\n",
    ")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44bf7530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W I D F K A K P Y Q R M Q\n",
      "W I E F K A K P Y Q I M Q Q Q G W S Y T P A\n",
      "W I D F K A K P Y Q I\n",
      "W I D F K A K P Y Q I M\n",
      "W I D F K A K P Y Q R M Q Q Q G W S Y T P T\n",
      "W I E F K A K P\n",
      "W I E F K A K P Y Q I M Q\n",
      "W S D F K Y K P R Q R Y Q Q Q G Y S Y T P T L\n",
      "W I E F K A K P Y Q I M Q Q Q G W S Y T P A\n",
      "W I A F K A K P Y\n",
      "W I E F K A K P Y Q I\n",
      "W I A F K A K P Y Q I M Q Q Q G\n",
      "W I E F K A K P Y Q I M Q Q Q G W S Y T P T L W M F N S\n",
      "W I D F K A K P Y Q\n",
      "W I D F K A K P Y Q I M Q Q Q G W S Y\n",
      "W I E F K A K P Y Q I M Q Q\n",
      "W I A F K A K P Y Q I M Q Q Q G W\n",
      "W I E F K A K P Y Q I M Q Q\n",
      "W I E F K A K P Y Q I M Q Q Q G W S Y T\n",
      "W I E F K A K P Y Q I M Q Q Q G W S Y T P T L W\n"
     ]
    }
   ],
   "source": [
    "eval_df.predicted.map(print)\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

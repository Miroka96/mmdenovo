{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lovely-landing",
   "metadata": {},
   "source": [
    "# Training an ML Model on Tensorflow Datasets\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worth-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from mmproteo.utils import log, utils, visualization\n",
    "from mmproteo.utils.formats.mz import MzmlidFileStatsCreator\n",
    "from mmproteo.utils.formats.tf_dataset import Parquet2DatasetFileProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "circular-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "certified-gibson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Printing to Stdout\n"
     ]
    }
   ],
   "source": [
    "logger = log.DummyLogger(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-playlist",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "norwegian-therapist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/workspace/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "genuine-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"PXD010000\"\n",
    "DUMP_PATH = os.path.join(\"..\", \"dumps\", PROJECT)\n",
    "TRAINING_COLUMNS_DUMP_PATH = os.path.join(DUMP_PATH, \"training_columns\")\n",
    "FILES_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"*_mzmlid.parquet\")\n",
    "STATISTICS_FILE_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"statistics.parquet\")\n",
    "DATASET_DUMP_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"tf_datasets\")\n",
    "PROCESSING_FILE_PATH = os.path.join(DATASET_DUMP_PATH, \"processing_info.json\")\n",
    "\n",
    "SEQ = 'peptide_sequence'\n",
    "MZ = 'mz_array'\n",
    "INT = 'intensity_array'\n",
    "\n",
    "TRAINING_DATA_COLUMNS = [MZ, INT]\n",
    "TARGET_DATA_COLUMNS = [SEQ]\n",
    "SPLIT_VALUE_COLUMNS = ['species', 'istrain']\n",
    "\n",
    "PADDING_CHARACTERS = {\n",
    "    SEQ: '_',\n",
    "    MZ: 0.0,\n",
    "    INT: 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alpha-message",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../dumps/PXD010000/training_columns/Biodiversity_B_fragilis_01_28Jul15_Arwen_14-12-03_mzmlid.parquet'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MZMLID_FILE_PATHS = glob.glob(FILES_PATH)\n",
    "print(len(MZMLID_FILE_PATHS))\n",
    "MZMLID_FILE_PATHS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-headset",
   "metadata": {},
   "source": [
    "## Calculating Statistics over all MZMLID Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "vertical-tiger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: loaded previous statistics file '../dumps/PXD010000/training_columns/statistics.parquet'\n",
      "235\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>max_sequence_length</th>\n",
       "      <th>max_array_length</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>item_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../dumps/PXD010000/training_columns/Biodiversity_B_fragilis_01_28Jul15_Arwen_14-12-03_mzmlid.parquet</td>\n",
       "      <td>50</td>\n",
       "      <td>1845</td>\n",
       "      <td>{Q, W, A, F, C, V, K, I, E, P, G, D, M(Oxidation), Y, N, R, H, T, S, L, M}</td>\n",
       "      <td>26943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../dumps/PXD010000/training_columns/Biodiversity_Cibrobacter_freundii_LB_aerobic_01_01Feb16_Arwen_15-07-13_mzmlid.parquet</td>\n",
       "      <td>50</td>\n",
       "      <td>1697</td>\n",
       "      <td>{Q, W, A, F, C, V, K, I, E, P, G, D, M(Oxidation), Y, N, R, H, T, S, L, M}</td>\n",
       "      <td>27516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                   file_path  \\\n",
       "0                       ../dumps/PXD010000/training_columns/Biodiversity_B_fragilis_01_28Jul15_Arwen_14-12-03_mzmlid.parquet   \n",
       "1  ../dumps/PXD010000/training_columns/Biodiversity_Cibrobacter_freundii_LB_aerobic_01_01Feb16_Arwen_15-07-13_mzmlid.parquet   \n",
       "\n",
       "   max_sequence_length  max_array_length  \\\n",
       "0                   50              1845   \n",
       "1                   50              1697   \n",
       "\n",
       "                                                                     alphabet  \\\n",
       "0  {Q, W, A, F, C, V, K, I, E, P, G, D, M(Oxidation), Y, N, R, H, T, S, L, M}   \n",
       "1  {Q, W, A, F, C, V, K, I, E, P, G, D, M(Oxidation), Y, N, R, H, T, S, L, M}   \n",
       "\n",
       "   item_count  \n",
       "0       26943  \n",
       "1       27516  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_stats = MzmlidFileStatsCreator(\n",
    "    mzmlid_file_paths=MZMLID_FILE_PATHS,\n",
    "    statistics_file_path=STATISTICS_FILE_PATH,\n",
    "    seq_col_name=SEQ,\n",
    "    int_col_name=INT,\n",
    "    logger=logger\n",
    ").process(thread_count=0)\n",
    "print(len(file_stats))\n",
    "file_stats.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "following-enclosure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding lengths = {'mz_array': 2354, 'intensity_array': 2354, 'peptide_sequence': 50}\n",
      "TOTAL_ITEM_COUNT = 5513185\n",
      "ALPHABET = A, C, D, E, F, G, H, I, K, L, M, M(Oxidation), N, P, Q, R, S, T, V, W, Y\n"
     ]
    }
   ],
   "source": [
    "PADDING_LENGTHS = {\n",
    "    MZ: file_stats.max_array_length.max(),\n",
    "    INT: file_stats.max_array_length.max(),\n",
    "    SEQ: file_stats.max_sequence_length.max()\n",
    "}\n",
    "\n",
    "print(\"padding lengths =\", PADDING_LENGTHS)\n",
    "\n",
    "TOTAL_ITEM_COUNT = file_stats.item_count.sum()\n",
    "print(f\"TOTAL_ITEM_COUNT = {TOTAL_ITEM_COUNT}\")\n",
    "\n",
    "ALPHABET = set.union(*file_stats.alphabet)\n",
    "print(f\"ALPHABET = {', '.join(sorted(ALPHABET))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-recipient",
   "metadata": {},
   "source": [
    "## Data Normalization, Padding, and Conversion to Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "headed-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(values: np.ndarray) -> np.ndarray:\n",
    "    return tf.keras.utils.normalize(x=values, order=2)\n",
    "\n",
    "def base_peak_normalize(values: np.ndarray) -> np.ndarray:\n",
    "    return values / values.max(initial=0)\n",
    "\n",
    "# by Tom, probably\n",
    "# don't know, what it's based on\n",
    "def ion_current_normalize(intensities: np.ndarray) -> np.ndarray:\n",
    "    total_sum = np.sum(intensities**2)\n",
    "    normalized = intensities/total_sum\n",
    "    return normalized\n",
    "\n",
    "NORMALIZATION = {\n",
    "    INT: base_peak_normalize\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "waiting-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET.add(PADDING_CHARACTERS[SEQ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "understood-necklace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'C': 1,\n",
       " 'D': 2,\n",
       " 'E': 3,\n",
       " 'F': 4,\n",
       " 'G': 5,\n",
       " 'H': 6,\n",
       " 'I': 7,\n",
       " 'K': 8,\n",
       " 'L': 9,\n",
       " 'M': 10,\n",
       " 'M(Oxidation)': 11,\n",
       " 'N': 12,\n",
       " 'P': 13,\n",
       " 'Q': 14,\n",
       " 'R': 15,\n",
       " 'S': 16,\n",
       " 'T': 17,\n",
       " 'V': 18,\n",
       " 'W': 19,\n",
       " 'Y': 20,\n",
       " '_': 21}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx = {char: idx for idx, char in enumerate(sorted(ALPHABET))}\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "INDEX_ALPHABET = idx_to_char.keys()\n",
    "char_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "equivalent-portrait",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Processing item 1/235: '../dumps/PXD010000/training_columns/Biodiversity_B_fragilis_01_28Jul15_Arwen_14-12-03_mzmlid.parquet'\n",
      "INFO: Processing item 11/235: '../dumps/PXD010000/training_columns/Biodiversity_P_polymyxa_TBS_aerobic_3_17July16_Samwise_16-04-10_mzmlid.parquet'\n",
      "INFO: Processing item 21/235: '../dumps/PXD010000/training_columns/M_alcali_copp_CH4_B2_T1_09_QE_23Mar18_Oak_18-01-07_mzmlid.parquet'\n",
      "INFO: Processing item 31/235: '../dumps/PXD010000/training_columns/Cj_media_MH_R4_23Feb15_Arwen_14-12-03_mzmlid.parquet'\n",
      "INFO: Processing item 41/235: '../dumps/PXD010000/training_columns/Biodiversity_C_Baltica_T240_R2_C_27Jan16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 51/235: '../dumps/PXD010000/training_columns/Biodiversity_M_xanthus_DZ2_plates_1_03May16_Samwise_16-03-32_mzmlid.parquet'\n",
      "INFO: Processing item 61/235: '../dumps/PXD010000/training_columns/Biodiversity_B_thet_CMgluc_anaerobic_02_01Feb16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 71/235: '../dumps/PXD010000/training_columns/Biodiversity_R_palustris_PMnitro_anaerobic_2_01Jun16_Pippin_16-03-39_mzmlid.parquet'\n",
      "INFO: Processing item 81/235: '../dumps/PXD010000/training_columns/Biodiversity_S_elongatus_BG11_aerobic_1_14July16_Pippin_16-05-01_mzmlid.parquet'\n",
      "INFO: Processing item 91/235: '../dumps/PXD010000/training_columns/Biodiversity_F_novicida_TSB_aerobic_03_01Feb16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 101/235: '../dumps/PXD010000/training_columns/M_alcali_copp_CH4_B3_T1_11_QE_23Mar18_Oak_18-01-07_mzmlid.parquet'\n",
      "INFO: Processing item 111/235: '../dumps/PXD010000/training_columns/Biodiversity_M_xanthus_DZ2_48h_plates_2_13Jun16_Pippin_16-03-39_mzmlid.parquet'\n",
      "INFO: Processing item 121/235: '../dumps/PXD010000/training_columns/Biodiversity_F_prausnitzii_Glc_01_28Oct15_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 131/235: '../dumps/PXD010000/training_columns/Biodiversity_P_ruminicola_MDM_anaerobic_2_09Jun16_Pippin_16-03-39_mzmlid.parquet'\n",
      "INFO: Processing item 141/235: '../dumps/PXD010000/training_columns/M_alcali_copp_MeOH_B2_T1_03_QE_23Mar18_Oak_18-01-07_mzmlid.parquet'\n",
      "INFO: Processing item 151/235: '../dumps/PXD010000/training_columns/Biodiversity_A_cryptum_FeTSB_anaerobic_2_01Jun16_Pippin_16-03-39_mzmlid.parquet'\n",
      "INFO: Processing item 161/235: '../dumps/PXD010000/training_columns/Biodiversity_B_thet_LIB_anaerobic_03_01Feb16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 171/235: '../dumps/PXD010000/training_columns/Biodiversity_C_Baltica_T240_R2_Inf_27Jan16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 181/235: '../dumps/PXD010000/training_columns/Biodiversity_B_thet_CMcarb_anaerobic_02_01Feb16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 191/235: '../dumps/PXD010000/training_columns/Biodiversity_S_elongatus_BG11NaCl_aerobic_1_05Oct16_Pippin_16-05-06_mzmlid.parquet'\n",
      "INFO: Processing item 201/235: '../dumps/PXD010000/training_columns/Biodiversity_B_thet_CMcarb_anaerobic_03_01Feb16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 211/235: '../dumps/PXD010000/training_columns/Biodiversity_B_subtilis_pellet_set2_2_13Jun16_Pippin_16-03-39_mzmlid.parquet'\n",
      "INFO: Processing item 221/235: '../dumps/PXD010000/training_columns/Biodiversity_HL49_HLHYE_aerobic_3_05Oct16_Pippin_16-05-06_mzmlid.parquet'\n",
      "INFO: Processing item 231/235: '../dumps/PXD010000/training_columns/Biodiversity_B_subtilis_NCIB3610_48h_plates_3_13Jun16_Pippin_16-03-39_mzmlid.parquet'\n",
      "INFO: No mzmlid parquet files were parquet2tf_dataset-processed\n",
      "INFO: Encountered 0 exceptions during processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parquet2DatasetFileProcessor(\n",
    "    training_data_columns=TRAINING_DATA_COLUMNS,\n",
    "    target_data_columns=TARGET_DATA_COLUMNS,\n",
    "    padding_lengths=PADDING_LENGTHS,\n",
    "    padding_characters=PADDING_CHARACTERS,\n",
    "    column_normalizations=NORMALIZATION,\n",
    "    dataset_dump_path_prefix=DATASET_DUMP_PATH,\n",
    "    char_to_idx_mapping_functions={\n",
    "        SEQ: char_to_idx.get\n",
    "    },\n",
    "    item_count=len(MZMLID_FILE_PATHS),\n",
    "    skip_existing=True,\n",
    "    split_on_column_values_of=SPLIT_VALUE_COLUMNS,\n",
    "    logger=logger\n",
    ").process(parquet_file_paths=MZMLID_FILE_PATHS,\n",
    "          thread_count=3)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9517d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_configuration = {\n",
    "    'padding_characters': PADDING_CHARACTERS,\n",
    "    'padding_lengths': PADDING_LENGTHS,\n",
    "    'idx_to_char': idx_to_char,\n",
    "    'normalization': NORMALIZATION,\n",
    "    'split_value_columns': SPLIT_VALUE_COLUMNS,\n",
    "    'training_data_columns': TRAINING_DATA_COLUMNS,\n",
    "    'target_data_columns': TARGET_DATA_COLUMNS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "225f5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_configuration = utils.denumpyfy(processing_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31f0a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"padding_characters\": {\n",
      "        \"peptide_sequence\": \"_\",\n",
      "        \"mz_array\": 0.0,\n",
      "        \"intensity_array\": 0.0\n",
      "    },\n",
      "    \"padding_lengths\": {\n",
      "        \"mz_array\": 2354,\n",
      "        \"intensity_array\": 2354,\n",
      "        \"peptide_sequence\": 50\n",
      "    },\n",
      "    \"idx_to_char\": {\n",
      "        \"0\": \"A\",\n",
      "        \"1\": \"C\",\n",
      "        \"2\": \"D\",\n",
      "        \"3\": \"E\",\n",
      "        \"4\": \"F\",\n",
      "        \"5\": \"G\",\n",
      "        \"6\": \"H\",\n",
      "        \"7\": \"I\",\n",
      "        \"8\": \"K\",\n",
      "        \"9\": \"L\",\n",
      "        \"10\": \"M\",\n",
      "        \"11\": \"M(Oxidation)\",\n",
      "        \"12\": \"N\",\n",
      "        \"13\": \"P\",\n",
      "        \"14\": \"Q\",\n",
      "        \"15\": \"R\",\n",
      "        \"16\": \"S\",\n",
      "        \"17\": \"T\",\n",
      "        \"18\": \"V\",\n",
      "        \"19\": \"W\",\n",
      "        \"20\": \"Y\",\n",
      "        \"21\": \"_\"\n",
      "    },\n",
      "    \"normalization\": {\n",
      "        \"intensity_array\": \"<function base_peak_normalize at 0x7fa6046d5158>\"\n",
      "    },\n",
      "    \"split_value_columns\": [\n",
      "        \"species\",\n",
      "        \"istrain\"\n",
      "    ],\n",
      "    \"training_data_columns\": [\n",
      "        \"mz_array\",\n",
      "        \"intensity_array\"\n",
      "    ],\n",
      "    \"target_data_columns\": [\n",
      "        \"peptide_sequence\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(visualization.pretty_print_json(processing_configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c999d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote processing info to '../dumps/PXD010000/training_columns/tf_datasets/processing_info.json'\n"
     ]
    }
   ],
   "source": [
    "with open(PROCESSING_FILE_PATH, 'w') as file:\n",
    "    file.write(visualization.pretty_print_json(processing_configuration))\n",
    "    print(f\"wrote processing info to '{PROCESSING_FILE_PATH}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

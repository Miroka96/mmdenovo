{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lovely-landing",
   "metadata": {},
   "source": [
    "# Training an ML Model on Tensorflow Datasets\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worth-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from mmproteo.utils import log, utils, visualization\n",
    "from mmproteo.utils.formats.mz import MzmlidFileStatsCreator\n",
    "from mmproteo.utils.formats.tf_dataset import Parquet2DatasetFileProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "circular-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28437478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-playlist",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "norwegian-therapist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/hpi/fs00/home/mirko.krause/masterthesis/pride-downloader/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01ae40b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"PXD010000\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "e52ac2d1",
   "metadata": {},
   "source": [
    "DUMP_PATH = os.path.join(\"..\", \"dumps\", PROJECT)\n",
    "TRAINING_COLUMNS_DUMP_PATH = os.path.join(DUMP_PATH, \"training_columns\")\n",
    "FILES_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"*_mzmlid.parquet\"\n",
    "THREAD_COUNT=8\n",
    "SPLIT_VALUE_COLUMNS = ['species', 'istrain']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dd95656c",
   "metadata": {},
   "source": [
    "DUMP_PATH = \"/scratch/mirko.krause/dumps/\" + PROJECT\n",
    "TRAINING_COLUMNS_DUMP_PATH = os.path.join(DUMP_PATH, \"training_columns\")\n",
    "FILES_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"*_mzmlid.parquet\")\n",
    "THREAD_COUNT=32\n",
    "SPLIT_VALUE_COLUMNS = ['species', 'istrain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcf97326",
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMP_PATH = \"/scratch/mirko.krause/pdeep\"\n",
    "TRAINING_COLUMNS_DUMP_PATH = os.path.join(DUMP_PATH, \"training_columns\")\n",
    "FILES_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"file_*.parquet\")\n",
    "THREAD_COUNT=32\n",
    "SPLIT_VALUE_COLUMNS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "genuine-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATISTICS_FILE_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"statistics.parquet\")\n",
    "DATASET_DUMP_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"tf_datasets\")\n",
    "PROCESSING_FILE_PATH = os.path.join(DATASET_DUMP_PATH, \"processing_info.json\")\n",
    "\n",
    "SEQ = 'peptide_sequence'\n",
    "MZ = 'mz_array'\n",
    "INT = 'intensity_array'\n",
    "\n",
    "TRAINING_DATA_COLUMNS = [MZ, INT]\n",
    "TARGET_DATA_COLUMNS = [SEQ]\n",
    "\n",
    "PADDING_CHARACTERS = {\n",
    "    SEQ: '_',\n",
    "    MZ: 0.0,\n",
    "    INT: 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2dc5116",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.ensure_dir_exists(DATASET_DUMP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04949367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 16:53:32,761 - mmproteo_dataset_generation: Logging to file '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/mmproteo_dataset_generation.log' and to stderr\n"
     ]
    }
   ],
   "source": [
    "logger = log.create_logger(\n",
    "    name='mmproteo_dataset_generation',\n",
    "    verbose=True,\n",
    "    log_dir=DATASET_DUMP_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "alpha-message",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/scratch/mirko.krause/pdeep/training_columns/file_10.parquet'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MZMLID_FILE_PATHS = glob.glob(FILES_PATH)\n",
    "print(len(MZMLID_FILE_PATHS))\n",
    "MZMLID_FILE_PATHS[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-headset",
   "metadata": {},
   "source": [
    "## Calculating Statistics over all MZMLID Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "vertical-tiger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 16:53:32,806 - mmproteo_dataset_generation: loaded previous statistics file '/scratch/mirko.krause/pdeep/training_columns/statistics.parquet'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>max_sequence_length</th>\n",
       "      <th>max_array_length</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>item_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/scratch/mirko.krause/pdeep/training_columns/file_10.parquet</td>\n",
       "      <td>30</td>\n",
       "      <td>88</td>\n",
       "      <td>{Q, L, G, R, W, N, I, S, V, P, Y, H, A, T, E, F, M, C, K, D}</td>\n",
       "      <td>999596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/scratch/mirko.krause/pdeep/training_columns/file_11.parquet</td>\n",
       "      <td>30</td>\n",
       "      <td>89</td>\n",
       "      <td>{Q, L, G, R, W, N, I, S, V, P, Y, H, A, T, E, F, M, C, K, D}</td>\n",
       "      <td>999486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      file_path  \\\n",
       "0  /scratch/mirko.krause/pdeep/training_columns/file_10.parquet   \n",
       "1  /scratch/mirko.krause/pdeep/training_columns/file_11.parquet   \n",
       "\n",
       "   max_sequence_length  max_array_length  \\\n",
       "0                   30                88   \n",
       "1                   30                89   \n",
       "\n",
       "                                                       alphabet  item_count  \n",
       "0  {Q, L, G, R, W, N, I, S, V, P, Y, H, A, T, E, F, M, C, K, D}      999596  \n",
       "1  {Q, L, G, R, W, N, I, S, V, P, Y, H, A, T, E, F, M, C, K, D}      999486  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_stats = MzmlidFileStatsCreator(\n",
    "    mzmlid_file_paths=MZMLID_FILE_PATHS,\n",
    "    statistics_file_path=STATISTICS_FILE_PATH,\n",
    "    seq_col_name=SEQ,\n",
    "    int_col_name=INT,\n",
    "    logger=logger\n",
    ").process(thread_count=THREAD_COUNT)\n",
    "print(len(file_stats))\n",
    "file_stats.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "following-enclosure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding lengths = {'mz_array': 89, 'intensity_array': 89, 'peptide_sequence': 30}\n",
      "TOTAL_ITEM_COUNT = 25142457\n",
      "ALPHABET = A, C, D, E, F, G, H, I, K, L, M, N, P, Q, R, S, T, V, W, Y\n"
     ]
    }
   ],
   "source": [
    "PADDING_LENGTHS = {\n",
    "    MZ: file_stats.max_array_length.max(),\n",
    "    INT: file_stats.max_array_length.max(),\n",
    "    SEQ: file_stats.max_sequence_length.max()\n",
    "}\n",
    "\n",
    "print(\"padding lengths =\", PADDING_LENGTHS)\n",
    "\n",
    "TOTAL_ITEM_COUNT = file_stats.item_count.sum()\n",
    "print(f\"TOTAL_ITEM_COUNT = {TOTAL_ITEM_COUNT}\")\n",
    "\n",
    "ALPHABET = set.union(*file_stats.alphabet)\n",
    "print(f\"ALPHABET = {', '.join(sorted(ALPHABET))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-recipient",
   "metadata": {},
   "source": [
    "## Data Normalization, Padding, and Conversion to Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "headed-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(values: np.ndarray) -> np.ndarray:\n",
    "    return tf.keras.utils.normalize(x=values, order=2)\n",
    "\n",
    "def base_peak_normalize(values: np.ndarray) -> np.ndarray:\n",
    "    return values / values.max(initial=0)\n",
    "\n",
    "# by Tom, probably\n",
    "# don't know, what it's based on\n",
    "def ion_current_normalize(intensities: np.ndarray) -> np.ndarray:\n",
    "    total_sum = np.sum(intensities**2)\n",
    "    normalized = intensities/total_sum\n",
    "    return normalized\n",
    "\n",
    "NORMALIZATION = {\n",
    "    INT: base_peak_normalize\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "waiting-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHABET.add(PADDING_CHARACTERS[SEQ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "understood-necklace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'C': 1,\n",
       " 'D': 2,\n",
       " 'E': 3,\n",
       " 'F': 4,\n",
       " 'G': 5,\n",
       " 'H': 6,\n",
       " 'I': 7,\n",
       " 'K': 8,\n",
       " 'L': 9,\n",
       " 'M': 10,\n",
       " 'N': 11,\n",
       " 'P': 12,\n",
       " 'Q': 13,\n",
       " 'R': 14,\n",
       " 'S': 15,\n",
       " 'T': 16,\n",
       " 'V': 17,\n",
       " 'W': 18,\n",
       " 'Y': 19,\n",
       " '_': 20}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx = {char: idx for idx, char in enumerate(sorted(ALPHABET))}\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "INDEX_ALPHABET = idx_to_char.keys()\n",
    "char_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "equivalent-portrait",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 16:53:32,836 - mmproteo_dataset_generation: DEBUG: Processing items with 16 subprocesses\n",
      "2021-07-20 16:53:32,919 - mmproteo_dataset_generation: DEBUG: Preprocessing item 2/26: '/scratch/mirko.krause/pdeep/training_columns/file_11.parquet'\n",
      "2021-07-20 16:53:32,919 - mmproteo_dataset_generation: Preprocessing item 1/26: '/scratch/mirko.krause/pdeep/training_columns/file_10.parquet'\n",
      "2021-07-20 16:53:32,919 - mmproteo_dataset_generation: DEBUG: Preprocessing item 3/26: '/scratch/mirko.krause/pdeep/training_columns/file_15.parquet'\n",
      "2021-07-20 16:53:32,920 - mmproteo_dataset_generation: DEBUG: Preprocessing item 6/26: '/scratch/mirko.krause/pdeep/training_columns/file_9.parquet'\n",
      "2021-07-20 16:53:32,920 - mmproteo_dataset_generation: DEBUG: Preprocessing item 7/26: '/scratch/mirko.krause/pdeep/training_columns/file_6.parquet'\n",
      "2021-07-20 16:53:32,920 - mmproteo_dataset_generation: DEBUG: Preprocessing item 8/26: '/scratch/mirko.krause/pdeep/training_columns/file_17.parquet'\n",
      "2021-07-20 16:53:32,922 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_11.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_11.parquet' already exists\n",
      "2021-07-20 16:53:32,922 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_15.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_15.parquet' already exists\n",
      "2021-07-20 16:53:32,921 - mmproteo_dataset_generation: DEBUG: Preprocessing item 12/26: '/scratch/mirko.krause/pdeep/training_columns/file_5.parquet'\n",
      "2021-07-20 16:53:32,922 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_10.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_10.parquet' already exists\n",
      "2021-07-20 16:53:32,921 - mmproteo_dataset_generation: DEBUG: Preprocessing item 10/26: '/scratch/mirko.krause/pdeep/training_columns/file_18.parquet'\n",
      "2021-07-20 16:53:32,921 - mmproteo_dataset_generation: Preprocessing item 11/26: '/scratch/mirko.krause/pdeep/training_columns/file_20.parquet'\n",
      "2021-07-20 16:53:32,921 - mmproteo_dataset_generation: DEBUG: Preprocessing item 13/26: '/scratch/mirko.krause/pdeep/training_columns/file_25.parquet'\n",
      "2021-07-20 16:53:32,921 - mmproteo_dataset_generation: DEBUG: Preprocessing item 9/26: '/scratch/mirko.krause/pdeep/training_columns/file_7.parquet'\n",
      "2021-07-20 16:53:32,922 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_9.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_9.parquet' already exists\n",
      "2021-07-20 16:53:32,921 - mmproteo_dataset_generation: DEBUG: Preprocessing item 14/26: '/scratch/mirko.krause/pdeep/training_columns/file_3.parquet'\n",
      "2021-07-20 16:53:32,921 - mmproteo_dataset_generation: DEBUG: Preprocessing item 15/26: '/scratch/mirko.krause/pdeep/training_columns/file_26.parquet'\n",
      "2021-07-20 16:53:32,921 - mmproteo_dataset_generation: DEBUG: Preprocessing item 16/26: '/scratch/mirko.krause/pdeep/training_columns/file_16.parquet'\n",
      "2021-07-20 16:53:32,923 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_6.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_6.parquet' already exists\n",
      "2021-07-20 16:53:32,923 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_17.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_17.parquet' already exists\n",
      "2021-07-20 16:53:32,923 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_5.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_5.parquet' already exists\n",
      "2021-07-20 16:53:32,924 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_18.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_18.parquet' already exists\n",
      "2021-07-20 16:53:32,924 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_25.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_25.parquet' already exists\n",
      "2021-07-20 16:53:32,924 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_20.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_20.parquet' already exists\n",
      "2021-07-20 16:53:32,924 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_7.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_7.parquet' already exists\n",
      "2021-07-20 16:53:32,924 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_26.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_26.parquet' already exists\n",
      "2021-07-20 16:53:32,924 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_3.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_3.parquet' already exists\n",
      "2021-07-20 16:53:32,925 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_16.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_16.parquet' already exists\n",
      "2021-07-20 16:53:32,917 - mmproteo_dataset_generation: DEBUG: Trying to parquet2tf_dataset-process 26 mzmlid parquet files\n",
      "2021-07-20 16:53:32,920 - mmproteo_dataset_generation: DEBUG: Preprocessing item 4/26: '/scratch/mirko.krause/pdeep/training_columns/file_24.parquet'\n",
      "2021-07-20 16:53:32,920 - mmproteo_dataset_generation: DEBUG: Preprocessing item 5/26: '/scratch/mirko.krause/pdeep/training_columns/file_22.parquet'\n",
      "2021-07-20 16:53:32,987 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_24.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_24.parquet' already exists\n",
      "2021-07-20 16:53:32,987 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_22.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_22.parquet' already exists\n",
      "2021-07-20 16:53:33,090 - mmproteo_dataset_generation: DEBUG: Preprocessing item 18/26: '/scratch/mirko.krause/pdeep/training_columns/file_2.parquet'\n",
      "2021-07-20 16:53:33,090 - mmproteo_dataset_generation: DEBUG: Preprocessing item 17/26: '/scratch/mirko.krause/pdeep/training_columns/file_21.parquet'\n",
      "2021-07-20 16:53:33,090 - mmproteo_dataset_generation: DEBUG: Preprocessing item 19/26: '/scratch/mirko.krause/pdeep/training_columns/file_1.parquet'\n",
      "2021-07-20 16:53:33,091 - mmproteo_dataset_generation: DEBUG: Preprocessing item 20/26: '/scratch/mirko.krause/pdeep/training_columns/file_8.parquet'\n",
      "2021-07-20 16:53:33,091 - mmproteo_dataset_generation: Preprocessing item 21/26: '/scratch/mirko.krause/pdeep/training_columns/file_13.parquet'\n",
      "2021-07-20 16:53:33,091 - mmproteo_dataset_generation: DEBUG: Preprocessing item 22/26: '/scratch/mirko.krause/pdeep/training_columns/file_19.parquet'\n",
      "2021-07-20 16:53:33,091 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_2.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_2.parquet' already exists\n",
      "2021-07-20 16:53:33,091 - mmproteo_dataset_generation: DEBUG: Preprocessing item 23/26: '/scratch/mirko.krause/pdeep/training_columns/file_14.parquet'\n",
      "2021-07-20 16:53:33,092 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_21.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_21.parquet' already exists\n",
      "2021-07-20 16:53:33,092 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_1.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_1.parquet' already exists\n",
      "2021-07-20 16:53:33,092 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_8.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_8.parquet' already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-20 16:53:33,092 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_13.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_13.parquet' already exists\n",
      "2021-07-20 16:53:33,092 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_19.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_19.parquet' already exists\n",
      "2021-07-20 16:53:33,092 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_14.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_14.parquet' already exists\n",
      "2021-07-20 16:53:33,092 - mmproteo_dataset_generation: DEBUG: Preprocessing item 24/26: '/scratch/mirko.krause/pdeep/training_columns/file_23.parquet'\n",
      "2021-07-20 16:53:33,092 - mmproteo_dataset_generation: DEBUG: Preprocessing item 25/26: '/scratch/mirko.krause/pdeep/training_columns/file_4.parquet'\n",
      "2021-07-20 16:53:33,092 - mmproteo_dataset_generation: DEBUG: Preprocessing item 26/26: '/scratch/mirko.krause/pdeep/training_columns/file_12.parquet'\n",
      "2021-07-20 16:53:33,093 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_23.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_23.parquet' already exists\n",
      "2021-07-20 16:53:33,093 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_4.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_4.parquet' already exists\n",
      "2021-07-20 16:53:33,093 - mmproteo_dataset_generation: DEBUG: Skipped '/scratch/mirko.krause/pdeep/training_columns/file_12.parquet' because '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_12.parquet' already exists\n",
      "2021-07-20 16:53:33,265 - mmproteo_dataset_generation: No mzmlid parquet files were parquet2tf_dataset-processed\n",
      "2021-07-20 16:53:33,265 - mmproteo_dataset_generation: Encountered 0 exceptions during processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parquet2DatasetFileProcessor(\n",
    "    training_data_columns=TRAINING_DATA_COLUMNS,\n",
    "    target_data_columns=TARGET_DATA_COLUMNS,\n",
    "    padding_lengths=PADDING_LENGTHS,\n",
    "    padding_characters=PADDING_CHARACTERS,\n",
    "    column_normalizations=NORMALIZATION,\n",
    "    dataset_dump_path_prefix=DATASET_DUMP_PATH,\n",
    "    char_to_idx_mapping_functions={\n",
    "        SEQ: char_to_idx.get\n",
    "    },\n",
    "    item_count=len(MZMLID_FILE_PATHS),\n",
    "    skip_existing=True,\n",
    "    split_on_column_values_of=SPLIT_VALUE_COLUMNS,\n",
    "    logger=logger\n",
    ").process(parquet_file_paths=MZMLID_FILE_PATHS,\n",
    "          thread_count=int(THREAD_COUNT/2),\n",
    "          keep_exceptions_as=True,\n",
    "         )[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9517d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_configuration = {\n",
    "    'padding_characters': PADDING_CHARACTERS,\n",
    "    'padding_lengths': PADDING_LENGTHS,\n",
    "    'idx_to_char': idx_to_char,\n",
    "    'normalization': NORMALIZATION,\n",
    "    'split_value_columns': SPLIT_VALUE_COLUMNS,\n",
    "    'training_data_columns': TRAINING_DATA_COLUMNS,\n",
    "    'target_data_columns': TARGET_DATA_COLUMNS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "225f5e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_configuration = utils.denumpyfy(processing_configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31f0a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"padding_characters\": {\n",
      "        \"peptide_sequence\": \"_\",\n",
      "        \"mz_array\": 0.0,\n",
      "        \"intensity_array\": 0.0\n",
      "    },\n",
      "    \"padding_lengths\": {\n",
      "        \"mz_array\": 89,\n",
      "        \"intensity_array\": 89,\n",
      "        \"peptide_sequence\": 30\n",
      "    },\n",
      "    \"idx_to_char\": {\n",
      "        \"0\": \"A\",\n",
      "        \"1\": \"C\",\n",
      "        \"2\": \"D\",\n",
      "        \"3\": \"E\",\n",
      "        \"4\": \"F\",\n",
      "        \"5\": \"G\",\n",
      "        \"6\": \"H\",\n",
      "        \"7\": \"I\",\n",
      "        \"8\": \"K\",\n",
      "        \"9\": \"L\",\n",
      "        \"10\": \"M\",\n",
      "        \"11\": \"N\",\n",
      "        \"12\": \"P\",\n",
      "        \"13\": \"Q\",\n",
      "        \"14\": \"R\",\n",
      "        \"15\": \"S\",\n",
      "        \"16\": \"T\",\n",
      "        \"17\": \"V\",\n",
      "        \"18\": \"W\",\n",
      "        \"19\": \"Y\",\n",
      "        \"20\": \"_\"\n",
      "    },\n",
      "    \"normalization\": {\n",
      "        \"intensity_array\": \"<function base_peak_normalize at 0x7fc52ee681f0>\"\n",
      "    },\n",
      "    \"split_value_columns\": null,\n",
      "    \"training_data_columns\": [\n",
      "        \"mz_array\",\n",
      "        \"intensity_array\"\n",
      "    ],\n",
      "    \"target_data_columns\": [\n",
      "        \"peptide_sequence\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(visualization.pretty_print_json(processing_configuration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c999d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote processing info to '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/processing_info.json'\n"
     ]
    }
   ],
   "source": [
    "with open(PROCESSING_FILE_PATH, 'w') as file:\n",
    "    file.write(visualization.pretty_print_json(processing_configuration))\n",
    "    print(f\"wrote processing info to '{PROCESSING_FILE_PATH}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3844e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lovely-landing",
   "metadata": {},
   "source": [
    "# Prototyping an ML Model on Tensorflow Datasets\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worth-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "from typing import Iterable, Callable, Dict, Any, Tuple, Optional, List, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.python import keras as K\n",
    "\n",
    "from mmproteo.utils import log, utils, visualization\n",
    "from mmproteo.utils.formats.mz import FilteringProcessor\n",
    "from mmproteo.utils.formats.tf_dataset import Parquet2DatasetFileProcessor\n",
    "from mmproteo.utils.processing import ItemProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "circular-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "certified-gibson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Printing to Stdout\n"
     ]
    }
   ],
   "source": [
    "logger = log.DummyLogger(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-playlist",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "norwegian-therapist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/workspace/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "genuine-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"PXD010000\"\n",
    "DUMP_PATH = os.path.join(\"..\", \"dumps\", PROJECT)\n",
    "TRAINING_COLUMNS_DUMP_PATH = os.path.join(DUMP_PATH, \"training_columns\")\n",
    "FILES_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"*_mzmlid.parquet\")\n",
    "STATISTICS_FILE_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"statistics.parquet\")\n",
    "DATASET_DUMP_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"tf_datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alpha-message",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MZMLID_FILE_PATHS = glob.glob(FILES_PATH)\n",
    "len(MZMLID_FILE_PATHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "twenty-methodology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../dumps/PXD010000/training_columns/Biodiversity_B_fragilis_01_28Jul15_Arwen_14-12-03_mzmlid.parquet'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MZMLID_FILE_PATHS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a485487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide_sequence</th>\n",
       "      <th>mz_array</th>\n",
       "      <th>intensity_array</th>\n",
       "      <th>species</th>\n",
       "      <th>istrain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[C, K, P, T, S, P, G, R]</td>\n",
       "      <td>[102.0558, 115.05197, 116.971794, 119.907036, 129.1024, 136.06175, 152.05682, 157.84837, 159.22517, 171.11295, 175.119, 175.95169, 199.10796, 202.6932, 215.08527, 228.88432, 232.11212, 244.87819, 286.14047, 307.6665, 312.16718, 329.19223, 360.2081, 378.2132, 385.92047, 400.78918, 401.78973, 416.22388, 422.8325, 440.8446, 441.84528, 517.2766, 614.3271, 615.3258]</td>\n",
       "      <td>[723.529, 569.4288, 659.1485, 599.0097, 19982.768, 4909.943, 771.28937, 596.6283, 593.3602, 1262.0436, 868.29816, 581.3835, 721.64886, 752.1542, 2492.1565, 3854.2283, 1364.17, 615.11633, 746.43365, 1512.8475, 1474.3188, 1069.4283, 762.6549, 744.29315, 925.18164, 7245.0005, 2374.2295, 3248.2861, 4047.135, 21597.44, 5534.1826, 4359.906, 13269.387, 2903.926]</td>\n",
       "      <td>Citrobacter_freundii</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>[K, H, I, T, A, G, A, K]</td>\n",
       "      <td>[101.1075, 110.07151, 111.04457, 111.619194, 112.050735, 116.972084, 118.967834, 122.29705, 129.05539, 129.10248, 129.11131, 129.92657, 130.08653, 136.06192, 136.07182, 136.07652, 137.06726, 139.98817, 147.11304, 152.05687, 171.00543, 173.09312, 189.01633, 197.12833, 200.14093, 212.10458, 218.14975, 223.15533, 230.11382, 231.12407, 232.88867, 239.08455, 249.13492, 251.15112, 275.1718, 283.13745, 299.95496, 301.1428, 302.81696, 309.96753, 313.8611, 315.81067, 316.8158, 318.8151, 334.8159, 335.81232, 336.81036, 337.8101, 340.79953, 343.80972, 344.8009, 346.20868, 349.20425, 354.82224, 355.82004, 360.81204, 361.81488, 362.81155, 363.81027, 370.8382, 372.79752, 389.83908, 394.83862, 407.8483, 408.7495, 408.8483, 412.79782, 412.8495, 413.26614, 413.85025, 414.26913, 419.80457, 430.79797, 431.7977, 447.25662, 448.2613, 465.94623, 560.34186, 561.3432, 697.4013, 787.23486]</td>\n",
       "      <td>[1244.104, 18248.63, 747.18225, 672.4936, 3284.768, 5824.9575, 1207.1666, 563.56824, 1090.989, 18666.379, 1132.0656, 547.7189, 8010.2773, 9944.686, 717.7685, 909.038, 927.90424, 1259.5803, 9798.942, 12360.792, 777.4666, 711.51215, 1365.1267, 669.6005, 718.6803, 724.85455, 1516.5447, 6849.315, 1172.2983, 11597.979, 882.7782, 954.53986, 1087.7533, 5462.294, 3395.8171, 717.6081, 663.439, 7134.955, 748.11066, 1207.3207, 3609.01, 838.3727, 1179.3096, 1473.9382, 2907.0327, 3263.6355, 4049.7156, 4270.7646, 793.22906, 1597.9222, 4802.7974, 4149.7407, 6089.5537, 7634.4062, 5610.0933, 1050.6061, 957.7547, 6195.684, 1396.489, 866.404, 846.26697, 1433.4541, 1076.0883, 5400.0293, 1063.56, 1220.6185, 1581.0791, 21550.523, 21930.604, 7990.5386, 3053.2961, 754.4101, 2840.6213, 1415.5275, 9367.521, 1103.6198, 957.9087, 6343.26, 795.6793, 2594.3503, 750.4295]</td>\n",
       "      <td>Citrobacter_freundii</td>\n",
       "      <td>Train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            peptide_sequence  \\\n",
       "21  [C, K, P, T, S, P, G, R]   \n",
       "70  [K, H, I, T, A, G, A, K]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         mz_array  \\\n",
       "21                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    [102.0558, 115.05197, 116.971794, 119.907036, 129.1024, 136.06175, 152.05682, 157.84837, 159.22517, 171.11295, 175.119, 175.95169, 199.10796, 202.6932, 215.08527, 228.88432, 232.11212, 244.87819, 286.14047, 307.6665, 312.16718, 329.19223, 360.2081, 378.2132, 385.92047, 400.78918, 401.78973, 416.22388, 422.8325, 440.8446, 441.84528, 517.2766, 614.3271, 615.3258]   \n",
       "70  [101.1075, 110.07151, 111.04457, 111.619194, 112.050735, 116.972084, 118.967834, 122.29705, 129.05539, 129.10248, 129.11131, 129.92657, 130.08653, 136.06192, 136.07182, 136.07652, 137.06726, 139.98817, 147.11304, 152.05687, 171.00543, 173.09312, 189.01633, 197.12833, 200.14093, 212.10458, 218.14975, 223.15533, 230.11382, 231.12407, 232.88867, 239.08455, 249.13492, 251.15112, 275.1718, 283.13745, 299.95496, 301.1428, 302.81696, 309.96753, 313.8611, 315.81067, 316.8158, 318.8151, 334.8159, 335.81232, 336.81036, 337.8101, 340.79953, 343.80972, 344.8009, 346.20868, 349.20425, 354.82224, 355.82004, 360.81204, 361.81488, 362.81155, 363.81027, 370.8382, 372.79752, 389.83908, 394.83862, 407.8483, 408.7495, 408.8483, 412.79782, 412.8495, 413.26614, 413.85025, 414.26913, 419.80457, 430.79797, 431.7977, 447.25662, 448.2613, 465.94623, 560.34186, 561.3432, 697.4013, 787.23486]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          intensity_array  \\\n",
       "21                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [723.529, 569.4288, 659.1485, 599.0097, 19982.768, 4909.943, 771.28937, 596.6283, 593.3602, 1262.0436, 868.29816, 581.3835, 721.64886, 752.1542, 2492.1565, 3854.2283, 1364.17, 615.11633, 746.43365, 1512.8475, 1474.3188, 1069.4283, 762.6549, 744.29315, 925.18164, 7245.0005, 2374.2295, 3248.2861, 4047.135, 21597.44, 5534.1826, 4359.906, 13269.387, 2903.926]   \n",
       "70  [1244.104, 18248.63, 747.18225, 672.4936, 3284.768, 5824.9575, 1207.1666, 563.56824, 1090.989, 18666.379, 1132.0656, 547.7189, 8010.2773, 9944.686, 717.7685, 909.038, 927.90424, 1259.5803, 9798.942, 12360.792, 777.4666, 711.51215, 1365.1267, 669.6005, 718.6803, 724.85455, 1516.5447, 6849.315, 1172.2983, 11597.979, 882.7782, 954.53986, 1087.7533, 5462.294, 3395.8171, 717.6081, 663.439, 7134.955, 748.11066, 1207.3207, 3609.01, 838.3727, 1179.3096, 1473.9382, 2907.0327, 3263.6355, 4049.7156, 4270.7646, 793.22906, 1597.9222, 4802.7974, 4149.7407, 6089.5537, 7634.4062, 5610.0933, 1050.6061, 957.7547, 6195.684, 1396.489, 866.404, 846.26697, 1433.4541, 1076.0883, 5400.0293, 1063.56, 1220.6185, 1581.0791, 21550.523, 21930.604, 7990.5386, 3053.2961, 754.4101, 2840.6213, 1415.5275, 9367.521, 1103.6198, 957.9087, 6343.26, 795.6793, 2594.3503, 750.4295]   \n",
       "\n",
       "                 species istrain  \n",
       "21  Citrobacter_freundii   Train  \n",
       "70  Citrobacter_freundii   Train  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(MZMLID_FILE_PATHS[1])\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a453e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interesting-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ = 'peptide_sequence'\n",
    "MZ = 'mz_array'\n",
    "INT = 'intensity_array'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73a1f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_COLUMNS = [MZ, INT]\n",
    "TARGET_DATA_COLUMNS = [SEQ]\n",
    "SPLIT_VALUE_COLUMNS = ['species', 'istrain']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honey-headset",
   "metadata": {},
   "source": [
    "## Calculating Statistics over all MZMLID Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vertical-tiger",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded previous statistics file '../dumps/PXD010000/training_columns/statistics.parquet'\n"
     ]
    }
   ],
   "source": [
    "file_path_count = len(MZMLID_FILE_PATHS)\n",
    "\n",
    "def get_mzmlid_file_stats(item: Tuple[int, str]) -> Dict[str, Any]:\n",
    "    idx, path = item\n",
    "    info_text = f\"Processing item {idx + 1}/{file_path_count} '{path}'\"\n",
    "    if idx % 10 == 0:\n",
    "        logger.info(info_text)\n",
    "    else:\n",
    "        logger.debug(info_text)\n",
    "    df = pd.read_parquet(path)\n",
    "    max_sequence_length = df[SEQ].str.len().max()\n",
    "    max_array_length = df[INT].str.len().max()\n",
    "    alphabet = set.union(*df[SEQ].apply(set))\n",
    "    item_count = len(df)\n",
    "    del df\n",
    "    gc.collect()\n",
    "    \n",
    "    return {\n",
    "        \"file_path\": path,\n",
    "        \"max_sequence_length\": max_sequence_length,\n",
    "        \"max_array_length\": max_array_length,\n",
    "        \"alphabet\": alphabet,\n",
    "        \"item_count\": item_count\n",
    "    }\n",
    "\n",
    "if os.path.exists(STATISTICS_FILE_PATH):\n",
    "    file_stats = pd.read_parquet(STATISTICS_FILE_PATH)\n",
    "    file_stats.alphabet = file_stats.alphabet.apply(set)\n",
    "    print(f\"loaded previous statistics file '{STATISTICS_FILE_PATH}'\")\n",
    "else:\n",
    "    file_stats = pd.DataFrame(\n",
    "        ItemProcessor(\n",
    "            items=enumerate(MZMLID_FILE_PATHS),\n",
    "            item_processor=get_mzmlid_file_stats,\n",
    "            action_name=\"analyse\",\n",
    "            subject_name=\"mzmlid file\",\n",
    "            thread_count=0,\n",
    "            logger=logger\n",
    "        ).process()\n",
    "    )\n",
    "    \n",
    "    file_stats_writable = file_stats.copy()\n",
    "    file_stats_writable.alphabet = file_stats_writable.alphabet.apply(list) # cannot store sets\n",
    "    file_stats_writable.to_parquet(STATISTICS_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "leading-pipeline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>max_sequence_length</th>\n",
       "      <th>max_array_length</th>\n",
       "      <th>alphabet</th>\n",
       "      <th>item_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../dumps/PXD010000/training_columns/Biodiversity_B_fragilis_01_28Jul15_Arwen_14-12-03_mzmlid.parquet</td>\n",
       "      <td>50</td>\n",
       "      <td>1845</td>\n",
       "      <td>{T, P, A, S, G, Q, R, I, K, Y, W, V, E, H, M, D, F, M(Oxidation), C, L, N}</td>\n",
       "      <td>26943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../dumps/PXD010000/training_columns/Biodiversity_Cibrobacter_freundii_LB_aerobic_01_01Feb16_Arwen_15-07-13_mzmlid.parquet</td>\n",
       "      <td>50</td>\n",
       "      <td>1697</td>\n",
       "      <td>{T, P, A, S, G, Q, R, I, K, Y, W, V, E, H, M, D, F, M(Oxidation), C, L, N}</td>\n",
       "      <td>27516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                   file_path  \\\n",
       "0                       ../dumps/PXD010000/training_columns/Biodiversity_B_fragilis_01_28Jul15_Arwen_14-12-03_mzmlid.parquet   \n",
       "1  ../dumps/PXD010000/training_columns/Biodiversity_Cibrobacter_freundii_LB_aerobic_01_01Feb16_Arwen_15-07-13_mzmlid.parquet   \n",
       "\n",
       "   max_sequence_length  max_array_length  \\\n",
       "0                   50              1845   \n",
       "1                   50              1697   \n",
       "\n",
       "                                                                     alphabet  \\\n",
       "0  {T, P, A, S, G, Q, R, I, K, Y, W, V, E, H, M, D, F, M(Oxidation), C, L, N}   \n",
       "1  {T, P, A, S, G, Q, R, I, K, Y, W, V, E, H, M, D, F, M(Oxidation), C, L, N}   \n",
       "\n",
       "   item_count  \n",
       "0       26943  \n",
       "1       27516  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_stats.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "following-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING_LENGTHS = {\n",
    "    MZ: file_stats.max_array_length.max(),\n",
    "    INT: file_stats.max_array_length.max(),\n",
    "    SEQ: file_stats.max_sequence_length.max()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "early-legislature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding lengths = {'mz_array': 2354, 'intensity_array': 2354, 'peptide_sequence': 50}\n",
      "TOTAL_ITEM_COUNT = 5513185\n",
      "ALPHABET = A, C, D, E, F, G, H, I, K, L, M, M(Oxidation), N, P, Q, R, S, T, V, W, Y\n"
     ]
    }
   ],
   "source": [
    "print(\"padding lengths =\", PADDING_LENGTHS)\n",
    "\n",
    "TOTAL_ITEM_COUNT = file_stats.item_count.sum()\n",
    "print(f\"TOTAL_ITEM_COUNT = {TOTAL_ITEM_COUNT}\")\n",
    "\n",
    "ALPHABET = set.union(*file_stats.alphabet)\n",
    "print(f\"ALPHABET = {', '.join(sorted(ALPHABET))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-recipient",
   "metadata": {},
   "source": [
    "## Data Normalization, Padding, and Conversion to Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "headed-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(values: np.ndarray) -> np.ndarray:\n",
    "    return tf.keras.utils.normalize(x=values, order=2)\n",
    "\n",
    "def base_peak_normalize(values: np.ndarray) -> np.ndarray:\n",
    "    return values / values.max(initial=0)\n",
    "\n",
    "# by Tom, probably\n",
    "# don't know, what it's based on\n",
    "def ion_current_normalize(intensities: np.ndarray) -> np.ndarray:\n",
    "    total_sum = np.sum(intensities**2)\n",
    "    normalized = intensities/total_sum\n",
    "    return normalized\n",
    "\n",
    "NORMALIZATION = {\n",
    "    INT: base_peak_normalize\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "waiting-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING_CHARACTERS = {\n",
    "    SEQ: '_',\n",
    "    MZ: 0.0,\n",
    "    INT: 0.0,\n",
    "}\n",
    "\n",
    "ALPHABET.add(PADDING_CHARACTERS[SEQ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "understood-necklace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 0,\n",
       " 'C': 1,\n",
       " 'D': 2,\n",
       " 'E': 3,\n",
       " 'F': 4,\n",
       " 'G': 5,\n",
       " 'H': 6,\n",
       " 'I': 7,\n",
       " 'K': 8,\n",
       " 'L': 9,\n",
       " 'M': 10,\n",
       " 'M(Oxidation)': 11,\n",
       " 'N': 12,\n",
       " 'P': 13,\n",
       " 'Q': 14,\n",
       " 'R': 15,\n",
       " 'S': 16,\n",
       " 'T': 17,\n",
       " 'V': 18,\n",
       " 'W': 19,\n",
       " 'Y': 20,\n",
       " '_': 21}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx = {char: idx for idx, char in enumerate(sorted(ALPHABET))}\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "INDEX_ALPHABET = idx_to_char.keys()\n",
    "char_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "equivalent-portrait",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Processing item 1/235: '../dumps/PXD010000/training_columns/Biodiversity_B_fragilis_01_28Jul15_Arwen_14-12-03_mzmlid.parquet'\n",
      "INFO: Processing item 11/235: '../dumps/PXD010000/training_columns/Biodiversity_P_polymyxa_TBS_aerobic_3_17July16_Samwise_16-04-10_mzmlid.parquet'\n",
      "INFO: Processing item 21/235: '../dumps/PXD010000/training_columns/M_alcali_copp_CH4_B2_T1_09_QE_23Mar18_Oak_18-01-07_mzmlid.parquet'\n",
      "INFO: Processing item 31/235: '../dumps/PXD010000/training_columns/Cj_media_MH_R4_23Feb15_Arwen_14-12-03_mzmlid.parquet'\n",
      "INFO: Processing item 41/235: '../dumps/PXD010000/training_columns/Biodiversity_C_Baltica_T240_R2_C_27Jan16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 51/235: '../dumps/PXD010000/training_columns/Biodiversity_M_xanthus_DZ2_plates_1_03May16_Samwise_16-03-32_mzmlid.parquet'\n",
      "INFO: Processing item 61/235: '../dumps/PXD010000/training_columns/Biodiversity_B_thet_CMgluc_anaerobic_02_01Feb16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 71/235: '../dumps/PXD010000/training_columns/Biodiversity_R_palustris_PMnitro_anaerobic_2_01Jun16_Pippin_16-03-39_mzmlid.parquet'\n",
      "INFO: Processing item 81/235: '../dumps/PXD010000/training_columns/Biodiversity_S_elongatus_BG11_aerobic_1_14July16_Pippin_16-05-01_mzmlid.parquet'\n",
      "INFO: Processing item 91/235: '../dumps/PXD010000/training_columns/Biodiversity_F_novicida_TSB_aerobic_03_01Feb16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 101/235: '../dumps/PXD010000/training_columns/M_alcali_copp_CH4_B3_T1_11_QE_23Mar18_Oak_18-01-07_mzmlid.parquet'\n",
      "INFO: Processing item 111/235: '../dumps/PXD010000/training_columns/Biodiversity_M_xanthus_DZ2_48h_plates_2_13Jun16_Pippin_16-03-39_mzmlid.parquet'\n",
      "INFO: Processing item 121/235: '../dumps/PXD010000/training_columns/Biodiversity_F_prausnitzii_Glc_01_28Oct15_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 131/235: '../dumps/PXD010000/training_columns/Biodiversity_P_ruminicola_MDM_anaerobic_2_09Jun16_Pippin_16-03-39_mzmlid.parquet'\n",
      "INFO: Processing item 141/235: '../dumps/PXD010000/training_columns/M_alcali_copp_MeOH_B2_T1_03_QE_23Mar18_Oak_18-01-07_mzmlid.parquet'\n",
      "INFO: Processing item 151/235: '../dumps/PXD010000/training_columns/Biodiversity_A_cryptum_FeTSB_anaerobic_2_01Jun16_Pippin_16-03-39_mzmlid.parquet'\n",
      "INFO: Processing item 161/235: '../dumps/PXD010000/training_columns/Biodiversity_B_thet_LIB_anaerobic_03_01Feb16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 171/235: '../dumps/PXD010000/training_columns/Biodiversity_C_Baltica_T240_R2_Inf_27Jan16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 181/235: '../dumps/PXD010000/training_columns/Biodiversity_B_thet_CMcarb_anaerobic_02_01Feb16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 191/235: '../dumps/PXD010000/training_columns/Biodiversity_S_elongatus_BG11NaCl_aerobic_1_05Oct16_Pippin_16-05-06_mzmlid.parquet'\n",
      "INFO: Processing item 201/235: '../dumps/PXD010000/training_columns/Biodiversity_B_thet_CMcarb_anaerobic_03_01Feb16_Arwen_15-07-13_mzmlid.parquet'\n",
      "INFO: Processing item 211/235: '../dumps/PXD010000/training_columns/Biodiversity_B_subtilis_pellet_set2_2_13Jun16_Pippin_16-03-39_mzmlid.parquet'\n",
      "INFO: Processing item 221/235: '../dumps/PXD010000/training_columns/Biodiversity_HL49_HLHYE_aerobic_3_05Oct16_Pippin_16-05-06_mzmlid.parquet'\n",
      "INFO: Processing item 231/235: '../dumps/PXD010000/training_columns/Biodiversity_B_subtilis_NCIB3610_48h_plates_3_13Jun16_Pippin_16-03-39_mzmlid.parquet'\n",
      "INFO: No mzmlid parquet files were parquet2tf_dataset-processed\n",
      "INFO: Encountered 0 exceptions during processing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Parquet2DatasetFileProcessor(\n",
    "    training_data_columns=TRAINING_DATA_COLUMNS,\n",
    "    target_data_columns=TARGET_DATA_COLUMNS,\n",
    "    padding_lengths=PADDING_LENGTHS,\n",
    "    padding_characters=PADDING_CHARACTERS,\n",
    "    column_normalizations=NORMALIZATION,\n",
    "    dataset_dump_path_prefix=DATASET_DUMP_PATH,\n",
    "    char_to_idx_mapping_functions={\n",
    "        SEQ: char_to_idx.get\n",
    "    },\n",
    "    item_count=len(MZMLID_FILE_PATHS),\n",
    "    skip_existing=True,\n",
    "    split_on_column_values_of=SPLIT_VALUE_COLUMNS,\n",
    "    logger=logger\n",
    ").process(parquet_file_paths=MZMLID_FILE_PATHS,\n",
    "          thread_count=3)[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-proceeding",
   "metadata": {},
   "source": [
    "## Loading Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5719d9a",
   "metadata": {},
   "source": [
    "### ... by type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8581bc",
   "metadata": {},
   "source": [
    "#### ... by training type annotation (abandoned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "323c4964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_DATA_TYPES = {path.split(os.path.sep)[-1] for path in glob.glob(\n",
    "    os.path.join(\n",
    "        DATASET_DUMP_PATH, \n",
    "        '*',  # filename\n",
    "        '*',  # species\n",
    "        '*'   # istrain\n",
    "    ))}\n",
    "TRAINING_DATA_TYPES"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae23af50",
   "metadata": {},
   "source": [
    "# only when using the annotated training data types\n",
    "dataset_file_paths = {training_data_type: glob.glob(os.path.join(DATASET_DUMP_PATH, '*', '*', training_data_type))\n",
    "for training_data_type in TRAINING_DATA_TYPES}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c094281b",
   "metadata": {},
   "source": [
    "#### ... by species annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93f5789b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acidiphilium_cryptum_JF-5',\n",
       " 'Agrobacterium_tumefaciens_IAM_12048',\n",
       " 'Alcaligenes_faecalis',\n",
       " 'Algoriphagus_marincola_HL-49',\n",
       " 'Anaerococcus_hydrogenalis_DSM_7454',\n",
       " 'Bacillus_cereus_ATCC14579',\n",
       " 'Bacillus_subtilis_168',\n",
       " 'Bacillus_subtilis_NCIB3610',\n",
       " 'Bacteroides_fragilis_638R',\n",
       " 'Bacteroides_thetaiotaomicron_VPI-5482',\n",
       " 'Bifidobacterium_bifidum_ATCC29521',\n",
       " 'Bifidobacterium_longum_infantis_ATCC15697',\n",
       " 'Campylobacter_jejuni',\n",
       " 'Cellulomonas_gilvus_ATCC13127',\n",
       " 'Cellulophaga_baltica_18',\n",
       " 'Chryseobacterium_indologenes',\n",
       " 'Citrobacter_freundii',\n",
       " 'Clostridium_ljungdahlii_DMS_13528',\n",
       " 'Coprococcus_comes_ATCC27758',\n",
       " 'Cupriavidus_necator_N-1',\n",
       " 'Cyanobacterium_stanieri',\n",
       " 'Delftia_acidovorans_SPH1',\n",
       " 'Dorea_longicatena_DSM13814',\n",
       " 'Erythrobacter_HL-111',\n",
       " 'Faecalibacterium_prausnitzii',\n",
       " 'Fibrobacter_succinogenes_S85',\n",
       " 'Francisella_novicida_U112',\n",
       " 'Halomonas_HL-48',\n",
       " 'Halomonas_HL-93',\n",
       " 'Lactobacillales_casei',\n",
       " 'Legionella_pneumophila',\n",
       " 'Listeria_monocytogenes_10403S',\n",
       " 'Methylomicrobium_alcaliphilum',\n",
       " 'Micrococcus_luteus',\n",
       " 'Mycobacterium_smegmatis',\n",
       " 'Myxococcus_xanthus_DZ2',\n",
       " 'Paenibacillus_polymyxa_ATCC842',\n",
       " 'Paracoccus_denitrificans',\n",
       " 'Prevotella_ruminicola_23_ATCC_19189',\n",
       " 'Pseudomonas_putida_KT2440',\n",
       " 'Rhodobacteraceae_bacterium_HL-91',\n",
       " 'Rhodococcus_jostii_RHA1',\n",
       " 'Rhodopseudomonas_palustris',\n",
       " 'Ruminococcus_gnavus',\n",
       " 'Shewanella_oneidensis_MR-1',\n",
       " 'Stigmatella_aurantiaca_DW431',\n",
       " 'Streptococcus_agalactiae',\n",
       " 'Streptomyces_griseorubens',\n",
       " 'Streptomyces_venezuelae',\n",
       " 'Sulfobacillus_thermosulfidooxidans',\n",
       " 'Synechococcus_elongatus_PCC7942'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPECIES = {path.split(os.path.sep)[-2] for path in glob.glob(\n",
    "    os.path.join(\n",
    "        DATASET_DUMP_PATH, \n",
    "        '*',  # filename\n",
    "        '*',  # species\n",
    "        '*'   # istrain\n",
    "    ))}\n",
    "SPECIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6e0937b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SPECIES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622256e",
   "metadata": {},
   "source": [
    "### ... with train-test-eval split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee8aadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIES_SPLITS = {\n",
    "            \"Train\": 0.4,\n",
    "            \"Test\": 0.5,\n",
    "            \"Eval\": 0.6\n",
    "        }\n",
    "KEEP_CACHE = True  # currently, there is no cache; the flag only disables benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55221ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found dataset file paths dump '../dumps/PXD010000/training_columns/tf_datasets/dataset_file_paths.json'\n",
      "\n",
      "assigned dataset files:\n",
      "#Train = 89\n",
      "e.g.: ../dumps/PXD010000/training_columns/tf_datasets/Biodiversity_C_indologenes_LIB_aerobic_02_03May16_Samwise_16-03-32_mzmlid.parquet/Chryseobacterium_indologenes/Train\n",
      "#Test = 17\n",
      "e.g.: ../dumps/PXD010000/training_columns/tf_datasets/Biodiversity_A_cryptum_FeTSB_anaerobic_1_01Jun16_Pippin_16-03-39_mzmlid.parquet/Acidiphilium_cryptum_JF-5/Train\n",
      "#Eval = 29\n",
      "e.g.: ../dumps/PXD010000/training_columns/tf_datasets/Biodiversity_B_fragilis_CMcarb_anaerobic_01_01Feb16_Arwen_15-07-13_mzmlid.parquet/Bacteroides_fragilis_638R/Train\n"
     ]
    }
   ],
   "source": [
    "def assign_species_randomly(species: List[str], splits: Dict[str, float] = None) -> Dict[str, List[str]]:\n",
    "    if splits is None:\n",
    "        splits = {\n",
    "            \"Train\": 0.8,\n",
    "            \"Test\": 0.94,\n",
    "            \"Eval\": 1.0\n",
    "        }\n",
    "    \n",
    "    splits[None] = 0\n",
    "    \n",
    "    sorted_splits = sorted(splits.items(), key=lambda tupl: tupl[1])\n",
    "    \n",
    "    shuffled_species = list(species)\n",
    "    random.shuffle(shuffled_species)\n",
    "\n",
    "    assigned_species = {\n",
    "        training_data_type: shuffled_species[\n",
    "            int(sorted_splits[i][1] * len(shuffled_species)):\n",
    "            int(split * len(shuffled_species))\n",
    "        ]\n",
    "        for i, (training_data_type, split) in enumerate(sorted_splits[1:])\n",
    "    }\n",
    "    return assigned_species\n",
    "\n",
    "def flatten(lists: List[List[Any]]) -> List[Any]:\n",
    "    res = []\n",
    "    for item in lists:\n",
    "        res += item\n",
    "    return res\n",
    "\n",
    "def find_files_for_assigned_species(\n",
    "    assigned_species: Dict[str, List[str]],\n",
    "    file_pattern: str = os.path.join(DATASET_DUMP_PATH, '*', \"{specie}\", '*')\n",
    ") -> Dict[str, List[str]]:\n",
    "    return {\n",
    "        training_type: flatten(\n",
    "            [\n",
    "                glob.glob(file_pattern.format(specie=specie)) for specie in species\n",
    "            ]\n",
    "        ) for training_type, species in assigned_species.items()\n",
    "    }\n",
    "\n",
    "def store_dataset_file_paths(\n",
    "    dataset_file_paths: str, \n",
    "    output_file) -> str:\n",
    "    with open(output_file, 'w') as file:\n",
    "        file.write(visualization.pretty_print_json(dataset_file_paths))\n",
    "\n",
    "    return output_file\n",
    "\n",
    "def load_json(file_path: str) -> Dict[str, Any]:\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.loads(file.read())\n",
    "\n",
    "def print_list_length_in_dict(dic: Dict[str, List[Any]]) -> None:\n",
    "    for key, list_value in dic.items():\n",
    "        print(f\"#{key} = {len(list_value)}\")\n",
    "        if len(list_value) > 0:\n",
    "            print(f\"e.g.: {list_value[0]}\")\n",
    "\n",
    "dataset_file_path_dump_file = os.path.join(\n",
    "        DATASET_DUMP_PATH, \n",
    "        \"dataset_file_paths.json\"\n",
    "    )\n",
    "\n",
    "if KEEP_CACHE and os.path.exists(dataset_file_path_dump_file):\n",
    "    dataset_file_paths = load_json(dataset_file_path_dump_file)\n",
    "    print(f\"found dataset file paths dump '{dataset_file_path_dump_file}'\")\n",
    "else:\n",
    "    assigned_species = assign_species_randomly(SPECIES, splits=SPECIES_SPLITS)\n",
    "    print(\"assigned species:\")\n",
    "    print_list_length_in_dict(assigned_species)\n",
    "\n",
    "    dataset_file_paths = find_files_for_assigned_species(assigned_species)\n",
    "    store_dataset_file_paths(dataset_file_paths, dataset_file_path_dump_file)\n",
    "    print(f\"dumped dataset file paths into '{dataset_file_path_dump_file}'\")\n",
    "\n",
    "print()\n",
    "print(\"assigned dataset files:\")\n",
    "print_list_length_in_dict(dataset_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec611252",
   "metadata": {},
   "source": [
    "### Loading corresponding TF datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "stupid-malaysia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(2354,), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(2354,), dtype=tf.float32, name=None)),\n",
       " TensorSpec(shape=(50,), dtype=tf.int8, name=None))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_spec = ((tf.TensorSpec(shape=(PADDING_LENGTHS[MZ],), dtype=tf.float32), \n",
    "  tf.TensorSpec(shape=(PADDING_LENGTHS[INT],), dtype=tf.float32)),\n",
    "(tf.TensorSpec(shape=(PADDING_LENGTHS[SEQ],), dtype=tf.int8)))\n",
    "element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aebc3d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train': <ParallelInterleaveDataset shapes: (((2354,), (2354,)), (50,)), types: ((tf.float32, tf.float32), tf.int8)>,\n",
       " 'Test': <ParallelInterleaveDataset shapes: (((2354,), (2354,)), (50,)), types: ((tf.float32, tf.float32), tf.int8)>,\n",
       " 'Eval': <ParallelInterleaveDataset shapes: (((2354,), (2354,)), (50,)), types: ((tf.float32, tf.float32), tf.int8)>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_datasets = {\n",
    "    training_data_type: tf.data.Dataset.from_tensor_slices(paths).interleave(lambda path: \n",
    "        tf.data.experimental.load(\n",
    "            path=path, \n",
    "            element_spec=element_spec, \n",
    "            compression='GZIP'\n",
    "        ),\n",
    "                                                                             num_parallel_calls=os.cpu_count(),\n",
    "                                                                             deterministic=False\n",
    "                                                                            )\n",
    "    for training_data_type, paths in dataset_file_paths.items()\n",
    "}\n",
    "\n",
    "merged_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-difficulty",
   "metadata": {},
   "source": [
    "## Configuring Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba9ffb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# although not all data fits into a 100k buffer, the interleaving should make it sufficiently random\n",
    "SHUFFLE_BUFFER_SIZE = 5*10**5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b141e",
   "metadata": {},
   "source": [
    "### Caching (currently abandoned because of too high RAM usage)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d4a97453",
   "metadata": {},
   "source": [
    "CACHED_DATASET_DUMP_PATH = os.path.join(DATASET_DUMP_PATH, \"cache\")\n",
    "\n",
    "try:\n",
    "    if not KEEP_CACHE:\n",
    "        shutil.rmtree(CACHED_DATASET_DUMP_PATH)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "\n",
    "utils.ensure_dir_exists(CACHED_DATASET_DUMP_PATH)\n",
    "print(CACHED_DATASET_DUMP_PATH)\n",
    "\n",
    "merged_datasets = {\n",
    "    training_data_type: dataset.cache(os.path.join(CACHED_DATASET_DUMP_PATH, training_data_type))\n",
    "    for training_data_type, dataset in merged_datasets.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b491f44",
   "metadata": {},
   "source": [
    "### Preloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c881d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_cache(dataset, name: Optional[str] = None):\n",
    "    \"\"\"\n",
    "    Use a benchmark to once process the whole dataset.\n",
    "    \"\"\"\n",
    "    if name is not None:\n",
    "        print(f\"{name}:\")\n",
    "    display(tfds.benchmark(dataset))\n",
    "    gc.collect()\n",
    "    logger.info(\"filled a cache - waiting 10 seconds\")\n",
    "    print()\n",
    "    time.sleep(10)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a7a9729",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not KEEP_CACHE:\n",
    "    merged_datasets = {\n",
    "        training_data_type: fill_cache(dataset, name=training_data_type)\n",
    "        for training_data_type, dataset in merged_datasets.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ee6a5",
   "metadata": {},
   "source": [
    "### Shuffling, Batching, Prefetching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cbc0466",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_datasets = {\n",
    "    training_data_type: dataset\n",
    "        .shuffle(SHUFFLE_BUFFER_SIZE, reshuffle_each_iteration=True)\n",
    "        .batch(BATCH_SIZE, drop_remainder=True)\n",
    "        .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    for training_data_type, dataset in merged_datasets.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7ee8ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_TYPE = 'Train'\n",
    "TEST_TYPE = 'Test'\n",
    "EVAL_TYPE = 'Eval'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-company",
   "metadata": {},
   "source": [
    "## Building the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dress-linux",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mz_array': <KerasTensor: shape=(None, 2354) dtype=float32 (created by layer 'mz_array')>,\n",
       " 'intensity_array': <KerasTensor: shape=(None, 2354) dtype=float32 (created by layer 'intensity_array')>}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_input_layers = {col: tf.keras.layers.Input(shape=(PADDING_LENGTHS[col],), name=col) for col in TRAINING_DATA_COLUMNS}\n",
    "named_input_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d489e61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 2354) dtype=float32 (created by layer 'mz_array')>,\n",
       " <KerasTensor: shape=(None, 2354) dtype=float32 (created by layer 'intensity_array')>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_input_layers_list = [ named_input_layers[col] for col in TRAINING_DATA_COLUMNS ]\n",
    "named_input_layers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "387e127d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mz_array': <KerasTensor: shape=(None, 2354) dtype=float32 (created by layer 'masked_mz_array')>,\n",
       " 'intensity_array': <KerasTensor: shape=(None, 2354) dtype=float32 (created by layer 'masked_intensity_array')>}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_input_layers = {\n",
    "    col: tf.keras.layers.Masking(mask_value=PADDING_CHARACTERS[col], name=f\"masked_{col}\")(input_layer)\n",
    "    for col, input_layer in named_input_layers.items()\n",
    "}\n",
    "masked_input_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14d2218b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 2354) dtype=float32 (created by layer 'masked_mz_array')>,\n",
       " <KerasTensor: shape=(None, 2354) dtype=float32 (created by layer 'masked_intensity_array')>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_input_layers_list = [ masked_input_layers[col] for col in TRAINING_DATA_COLUMNS ]\n",
    "masked_input_layers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "40b0b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedLoss(K.losses.LossFunctionWrapper):\n",
    "    def __init__(self, loss_function, masking_value, name='masked_loss', reduction=tf.keras.losses.Reduction.NONE):\n",
    "        def _masked_loss(y_true, y_pred):\n",
    "            length_mask = tf.equal(y_true, masking_value)\n",
    "            length_mask = tf.cast(length_mask, tf.float32)\n",
    "            length_mask = 1 - length_mask\n",
    "            lengths = tf.math.reduce_sum(length_mask, axis=-1)\n",
    "            lengths = lengths + 1 # to also include the first padding character\n",
    "            mask = tf.sequence_mask(\n",
    "                lengths=lengths,\n",
    "                maxlen=y_pred.shape[-2],  # pre-last dimension = padding length; last dimension = one-hot-encoded alphabet\n",
    "                dtype=tf.float32\n",
    "            )\n",
    "            losses = loss_function(y_true, y_pred) * mask\n",
    "            return tf.math.reduce_sum(losses, axis=-1) / lengths\n",
    "            \n",
    "        super(MaskedLoss, self).__init__(_masked_loss, name=name, reduction=reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03ed2a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_loss = MaskedLoss(\n",
    "    loss_function=tf.keras.losses.sparse_categorical_crossentropy,\n",
    "    masking_value=tf.constant(\n",
    "        value=char_to_idx[PADDING_CHARACTERS[SEQ]],\n",
    "        dtype=tf.int8\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "developmental-geneva",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mmproteo\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "mz_array (InputLayer)           [(None, 2354)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "intensity_array (InputLayer)    [(None, 2354)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masked_mz_array (Masking)       (None, 2354)         0           mz_array[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "masked_intensity_array (Masking (None, 2354)         0           intensity_array[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 2354)         0           masked_mz_array[0][0]            \n",
      "                                                                 masked_intensity_array[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flattened_masked_inputs (Flatte (None, 2354)         0           tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4096)         9646080     flattened_masked_inputs[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4096)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4096)         16781312    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 4096)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1100)         4506700     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (None, 50, 22)       0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_max (TFOpLambda) (None, 50, 1)        0           tf.reshape[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.subtract (TFOpLambda)   (None, 50, 22)       0           tf.reshape[0][0]                 \n",
      "                                                                 tf.math.reduce_max[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.exp (TFOpLambda)        (None, 50, 22)       0           tf.math.subtract[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_sum (TFOpLambda) (None, 50, 1)        0           tf.math.exp[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.truediv (TFOpLambda)    (None, 50, 22)       0           tf.math.exp[0][0]                \n",
      "                                                                 tf.math.reduce_sum[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 30,934,092\n",
      "Trainable params: 30,934,092\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x = masked_input_layers_list[0]\n",
    "for input_layer in masked_input_layers_list[1:]:\n",
    "    x = x + input_layer\n",
    "\n",
    "x = tf.keras.layers.Flatten(name=\"flattened_masked_inputs\")(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    x = tf.keras.layers.Dense(2**12)(x)\n",
    "    x = tf.keras.layers.Dropout(0.1)(x)\n",
    "\n",
    "x = tf.keras.layers.Dense(PADDING_LENGTHS[SEQ]*len(ALPHABET))(x)\n",
    "\n",
    "x = tf.reshape(x,(-1, PADDING_LENGTHS[SEQ], len(ALPHABET)))\n",
    "\n",
    "x = tf.keras.activations.softmax(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=named_input_layers_list, outputs=x, name='mmproteo')\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=masked_loss,\n",
    "              metrics=[\n",
    "                  tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "                  tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "              ]\n",
    "             )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-queue",
   "metadata": {},
   "source": [
    "## Training the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-commons",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " 2136/10000 [=====>........................] - ETA: 1:03 - loss: 15.2946 - sparse_categorical_accuracy: 0.0559 - sparse_categorical_crossentropy: 15.2178"
     ]
    }
   ],
   "source": [
    "model.fit(x=merged_datasets[TRAINING_TYPE],\n",
    "          validation_data=merged_datasets[TEST_TYPE], \n",
    "          validation_steps=500,\n",
    "          epochs=50,\n",
    "          steps_per_epoch=10_000\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-laser",
   "metadata": {},
   "source": [
    "## Evaluating the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "multiple-appendix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21824/21824 [==============================] - 49s 2ms/step - loss: 15.1661 - sparse_categorical_accuracy: 0.0844 - sparse_categorical_crossentropy: 14.7564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15.166107177734375, 0.08441463857889175, 14.756422996520996]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(merged_datasets[EVAL_TYPE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bd6b9861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip(tuple_list: Iterable[Tuple[Any, Any]]) -> Tuple[Iterable[Any], Iterable[Any]]:\n",
    "    return tuple(zip(*tuple_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a30b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_onehot(array: np.ndarray) -> np.ndarray:\n",
    "    return np.argmax(array, axis=-1)\n",
    "\n",
    "decode_idx: Callable[[np.ndarray], np.ndarray] = np.vectorize(idx_to_char.get)\n",
    "\n",
    "def concat_letter_rows(array: np.ndarray) -> np.ndarray:\n",
    "    return np.apply_along_axis(lambda row: ''.join(row), axis=-1, arr=array)\n",
    "\n",
    "def decode(array: np.ndarray, onehot: bool = True):\n",
    "    if onehot:\n",
    "        array = decode_onehot(array)\n",
    "    array = decode_idx(array)\n",
    "    array = concat_letter_rows(array)\n",
    "    if not onehot:\n",
    "        array = np.apply_along_axis(lambda row: row[0], axis=-1, arr=array)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24454d17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TIDRRWLCLFH__EDKGLCAMHEM(Oxidation)NTEPRMKM(Oxidation)W_FEHRKWLFRPEPCDNW</td>\n",
       "      <td>LTQQTLALGQEK______________________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TISSRWLDAEF__ENKA_EPMWYAWVDPGVKTMTFE_NGMDVNIAGM(Oxidation)VAW</td>\n",
       "      <td>VYTFGNGLAEGK______________________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TISSSWLDAEF_QHNQA_EPA_YAWDDPGVVTMTFE_FGHDVICDRPV_M(Oxidation)</td>\n",
       "      <td>DSYVFEDSFHGLQAGR__________________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TISSRWLDAEC__ENKA_M(Oxidation)PMWY_WVIPGVK_MTFE_NGMDVNIAGM(Oxidation)PAW</td>\n",
       "      <td>LAYPIQK___________________________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TISSSWLDAEF__HNQA_EPAWYAWVDPGVKTMTFE_NGMDVIIDGPV_M(Oxidation)</td>\n",
       "      <td>GILQAEGAEIINEENWGLK_______________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TISSSWLDAEF_QHNQA_EPA_YAWDDPGVVTMTFE_FGHDVICDRPV_M(Oxidation)</td>\n",
       "      <td>AMVVVDMPFGSYQGNEM(Oxidation)EGLASAIR______________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TISSRWLCAFH__ETKA_M(Oxidation)PMKYM(Oxidation)_VEPGMK_M_FE_RG_DVREEGCPAV</td>\n",
       "      <td>RCTAFILSDFIDQESFKNAMTIANRKHDVVAIQ_________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TISSRWLCAFH__EDKA_M(Oxidation)PMHYM(Oxidation)_VEPGMK_N_FEKRK_CQREEYCPAV</td>\n",
       "      <td>FLHNRIPVK_________________________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TISSSWLDAEF_YHNQA_EPAWYAWVDPGVKTMTFE_FGMDVIIDGPV_M(Oxidation)</td>\n",
       "      <td>DGFSHLYLYDTNGR____________________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TISSRWLDAEF__ENKA_EPAWYAWVDPGVKTMTFE_NGMDVWIDGM(Oxidation)V_V</td>\n",
       "      <td>SYLDKLGFLEVETPVLIGSTPEGAR_________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TISSRWLCAFH__ETKA_M(Oxidation)PMKYM(Oxidation)_VEPGMK_MQFE_NG_DVREKGCPAW</td>\n",
       "      <td>IMPYWK____________________________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TISSSWLDAEF_YHNQA_EPAWYAWVDPGVKTMTFE_FGMDVIIDGPV_M(Oxidation)</td>\n",
       "      <td>KEDKPEMPMGAPGMGGMGGM(Oxidation)M__________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TISSSWLDAEF_YHNQA_EPAWYAWDDPGVKTMTFE_FGMDVIIDGPV_M(Oxidation)</td>\n",
       "      <td>AESNFVDYVKIYCR____________________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TISSRWLCAFH__ENKA_M(Oxidation)PMKYM(Oxidation)_TIPGMK_MTFE_RGWDVRDPGCPAQ</td>\n",
       "      <td>GLSVAFDLATHR______________________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TISSRWLDAEC__ENKA_M(Oxidation)PMWY_WVIPGVK_MTFE_NGMDVNIAGM(Oxidation)PAW</td>\n",
       "      <td>NVWTVAK___________________________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>TISSSWLDAEF_YHNQA_EPAWYAWVDPGVKTMTFE_FGMDVIIDGPV_M(Oxidation)</td>\n",
       "      <td>ATGAIVSGPIPLPTHKR_________________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>TISSRWLCAFH__EDKA_M(Oxidation)PMHYM(Oxidation)NTEPGMKVN_FEKRK_CFREEGCPNV</td>\n",
       "      <td>LHSDQPNSFAFTPANQAWADAQIAK_________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TISSSWLDAEF_QHNQA_EPAWYAWDDPGVVTMTFW_FGHDVIIDIPV_M(Oxidation)</td>\n",
       "      <td>INEKEMENAYLR______________________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TISSSWLDAEF_YHNQA_EPAWYAWVDPGVKTMTFE_FGMDVIIDGPV_M(Oxidation)</td>\n",
       "      <td>AEEVVLMKGNEAIAHAAIR_______________________________</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>TISSRWLDAEF__ENKA_EPAWYAWVDPGVKTMTFE_NGMDVNIAGM(Oxidation)VAV</td>\n",
       "      <td>HHLSGIR___________________________________________</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   predicted  \\\n",
       "0   TIDRRWLCLFH__EDKGLCAMHEM(Oxidation)NTEPRMKM(Oxidation)W_FEHRKWLFRPEPCDNW   \n",
       "1              TISSRWLDAEF__ENKA_EPMWYAWVDPGVKTMTFE_NGMDVNIAGM(Oxidation)VAW   \n",
       "2              TISSSWLDAEF_QHNQA_EPA_YAWDDPGVVTMTFE_FGHDVICDRPV_M(Oxidation)   \n",
       "3   TISSRWLDAEC__ENKA_M(Oxidation)PMWY_WVIPGVK_MTFE_NGMDVNIAGM(Oxidation)PAW   \n",
       "4              TISSSWLDAEF__HNQA_EPAWYAWVDPGVKTMTFE_NGMDVIIDGPV_M(Oxidation)   \n",
       "5              TISSSWLDAEF_QHNQA_EPA_YAWDDPGVVTMTFE_FGHDVICDRPV_M(Oxidation)   \n",
       "6   TISSRWLCAFH__ETKA_M(Oxidation)PMKYM(Oxidation)_VEPGMK_M_FE_RG_DVREEGCPAV   \n",
       "7   TISSRWLCAFH__EDKA_M(Oxidation)PMHYM(Oxidation)_VEPGMK_N_FEKRK_CQREEYCPAV   \n",
       "8              TISSSWLDAEF_YHNQA_EPAWYAWVDPGVKTMTFE_FGMDVIIDGPV_M(Oxidation)   \n",
       "9              TISSRWLDAEF__ENKA_EPAWYAWVDPGVKTMTFE_NGMDVWIDGM(Oxidation)V_V   \n",
       "10  TISSRWLCAFH__ETKA_M(Oxidation)PMKYM(Oxidation)_VEPGMK_MQFE_NG_DVREKGCPAW   \n",
       "11             TISSSWLDAEF_YHNQA_EPAWYAWVDPGVKTMTFE_FGMDVIIDGPV_M(Oxidation)   \n",
       "12             TISSSWLDAEF_YHNQA_EPAWYAWDDPGVKTMTFE_FGMDVIIDGPV_M(Oxidation)   \n",
       "13  TISSRWLCAFH__ENKA_M(Oxidation)PMKYM(Oxidation)_TIPGMK_MTFE_RGWDVRDPGCPAQ   \n",
       "14  TISSRWLDAEC__ENKA_M(Oxidation)PMWY_WVIPGVK_MTFE_NGMDVNIAGM(Oxidation)PAW   \n",
       "15             TISSSWLDAEF_YHNQA_EPAWYAWVDPGVKTMTFE_FGMDVIIDGPV_M(Oxidation)   \n",
       "16  TISSRWLCAFH__EDKA_M(Oxidation)PMHYM(Oxidation)NTEPGMKVN_FEKRK_CFREEGCPNV   \n",
       "17             TISSSWLDAEF_QHNQA_EPAWYAWDDPGVVTMTFW_FGHDVIIDIPV_M(Oxidation)   \n",
       "18             TISSSWLDAEF_YHNQA_EPAWYAWVDPGVKTMTFE_FGMDVIIDGPV_M(Oxidation)   \n",
       "19             TISSRWLDAEF__ENKA_EPAWYAWVDPGVKTMTFE_NGMDVNIAGM(Oxidation)VAV   \n",
       "\n",
       "                                                  true  \n",
       "0   LTQQTLALGQEK______________________________________  \n",
       "1   VYTFGNGLAEGK______________________________________  \n",
       "2   DSYVFEDSFHGLQAGR__________________________________  \n",
       "3   LAYPIQK___________________________________________  \n",
       "4   GILQAEGAEIINEENWGLK_______________________________  \n",
       "5   AMVVVDMPFGSYQGNEM(Oxidation)EGLASAIR______________  \n",
       "6   RCTAFILSDFIDQESFKNAMTIANRKHDVVAIQ_________________  \n",
       "7   FLHNRIPVK_________________________________________  \n",
       "8   DGFSHLYLYDTNGR____________________________________  \n",
       "9   SYLDKLGFLEVETPVLIGSTPEGAR_________________________  \n",
       "10  IMPYWK____________________________________________  \n",
       "11  KEDKPEMPMGAPGMGGMGGM(Oxidation)M__________________  \n",
       "12  AESNFVDYVKIYCR____________________________________  \n",
       "13  GLSVAFDLATHR______________________________________  \n",
       "14  NVWTVAK___________________________________________  \n",
       "15  ATGAIVSGPIPLPTHKR_________________________________  \n",
       "16  LHSDQPNSFAFTPANQAWADAQIAK_________________________  \n",
       "17  INEKEMENAYLR______________________________________  \n",
       "18  AEEVVLMKGNEAIAHAAIR_______________________________  \n",
       "19  HHLSGIR___________________________________________  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_ds = merged_datasets[EVAL_TYPE].unbatch().batch(1).take(20)\n",
    "\n",
    "x_eval, y_eval = unzip(eval_ds.as_numpy_iterator())\n",
    "y_pred = model.predict(eval_ds)\n",
    "\n",
    "# although the string look like they have different lengths, they all have the same length\n",
    "pd.DataFrame(data=zip(decode(y_pred), decode(y_eval, onehot=False)), columns=['predicted', 'true'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d4b261d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[ 9, 17, 14, 14, 17,  9,  0,  9,  5, 14,  3,  8, 21, 21, 21, 21,\n",
       "          21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "          21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "          21, 21]], dtype=int8),),\n",
       " array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 1., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 1., 0., 0.]]], dtype=float32))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval[:1], y_pred[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7add0bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 9, 17, 14, 14, 17,  9,  0,  9,  5, 14,  3,  8, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[18, 20, 17,  4,  5, 12,  5,  9,  0,  3,  5,  8, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 2, 16, 20, 18,  4,  3,  2, 16,  4,  6,  5,  9, 14,  0,  5, 15,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 9,  0, 20, 13,  7, 14,  8, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 5,  7,  9, 14,  0,  3,  5,  0,  3,  7,  7, 12,  3,  3, 12, 19,\n",
       "          5,  9,  8, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 0, 10, 18, 18, 18,  2, 10, 13,  4,  5, 16, 20, 14,  5, 12,  3,\n",
       "         11,  3,  5,  9,  0, 16,  0,  7, 15, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[15,  1, 17,  0,  4,  7,  9, 16,  2,  4,  7,  2, 14,  3, 16,  4,\n",
       "          8, 12,  0, 10, 17,  7,  0, 12, 15,  8,  6,  2, 18, 18,  0,  7,\n",
       "         14, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 4,  9,  6, 12, 15,  7, 13, 18,  8, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 2,  5,  4, 16,  6,  9, 20,  9, 20,  2, 17, 12,  5, 15, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[16, 20,  9,  2,  8,  9,  5,  4,  9,  3, 18,  3, 17, 13, 18,  9,\n",
       "          7,  5, 16, 17, 13,  3,  5,  0, 15, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 7, 10, 13, 20, 19,  8, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 8,  3,  2,  8, 13,  3, 10, 13, 10,  5,  0, 13,  5, 10,  5,  5,\n",
       "         10,  5,  5, 11, 10, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 0,  3, 16, 12,  4, 18,  2, 20, 18,  8,  7, 20,  1, 15, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 5,  9, 16, 18,  0,  4,  2,  9,  0, 17,  6, 15, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[12, 18, 19, 17, 18,  0,  8, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 0, 17,  5,  0,  7, 18, 16,  5, 13,  7, 13,  9, 13, 17,  6,  8,\n",
       "         15, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 9,  6, 16,  2, 14, 13, 12, 16,  4,  0,  4, 17, 13,  0, 12, 14,\n",
       "          0, 19,  0,  2,  0, 14,  7,  0,  8, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 7, 12,  3,  8,  3, 10,  3, 12,  0, 20,  9, 15, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 0,  3,  3, 18, 18,  9, 10,  8,  5, 12,  3,  0,  7,  0,  6,  0,\n",
       "          0,  7, 15, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8),\n",
       " array([[ 6,  6,  9, 16,  5,  7, 15, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
       "         21, 21]], dtype=int8))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b211fa7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=float32, numpy=array([16.118097], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_loss(y_eval[2], y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6fec0553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20, 20), dtype=float32, numpy=\n",
       "array([[14.878244, 12.398538, 14.878244, 13.638391, 14.878244, 14.878244,\n",
       "        13.638391, 12.398538, 14.878244, 14.878244, 13.638391, 16.118097,\n",
       "        14.878244, 11.158683, 13.638391, 16.118097, 14.878244, 14.878244,\n",
       "        16.118097, 12.398538],\n",
       "       [14.878244, 12.398538, 14.878244, 13.638391, 14.878244, 14.878244,\n",
       "        13.638391, 12.398538, 14.878244, 14.878244, 13.638391, 16.118097,\n",
       "        14.878244, 11.158683, 13.638391, 16.118097, 14.878244, 14.878244,\n",
       "        16.118097, 12.398538],\n",
       "       [15.169974, 13.273728, 15.169974, 14.221851, 14.221851, 14.221851,\n",
       "        13.273728, 13.273728, 15.169974, 15.169974, 14.221851, 16.118097,\n",
       "        15.169974, 12.325604, 14.221851, 16.118097, 14.22185 , 15.169974,\n",
       "        15.169974, 13.273728],\n",
       "       [16.118097, 16.118097, 16.118097, 16.118097, 14.103335, 16.118097,\n",
       "        14.103335, 14.103335, 14.103335, 16.118097, 16.118097, 16.118097,\n",
       "        14.103335, 14.103335, 16.118097, 16.118097, 14.103335, 16.118097,\n",
       "        16.118097, 14.103335],\n",
       "       [15.312192, 12.89448 , 14.506287, 13.700383, 14.506289, 14.506289,\n",
       "        13.700383, 12.89448 , 14.506287, 15.312192, 13.700383, 16.118097,\n",
       "        14.506287, 12.088573, 13.700383, 15.312192, 14.506287, 14.506287,\n",
       "        15.312192, 12.89448 ],\n",
       "       [15.49817 , 13.638391, 14.258317, 13.638391, 14.878244, 14.258317,\n",
       "        14.258317, 13.018463, 14.878244, 14.878244, 13.638391, 16.118097,\n",
       "        14.878244, 12.398536, 13.638391, 15.498171, 14.878244, 14.878244,\n",
       "        15.498171, 13.638391],\n",
       "       [15.169974, 14.22185 , 14.695912, 13.747789, 15.169974, 14.695912,\n",
       "        14.22185 , 12.799666, 15.169972, 15.169974, 13.747789, 16.118095,\n",
       "        15.169972, 12.799665, 13.747789, 15.644035, 14.695913, 15.169974,\n",
       "        15.644035, 14.22185 ],\n",
       "       [16.118097, 12.894478, 16.118097, 16.118097, 14.506289, 16.118097,\n",
       "        12.894478, 14.506289, 14.506289, 14.506289, 16.118097, 16.118097,\n",
       "        14.506289, 12.894478, 16.118097, 16.118097, 14.506289, 14.506289,\n",
       "        16.118097, 14.506289],\n",
       "       [15.043558, 12.894479, 15.043558, 13.969019, 13.969019, 13.969019,\n",
       "        12.894479, 12.894479, 15.043558, 15.043558, 13.969019, 16.118097,\n",
       "        15.043558, 11.819938, 13.969019, 16.118097, 15.043558, 15.043558,\n",
       "        16.118097, 12.894479],\n",
       "       [15.49817 , 13.638391, 14.258317, 13.638391, 14.878244, 14.258317,\n",
       "        14.258317, 13.018463, 14.878244, 14.878244, 13.638391, 16.118097,\n",
       "        14.878244, 12.398536, 13.638391, 15.498171, 14.878244, 14.878244,\n",
       "        15.498171, 13.638391],\n",
       "       [16.118097, 16.118097, 16.118097, 16.118097, 13.815513, 16.118097,\n",
       "        13.815513, 13.815513, 13.815513, 16.118097, 16.118097, 16.118097,\n",
       "        13.815513, 13.815513, 16.118097, 16.118097, 13.815513, 16.118097,\n",
       "        16.118097, 13.815513],\n",
       "       [15.385456, 13.187534, 13.920175, 13.920175, 14.652816, 13.920175,\n",
       "        13.920176, 13.187534, 14.652816, 15.385456, 13.920175, 16.118097,\n",
       "        14.652816, 12.454894, 13.920175, 15.385456, 14.652816, 14.652816,\n",
       "        15.385456, 13.187534],\n",
       "       [15.043558, 12.894479, 15.043558, 13.969019, 13.969019, 13.969019,\n",
       "        12.894479, 12.894479, 15.043558, 15.043558, 13.969019, 16.118097,\n",
       "        15.043558, 11.819938, 13.969019, 16.118097, 15.043558, 15.043558,\n",
       "        16.118097, 12.894479],\n",
       "       [14.878244, 12.398538, 14.878244, 13.638391, 14.878244, 14.878244,\n",
       "        13.638391, 12.398538, 14.878244, 14.878244, 13.638391, 16.118097,\n",
       "        14.878244, 11.158683, 13.638391, 16.118097, 14.878244, 14.878244,\n",
       "        16.118097, 12.398538],\n",
       "       [16.118097, 16.118097, 16.118097, 16.118097, 14.103335, 16.118097,\n",
       "        14.103335, 14.103335, 14.103335, 16.118097, 16.118097, 16.118097,\n",
       "        14.103335, 14.103335, 16.118097, 16.118097, 14.103335, 16.118097,\n",
       "        16.118097, 14.103335],\n",
       "       [15.222648, 12.536299, 14.327198, 13.431748, 14.327198, 14.327198,\n",
       "        13.431748, 12.536299, 14.327198, 15.222648, 13.431748, 16.118097,\n",
       "        14.327198, 11.640849, 13.431748, 15.222648, 14.327198, 14.327198,\n",
       "        15.222648, 12.536299],\n",
       "       [15.49817 , 13.638391, 14.258317, 13.638391, 14.878244, 14.258317,\n",
       "        14.258317, 13.018463, 14.878244, 14.878244, 13.638391, 16.118097,\n",
       "        14.878244, 12.398536, 13.638391, 15.498171, 14.878244, 14.878244,\n",
       "        15.498171, 13.638391],\n",
       "       [14.878244, 12.398538, 14.878244, 13.638391, 14.878244, 14.878244,\n",
       "        13.638391, 12.398538, 14.878244, 14.878244, 13.638391, 16.118097,\n",
       "        14.878244, 11.158683, 13.638391, 16.118097, 14.878244, 14.878244,\n",
       "        16.118097, 12.398538],\n",
       "       [15.312192, 12.89448 , 14.506287, 13.700383, 14.506289, 14.506289,\n",
       "        13.700383, 12.89448 , 14.506287, 15.312192, 13.700383, 16.118097,\n",
       "        14.506287, 12.088573, 13.700383, 15.312192, 14.506287, 14.506287,\n",
       "        15.312192, 12.89448 ],\n",
       "       [16.118097, 16.118097, 16.118097, 16.118097, 14.103335, 16.118097,\n",
       "        14.103335, 14.103335, 14.103335, 16.118097, 16.118097, 16.118097,\n",
       "        14.103335, 14.103335, 16.118097, 16.118097, 14.103335, 16.118097,\n",
       "        16.118097, 14.103335]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_loss.fn(y_eval, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239093ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lovely-landing",
   "metadata": {},
   "source": [
    "# Training an Attention Model on Tensorflow Datasets\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worth-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Any, Callable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from IPython.core.display import display\n",
    "from mmproteo.utils import log, paths, utils, visualization\n",
    "from mmproteo.utils.formats.tf_dataset import DatasetLoader\n",
    "from mmproteo.utils.ml import callbacks, evaluation\n",
    "from official.modeling import tf_utils\n",
    "from official.nlp.modeling.models.seq2seq_transformer import Seq2SeqTransformer, TransformerDecoder, TransformerEncoder\n",
    "from official.nlp.modeling.ops import beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "circular-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "certified-gibson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Printing to Stdout\n"
     ]
    }
   ],
   "source": [
    "logger = log.DummyLogger(verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-playlist",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "norwegian-therapist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/workspace/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deed6b25",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if os.getcwd() == \"/tf\":\n",
    "    os.chdir(os.path.join('workspace', 'notebooks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "987d32ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/workspace/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "genuine-dealing",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"PXD010000\"\n",
    "DUMP_PATH = os.path.join(\"..\", \"dumps\", PROJECT)\n",
    "TRAINING_COLUMNS_DUMP_PATH = os.path.join(DUMP_PATH, \"training_columns\")\n",
    "FILES_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"*_mzmlid.parquet\")\n",
    "STATISTICS_FILE_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"statistics.parquet\")\n",
    "DATASET_DUMP_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"tf_datasets\")\n",
    "PROCESSING_FILE_PATH = os.path.join(DATASET_DUMP_PATH, \"processing_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "interesting-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ = 'peptide_sequence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c29d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'padding_characters': {'peptide_sequence': '_',\n",
       "  'mz_array': 0.0,\n",
       "  'intensity_array': 0.0},\n",
       " 'padding_lengths': {'mz_array': 2354,\n",
       "  'intensity_array': 2354,\n",
       "  'peptide_sequence': 50},\n",
       " 'idx_to_char': {'0': 'A',\n",
       "  '1': 'C',\n",
       "  '2': 'D',\n",
       "  '3': 'E',\n",
       "  '4': 'F',\n",
       "  '5': 'G',\n",
       "  '6': 'H',\n",
       "  '7': 'I',\n",
       "  '8': 'K',\n",
       "  '9': 'L',\n",
       "  '10': 'M',\n",
       "  '11': 'M(Oxidation)',\n",
       "  '12': 'N',\n",
       "  '13': 'P',\n",
       "  '14': 'Q',\n",
       "  '15': 'R',\n",
       "  '16': 'S',\n",
       "  '17': 'T',\n",
       "  '18': 'V',\n",
       "  '19': 'W',\n",
       "  '20': 'Y',\n",
       "  '21': '_'},\n",
       " 'normalization': {'intensity_array': '<function base_peak_normalize at 0x7fa6046d5158>'},\n",
       " 'split_value_columns': ['species', 'istrain'],\n",
       " 'training_data_columns': ['mz_array', 'intensity_array'],\n",
       " 'target_data_columns': ['peptide_sequence']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(PROCESSING_FILE_PATH, 'r') as file:\n",
    "    PROCESSING_INFO = json.loads(file.read())\n",
    "PROCESSING_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73a1f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_char = {int(idx): char for idx, char in PROCESSING_INFO[\"idx_to_char\"].items()}\n",
    "idx_to_char[-1] = \"[start]\"\n",
    "char_to_idx = {char: idx for idx, char in idx_to_char.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-proceeding",
   "metadata": {},
   "source": [
    "## Loading Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee8aadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_CACHE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ee8ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_TYPE = 'Train'\n",
    "TEST_TYPE = 'Test'\n",
    "EVAL_TYPE = 'Eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d696d51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: found file paths dump '../dumps/PXD010000/training_columns/tf_datasets/dataset_file_paths.json'\n",
      "\n",
      "assigned dataset files:\n",
      "#Train = 89\n",
      "e.g.: ../dumps/PXD010000/training_columns/tf_datasets/Biodiversity_C_indologenes_LIB_aerobic_02_03May16_Samwise_16-03-32_mzmlid.parquet/Chryseobacterium_indologenes/Train\n",
      "#Test = 17\n",
      "e.g.: ../dumps/PXD010000/training_columns/tf_datasets/Biodiversity_A_cryptum_FeTSB_anaerobic_1_01Jun16_Pippin_16-03-39_mzmlid.parquet/Acidiphilium_cryptum_JF-5/Train\n",
      "#Eval = 29\n",
      "e.g.: ../dumps/PXD010000/training_columns/tf_datasets/Biodiversity_B_fragilis_CMcarb_anaerobic_01_01Feb16_Arwen_15-07-13_mzmlid.parquet/Bacteroides_fragilis_638R/Train\n"
     ]
    }
   ],
   "source": [
    "dataset_file_paths = paths.assign_wildcard_paths_to_splits_grouped_by_path_position_value(\n",
    "    wildcard_path=os.path.join(\n",
    "        DATASET_DUMP_PATH,\n",
    "        '*',  # filename\n",
    "        '*',  # species\n",
    "        '*'  # istrain\n",
    "    ),\n",
    "    path_position=-2,\n",
    "    splits={\n",
    "        TRAINING_TYPE: 0.4,\n",
    "        TEST_TYPE: 0.5,\n",
    "        EVAL_TYPE: 0.6\n",
    "    },\n",
    "    paths_dump_file=os.path.join(\n",
    "        DATASET_DUMP_PATH,\n",
    "        \"dataset_file_paths.json\"\n",
    "    ),\n",
    "    skip_existing=KEEP_CACHE,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"assigned dataset files:\")\n",
    "visualization.print_list_length_in_dict(dataset_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec611252",
   "metadata": {},
   "source": [
    "### Loading corresponding TF datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0d829d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(2354,), dtype=tf.float32, name='mz_array'),\n",
       "  TensorSpec(shape=(2354,), dtype=tf.float32, name='intensity_array')),\n",
       " (TensorSpec(shape=(50,), dtype=tf.int8, name='peptide_sequence'),))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_spec = (\n",
    "    tuple(tf.TensorSpec(shape=(PROCESSING_INFO['padding_lengths'][col],), dtype=tf.float32, name=col)\n",
    "          for col in PROCESSING_INFO['training_data_columns']),\n",
    "    tuple(tf.TensorSpec(shape=(PROCESSING_INFO['padding_lengths'][col],), dtype=tf.int8, name=col)\n",
    "          for col in PROCESSING_INFO['target_data_columns'])\n",
    ")\n",
    "element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b34d7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbef3700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:1640: UserWarning: The `deterministic` argument has no effect unless the `num_parallel_calls` argument is specified.\n",
      "  warnings.warn(\"The `deterministic` argument has no effect unless the \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Train': <BatchDataset shapes: (((16, 2354), (16, 2354)), ((16, 50),)), types: ((tf.float32, tf.float32), (tf.int8,))>,\n",
       " 'Test': <BatchDataset shapes: (((16, 2354), (16, 2354)), ((16, 50),)), types: ((tf.float32, tf.float32), (tf.int8,))>,\n",
       " 'Eval': <BatchDataset shapes: (((16, 2354), (16, 2354)), ((16, 50),)), types: ((tf.float32, tf.float32), (tf.int8,))>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = DatasetLoader(\n",
    "    element_spec=element_spec,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle_buffer_size=100_000,\n",
    "    keep_cache=KEEP_CACHE,\n",
    "    logger=logger\n",
    ").load_datasets_by_type(dataset_file_paths)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1372f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_datasets = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eb0f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_target_sequences_with_start_token(tensor: tf.Tensor, token: Any = char_to_idx[\"[start]\"]) -> tf.Tensor:\n",
    "    return tf.concat(\n",
    "        values=[\n",
    "            tf.broadcast_to(\n",
    "                input=tf.constant(token, dtype=tensor.dtype),\n",
    "                shape=(\n",
    "                    tensor.shape[0],  # batch dimension\n",
    "                    1\n",
    "                )\n",
    "            ),\n",
    "            tensor\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "def _dataset_mapper_for_transformer(trainings: Tuple[tf.Tensor], targets: Tuple[tf.Tensor]):\n",
    "    inputs = tf.stack(trainings, axis=-1)\n",
    "    targets = prefix_target_sequences_with_start_token(targets[0])\n",
    "    targets = tf.cast(\n",
    "        x=targets,\n",
    "        dtype=tf.int32,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        {\n",
    "            \"inputs\": inputs,\n",
    "            \"targets\": targets[:, :-1],\n",
    "        },\n",
    "        targets[:, 1:]\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_dataset_for_transformer_training(dataset: tf.data.Dataset) -> tf.data.Dataset:\n",
    "    return dataset.map(_dataset_mapper_for_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a08cd1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train': <MapDataset shapes: ({inputs: (16, 2354, 2), targets: (16, 50)}, (16, 50)), types: ({inputs: tf.float32, targets: tf.int32}, tf.int32)>,\n",
       " 'Test': <MapDataset shapes: ({inputs: (16, 2354, 2), targets: (16, 50)}, (16, 50)), types: ({inputs: tf.float32, targets: tf.int32}, tf.int32)>,\n",
       " 'Eval': <MapDataset shapes: ({inputs: (16, 2354, 2), targets: (16, 50)}, (16, 50)), types: ({inputs: tf.float32, targets: tf.int32}, tf.int32)>}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {\n",
    "    t: prepare_dataset_for_transformer_training(dataset) for t, dataset in original_datasets.items()\n",
    "}\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "767ec869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original datasets:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "433ed603925d419f81f66c3031be8c52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Summary ************\n",
      "\n",
      "Examples/sec (First included) 2668.06 ex/sec (total: 21833 ex, 8.18 sec)\n",
      "Examples/sec (First only) 0.74 ex/sec (total: 1 ex, 1.35 sec)\n",
      "Examples/sec (First excluded) 3195.21 ex/sec (total: 21832 ex, 6.83 sec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>BenchmarkResult:</strong><br/><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first+lasts</th>\n",
       "      <td>8.183097</td>\n",
       "      <td>21833</td>\n",
       "      <td>2668.060664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>1.350378</td>\n",
       "      <td>1</td>\n",
       "      <td>0.740533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasts</th>\n",
       "      <td>6.832719</td>\n",
       "      <td>21832</td>\n",
       "      <td>3195.213959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BenchmarkResult(stats=             duration  num_examples          avg\n",
       "first+lasts  8.183097         21833  2668.060664\n",
       "first        1.350378             1     0.740533\n",
       "lasts        6.832719         21832  3195.213959, raw_stats=                      duration\n",
       "start_time        27617.335056\n",
       "first_batch_time  27618.685434\n",
       "end_time          27625.518153\n",
       "num_iter          21833.000000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mapped datasets:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc9bdf4393044e9bda951feb874b853",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Summary ************\n",
      "\n",
      "Examples/sec (First included) 2664.78 ex/sec (total: 21833 ex, 8.19 sec)\n",
      "Examples/sec (First only) 0.80 ex/sec (total: 1 ex, 1.25 sec)\n",
      "Examples/sec (First excluded) 3145.51 ex/sec (total: 21832 ex, 6.94 sec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>BenchmarkResult:</strong><br/><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first+lasts</th>\n",
       "      <td>8.193157</td>\n",
       "      <td>21833</td>\n",
       "      <td>2664.784709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>1.252478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasts</th>\n",
       "      <td>6.940679</td>\n",
       "      <td>21832</td>\n",
       "      <td>3145.513640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BenchmarkResult(stats=             duration  num_examples          avg\n",
       "first+lasts  8.193157         21833  2664.784709\n",
       "first        1.252478             1     0.798417\n",
       "lasts        6.940679         21832  3145.513640, raw_stats=                      duration\n",
       "start_time        27625.531118\n",
       "first_batch_time  27626.783596\n",
       "end_time          27633.724275\n",
       "num_iter          21833.000000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"original datasets:\")\n",
    "display(tfds.benchmark(original_datasets[TEST_TYPE]))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"mapped datasets:\")\n",
    "display(tfds.benchmark(datasets[TEST_TYPE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-company",
   "metadata": {},
   "source": [
    "## Building the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce6bb7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heavily based on:\n",
    "# https://github.com/tensorflow/models/blob/061c58a3937953c79819fd4e8826af1570cb6024/official/nlp/transformer/transformer.py\n",
    "# (29.06.2021)\n",
    "class MyTransformer(Seq2SeqTransformer):\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Calculate target logits or inferred target sequences.\n",
    "        Args:\n",
    "          inputs: a dictionary of tensors.\n",
    "            Feature `inputs`: int tensor with shape `[batch_size, input_length]`.\n",
    "            Feature `targets` (optional): None or int tensor with shape\n",
    "              `[batch_size, target_length]`.\n",
    "        Returns:\n",
    "          If targets is defined, then return logits for each word in the target\n",
    "          sequence, which is a float tensor with shape\n",
    "          `(batch_size, target_length, vocab_size)`. If target is `None`, then\n",
    "          generate output sequence one token at a time and\n",
    "          returns a dictionary {\n",
    "              outputs: `(batch_size, decoded_length)`\n",
    "              scores: `(batch_size, 1)`}\n",
    "          Even when `float16` is used, the output tensor(s) are always `float32`.\n",
    "        Raises:\n",
    "          NotImplementedError: If try to use padded decode method on CPU/GPUs.\n",
    "        \"\"\"\n",
    "        sources = inputs[\"inputs\"]\n",
    "        targets = inputs.get(\"targets\", None)\n",
    "        # Prepare inputs to the layer stack by adding positional encodings and\n",
    "        # applying dropout.\n",
    "\n",
    "        # Attention_mask generation.\n",
    "        input_shape = tf_utils.get_shape_list(sources, expected_rank=3)\n",
    "        batch_size = input_shape[0]\n",
    "        input_length = input_shape[1]\n",
    "        channel_count = input_shape[2]\n",
    "        non_padding_sources = tf.not_equal(sources[:, :, 0], 0.0)\n",
    "        non_padding_sources = tf.reshape(\n",
    "            tensor=non_padding_sources,\n",
    "            shape=[batch_size, 1, input_length]\n",
    "        )\n",
    "        attention_mask = tf.cast(\n",
    "            x=non_padding_sources,\n",
    "            dtype=sources.dtype\n",
    "        )\n",
    "        broadcast_ones = tf.ones(\n",
    "            shape=[batch_size, input_length, 1],\n",
    "            dtype=sources.dtype\n",
    "        )\n",
    "        attention_mask = broadcast_ones * attention_mask\n",
    "\n",
    "        pos_encoding = self.position_embedding(sources)\n",
    "        pos_encoding = tf.cast(pos_encoding, sources.dtype)\n",
    "        encoder_inputs = sources + pos_encoding\n",
    "\n",
    "        encoder_inputs = self.encoder_dropout(encoder_inputs)\n",
    "\n",
    "        encoder_outputs = self.encoder_layer(\n",
    "            encoder_inputs, attention_mask=attention_mask)\n",
    "\n",
    "        if targets is None:\n",
    "            if self._padded_decode:\n",
    "                max_decode_length = self._decode_max_length\n",
    "            else:\n",
    "                max_decode_length = self._decode_max_length or (\n",
    "                        tf.shape(encoder_outputs)[1] + self._extra_decode_length)\n",
    "            symbols_to_logits_fn = self._get_symbols_to_logits_fn(max_decode_length)\n",
    "\n",
    "            batch_size = tf.shape(encoder_outputs)[0]\n",
    "            # Create initial set of IDs that will be passed to symbols_to_logits_fn.\n",
    "            initial_ids = tf.zeros([batch_size], dtype=tf.int32)\n",
    "\n",
    "            # Create cache storing decoder attention values for each layer.\n",
    "            init_decode_length = (max_decode_length if self._padded_decode else 0)\n",
    "            num_heads = self.decoder_layer.num_attention_heads\n",
    "            dim_per_head = self._embedding_width // num_heads\n",
    "\n",
    "            # Cache dtype needs to match beam_search dtype.\n",
    "            # pylint: disable=g-complex-comprehension\n",
    "            cache = {\n",
    "                str(layer): {\n",
    "                    \"key\":\n",
    "                        tf.zeros(\n",
    "                            [batch_size, init_decode_length, num_heads, dim_per_head],\n",
    "                            dtype=self.compute_dtype),\n",
    "                    \"value\":\n",
    "                        tf.zeros(\n",
    "                            [batch_size, init_decode_length, num_heads, dim_per_head],\n",
    "                            dtype=self.compute_dtype)\n",
    "                } for layer in range(self.decoder_layer.num_layers)\n",
    "            }\n",
    "            # pylint: enable=g-complex-comprehension\n",
    "\n",
    "            # Add encoder output and attention bias to the cache.\n",
    "            encoder_outputs = tf.cast(encoder_outputs, dtype=self.compute_dtype)\n",
    "            attention_mask = tf.cast(\n",
    "                tf.reshape(\n",
    "                    tf.not_equal(sources, 0), [input_shape[0], 1, input_shape[1]]),\n",
    "                dtype=self.compute_dtype)\n",
    "            cache[\"encoder_outputs\"] = encoder_outputs\n",
    "            cache[\"encoder_decoder_attention_mask\"] = attention_mask\n",
    "\n",
    "            # Use beam search to find the top beam_size sequences and scores.\n",
    "            decoded_ids, scores = beam_search.sequence_beam_search(\n",
    "                symbols_to_logits_fn=symbols_to_logits_fn,\n",
    "                initial_ids=initial_ids,\n",
    "                initial_cache=cache,\n",
    "                vocab_size=self._vocab_size,\n",
    "                beam_size=self._beam_size,\n",
    "                alpha=self._alpha,\n",
    "                max_decode_length=max_decode_length,\n",
    "                eos_id=self._eos_id,\n",
    "                padded_decode=self._padded_decode,\n",
    "                dtype=self.compute_dtype)\n",
    "\n",
    "            # Get the top sequence for each batch element\n",
    "            top_decoded_ids = decoded_ids[:, 0, 1:]\n",
    "            top_scores = scores[:, 0]\n",
    "\n",
    "            return {\"outputs\": top_decoded_ids, \"scores\": top_scores}\n",
    "\n",
    "        decoder_inputs = self.embedding_lookup(targets)\n",
    "        embedding_mask = tf.cast(tf.not_equal(targets, 0), decoder_inputs.dtype)\n",
    "        decoder_inputs *= tf.expand_dims(embedding_mask, -1)\n",
    "        # Shift targets to the right, and remove the last element\n",
    "        decoder_inputs = tf.pad(decoder_inputs, [[0, 0], [1, 0], [0, 0]])[:, :-1, :]\n",
    "        length = tf.shape(decoder_inputs)[1]\n",
    "        pos_encoding = self.position_embedding(decoder_inputs)\n",
    "        pos_encoding = tf.cast(pos_encoding, decoder_inputs.dtype)\n",
    "        decoder_inputs += pos_encoding\n",
    "\n",
    "        decoder_inputs = self.decoder_dropout(decoder_inputs)\n",
    "\n",
    "        decoder_shape = tf_utils.get_shape_list(decoder_inputs, expected_rank=3)\n",
    "        batch_size = decoder_shape[0]\n",
    "        decoder_length = decoder_shape[1]\n",
    "\n",
    "        self_attention_mask = tf.linalg.band_part(tf.ones([length, length]), -1, 0)\n",
    "        self_attention_mask = tf.reshape(self_attention_mask, [1, length, length])\n",
    "        self_attention_mask = tf.tile(self_attention_mask, [batch_size, 1, 1])\n",
    "\n",
    "        attention_mask = tf.cast(\n",
    "            tf.expand_dims(tf.not_equal(sources[:, :, 0], 0), axis=1), dtype=sources.dtype)\n",
    "        attention_mask = tf.tile(attention_mask, [1, decoder_length, 1])\n",
    "\n",
    "        outputs = self.decoder_layer(\n",
    "            decoder_inputs,\n",
    "            encoder_outputs,\n",
    "            memory_mask=self_attention_mask,\n",
    "            target_mask=attention_mask)\n",
    "        logits = self._embedding_linear(self.embedding_lookup.embeddings, outputs)\n",
    "        # Model outputs should be float32 to avoid numeric issues.\n",
    "        # https://www.tensorflow.org/guide/mixed_precision#building_the_model\n",
    "        logits = tf.cast(logits, tf.float32)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96a40234",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "TRANSFORMER_LAYERS = 4\n",
    "\n",
    "encoder_layer = TransformerEncoder(\n",
    "    num_attention_heads=2,\n",
    "    num_layers=TRANSFORMER_LAYERS,\n",
    ")\n",
    "decoder_layer = TransformerDecoder(\n",
    "    num_attention_heads=2,\n",
    "    num_layers=TRANSFORMER_LAYERS,\n",
    ")\n",
    "\n",
    "model = MyTransformer(\n",
    "    vocab_size=len(idx_to_char),\n",
    "    embedding_width=len(PROCESSING_INFO['training_data_columns']),\n",
    "    encoder_layer=encoder_layer,\n",
    "    decoder_layer=decoder_layer,\n",
    "    name=f\"mmproteo_transformer_{utils.get_current_time_str()}\"\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),  #masked_loss,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "        tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06d6ea94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "1/1 [==============================] - 8s 8s/step - loss: nan - sparse_categorical_accuracy: 0.0550 - sparse_categorical_crossentropy: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8a445ec438>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to define an input for the model because of a missing input layer\n",
    "model.fit(\n",
    "    x=datasets[TRAINING_TYPE].repeat(),\n",
    "    epochs=1,\n",
    "    steps_per_epoch=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "456b69eb",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../dumps/PXD010000/models/mmproteo_transformer_20210630-134317'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = os.path.join(DUMP_PATH, \"models\", model.name)\n",
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5481a85",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "utils.ensure_dir_exists(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04bbca25",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model=model,\n",
    "    to_file=os.path.join(MODEL_PATH, \"model.png\"),\n",
    "    show_shapes=True,\n",
    "    expand_nested=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd410eda",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mmproteo_transformer_20210630-134317\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "on_device_embedding (OnDevic multiple                  46        \n",
      "_________________________________________________________________\n",
      "transformer_encoder (Transfo multiple                  41068     \n",
      "_________________________________________________________________\n",
      "transformer_decoder (Transfo multiple                  41148     \n",
      "_________________________________________________________________\n",
      "relative_position_embedding  multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 82,262\n",
      "Trainable params: 82,262\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(MODEL_PATH, \"summary.txt\"), 'w') as file:\n",
    "    def write_lines(line: str) -> None:\n",
    "        file.write(line)\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "\n",
    "    model.summary(print_fn=write_lines)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2842ef24",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not implemented\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(os.path.join(MODEL_PATH, \"model.json\"), 'w') as file:\n",
    "        file.write(model.to_json())\n",
    "\n",
    "    with open(os.path.join(MODEL_PATH, \"model.yaml\"), 'w') as file:\n",
    "        file.write(model.to_yaml())\n",
    "except NotImplementedError as e:\n",
    "    print(\"not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-queue",
   "metadata": {},
   "source": [
    "## Training the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "630d443e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05152e65",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tf/workspace/dumps/PXD010000/models/mmproteo_transformer_20210630-134317/tensorboard'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSORBOARD_LOG_DIR = os.path.join(MODEL_PATH, \"tensorboard\")\n",
    "os.path.realpath(TENSORBOARD_LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe45638f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-cb215268b7169c64\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-cb215268b7169c64\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $TENSORBOARD_LOG_DIR --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "funded-commons",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 56s 544ms/step - loss: nan - sparse_categorical_accuracy: 0.0320 - sparse_categorical_crossentropy: nan - val_loss: nan - val_sparse_categorical_accuracy: 0.0284 - val_sparse_categorical_crossentropy: nan\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Nan in summary histogram for: mmproteo_transformer_20210630-134317/on_device_embedding/embeddings_0 [Op:WriteHistogramSummary]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidArgumentError\u001B[0m                      Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-32-a4eccffc513a>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m               \u001B[0mcheckpoints\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     12\u001B[0m               \u001B[0mcsv\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m               \u001B[0mbase_path\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mMODEL_PATH\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m           )\n\u001B[1;32m     15\u001B[0m       )\n",
      "\u001B[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1227\u001B[0m           \u001B[0mepoch_logs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mval_logs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1228\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1229\u001B[0;31m         \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_epoch_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch_logs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1230\u001B[0m         \u001B[0mtraining_logs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mepoch_logs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1231\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstop_training\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001B[0m in \u001B[0;36mon_epoch_end\u001B[0;34m(self, epoch, logs)\u001B[0m\n\u001B[1;32m    433\u001B[0m     \u001B[0mlogs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_process_logs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    434\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mcallback\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcallbacks\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 435\u001B[0;31m       \u001B[0mcallback\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_epoch_end\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    436\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    437\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mon_train_batch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlogs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001B[0m in \u001B[0;36mon_epoch_end\u001B[0;34m(self, epoch, logs)\u001B[0m\n\u001B[1;32m   2437\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2438\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhistogram_freq\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhistogram_freq\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2439\u001B[0;31m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_log_weights\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2440\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2441\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membeddings_freq\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mepoch\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membeddings_freq\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001B[0m in \u001B[0;36m_log_weights\u001B[0;34m(self, epoch)\u001B[0m\n\u001B[1;32m   2504\u001B[0m           \u001B[0;32mfor\u001B[0m \u001B[0mweight\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweights\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2505\u001B[0m             \u001B[0mweight_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreplace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m':'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'_'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2506\u001B[0;31m             \u001B[0msummary_ops_v2\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhistogram\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2507\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwrite_images\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2508\u001B[0m               \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_log_weight_as_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mweight_name\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py\u001B[0m in \u001B[0;36mhistogram\u001B[0;34m(name, tensor, family, step)\u001B[0m\n\u001B[1;32m    877\u001B[0m         name=scope)\n\u001B[1;32m    878\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 879\u001B[0;31m   \u001B[0;32mreturn\u001B[0m \u001B[0msummary_writer_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfamily\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfamily\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    880\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    881\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py\u001B[0m in \u001B[0;36msummary_writer_function\u001B[0;34m(name, tensor, function, family)\u001B[0m\n\u001B[1;32m    806\u001B[0m   \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"cpu:0\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    807\u001B[0m     op = smart_cond.smart_cond(\n\u001B[0;32m--> 808\u001B[0;31m         should_record_summaries(), record, _nothing, name=\"\")\n\u001B[0m\u001B[1;32m    809\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    810\u001B[0m       \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_to_collection\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mGraphKeys\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_SUMMARY_COLLECTION\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/smart_cond.py\u001B[0m in \u001B[0;36msmart_cond\u001B[0;34m(pred, true_fn, false_fn, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0mpred_value\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mpred_value\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 54\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtrue_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     55\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     56\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mfalse_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py\u001B[0m in \u001B[0;36mrecord\u001B[0;34m()\u001B[0m\n\u001B[1;32m    799\u001B[0m     with ops.name_scope(name_scope), summary_op_util.summary_scope(\n\u001B[1;32m    800\u001B[0m         name, family, values=[tensor]) as (tag, scope):\n\u001B[0;32m--> 801\u001B[0;31m       \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcontrol_dependencies\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mfunction\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtag\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscope\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    802\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mconstant_op\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconstant\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    803\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py\u001B[0m in \u001B[0;36mfunction\u001B[0;34m(tag, scope)\u001B[0m\n\u001B[1;32m    875\u001B[0m         \u001B[0mtag\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    876\u001B[0m         \u001B[0marray_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0midentity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 877\u001B[0;31m         name=scope)\n\u001B[0m\u001B[1;32m    878\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    879\u001B[0m   \u001B[0;32mreturn\u001B[0m \u001B[0msummary_writer_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfunction\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfamily\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfamily\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_summary_ops.py\u001B[0m in \u001B[0;36mwrite_histogram_summary\u001B[0;34m(writer, step, tag, values, name)\u001B[0m\n\u001B[1;32m    478\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    479\u001B[0m       return write_histogram_summary_eager_fallback(\n\u001B[0;32m--> 480\u001B[0;31m           writer, step, tag, values, name=name, ctx=_ctx)\n\u001B[0m\u001B[1;32m    481\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_SymbolicException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    482\u001B[0m       \u001B[0;32mpass\u001B[0m  \u001B[0;31m# Add nodes to the TensorFlow graph.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_summary_ops.py\u001B[0m in \u001B[0;36mwrite_histogram_summary_eager_fallback\u001B[0;34m(writer, step, tag, values, name, ctx)\u001B[0m\n\u001B[1;32m    497\u001B[0m   \u001B[0m_attrs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\"T\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0m_attr_T\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    498\u001B[0m   _result = _execute.execute(b\"WriteHistogramSummary\", 0, inputs=_inputs_flat,\n\u001B[0;32m--> 499\u001B[0;31m                              attrs=_attrs, ctx=ctx, name=name)\n\u001B[0m\u001B[1;32m    500\u001B[0m   \u001B[0m_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    501\u001B[0m   \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0;32m---> 60\u001B[0;31m                                         inputs, attrs, num_outputs)\n\u001B[0m\u001B[1;32m     61\u001B[0m   \u001B[0;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mInvalidArgumentError\u001B[0m: Nan in summary histogram for: mmproteo_transformer_20210630-134317/on_device_embedding/embeddings_0 [Op:WriteHistogramSummary]"
     ]
    }
   ],
   "source": [
    "model.fit(x=datasets[TRAINING_TYPE].repeat(),\n",
    "          validation_data=datasets[TEST_TYPE].repeat(),\n",
    "          validation_steps=50,\n",
    "          epochs=100,\n",
    "          steps_per_epoch=100,\n",
    "          callbacks=callbacks.create_callbacks(\n",
    "              tensorboard=True,\n",
    "              progressbar=False,\n",
    "              reduce_lr=True,\n",
    "              early_stopping=True,\n",
    "              checkpoints=True,\n",
    "              csv=True,\n",
    "              base_path=MODEL_PATH,\n",
    "          )\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-laser",
   "metadata": {},
   "source": [
    "## Evaluating the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab9299",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "decode_idx: Callable[[np.ndarray], np.ndarray] = np.vectorize(idx_to_char.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013c477",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluator = evaluation.SequenceEvaluator(\n",
    "    dataset=datasets[EVAL_TYPE],\n",
    "    decode_func=decode_idx,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    separator=\" \",\n",
    "    padding_character=PROCESSING_INFO['padding_characters'][SEQ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a30b848",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluator.evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917eb62e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "eval_df, (x_eval, y_eval, y_pred) = evaluator.evaluate_model_visually(\n",
    "    model=model,\n",
    "    sample_size=20,\n",
    "    keep_separator=True,\n",
    ")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf7530",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "eval_df.predicted.map(print)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d87b01",
   "metadata": {},
   "source": [
    "broken loss function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caff47e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "np.argmax(y_pred[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9fb39f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.predict(datasets[EVAL_TYPE].take(1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900bef38",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515599e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052447fc",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lovely-landing",
   "metadata": {},
   "source": [
    "# Training an Attention Model on Tensorflow Datasets\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worth-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import os\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from IPython.core.display import display\n",
    "from mmproteo.utils import log, paths, utils, visualization\n",
    "from mmproteo.utils.formats.tf_dataset import DatasetLoader\n",
    "from mmproteo.utils.ml import callbacks, evaluation\n",
    "from official.modeling import tf_utils\n",
    "from official.nlp.modeling.models.seq2seq_transformer import Seq2SeqTransformer, TransformerDecoder, TransformerEncoder\n",
    "from official.nlp.modeling.ops import beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac9492c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.metrics import MeanMetricWrapper\n",
    "from tensorflow.python.ops import array_ops, math_ops\n",
    "from tensorflow.python.keras import backend\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "circular-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c53d832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d6a88dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.debugging.set_log_device_placement(True)\n",
    "GPUs = tf.config.list_physical_devices('GPU')\n",
    "GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-playlist",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "norwegian-therapist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpi/fs00/home/mirko.krause/masterthesis/pride-downloader/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deed6b25",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if os.getcwd() == \"/tf\":\n",
    "    os.chdir(os.path.join('workspace', 'notebooks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "987d32ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpi/fs00/home/mirko.krause/masterthesis/pride-downloader/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9012190",
   "metadata": {},
   "source": [
    "PROJECT = \"PXD010000\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d85591d",
   "metadata": {},
   "source": [
    "DUMP_PATH = os.path.join(\"..\", \"dumps\", PROJECT)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7c71bd1",
   "metadata": {},
   "source": [
    "DUMP_PATH = os.path.join(\"/scratch/mirko.krause/dumps/\", PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b98848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMP_PATH = \"/scratch/mirko.krause/pdeep\"\n",
    "TRAINING_COLUMNS_DUMP_PATH = os.path.join(DUMP_PATH, \"training_columns\")\n",
    "FILES_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"file_*.parquet\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9c4b705",
   "metadata": {},
   "source": [
    "TRAINING_COLUMNS_DUMP_PATH = os.path.join(DUMP_PATH, \"training_columns\")\n",
    "FILES_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"*_mzmlid.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "genuine-dealing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dump path = /scratch/mirko.krause/pdeep\n"
     ]
    }
   ],
   "source": [
    "print(f\"dump path = {DUMP_PATH}\")\n",
    "THREAD_COUNT = min(int(os.cpu_count()/2), 16)\n",
    "STATISTICS_FILE_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"statistics.parquet\")\n",
    "DATASET_DUMP_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"tf_datasets\")\n",
    "PROCESSING_FILE_PATH = os.path.join(DATASET_DUMP_PATH, \"processing_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interesting-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ = 'peptide_sequence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "certified-gibson",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 11:44:09,540 - mmproteo_attention_model: Logging to file '/scratch/mirko.krause/pdeep/mmproteo_attention_model.log' and to stderr\n"
     ]
    }
   ],
   "source": [
    "logger = log.create_logger(\n",
    "    name='mmproteo_attention_model',\n",
    "    verbose=True,\n",
    "    log_dir=DUMP_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c29d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'padding_characters': {'peptide_sequence': '_',\n",
       "  'mz_array': 0.0,\n",
       "  'intensity_array': 0.0},\n",
       " 'padding_lengths': {'mz_array': 89,\n",
       "  'intensity_array': 89,\n",
       "  'peptide_sequence': 30},\n",
       " 'idx_to_char': {'0': 'A',\n",
       "  '1': 'C',\n",
       "  '2': 'D',\n",
       "  '3': 'E',\n",
       "  '4': 'F',\n",
       "  '5': 'G',\n",
       "  '6': 'H',\n",
       "  '7': 'I',\n",
       "  '8': 'K',\n",
       "  '9': 'L',\n",
       "  '10': 'M',\n",
       "  '11': 'N',\n",
       "  '12': 'P',\n",
       "  '13': 'Q',\n",
       "  '14': 'R',\n",
       "  '15': 'S',\n",
       "  '16': 'T',\n",
       "  '17': 'V',\n",
       "  '18': 'W',\n",
       "  '19': 'Y',\n",
       "  '20': '_'},\n",
       " 'normalization': {'intensity_array': '<function base_peak_normalize at 0x7f9e3ee96af0>'},\n",
       " 'split_value_columns': None,\n",
       " 'training_data_columns': ['mz_array', 'intensity_array'],\n",
       " 'target_data_columns': ['peptide_sequence'],\n",
       " 'element_spec': '((TensorSpec(shape=(89,), dtype=tf.float64, name=None), TensorSpec(shape=(89,), dtype=tf.float64, name=None)), (TensorSpec(shape=(30,), dtype=tf.int8, name=None),))'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(PROCESSING_FILE_PATH, 'r') as file:\n",
    "    PROCESSING_INFO = json.loads(file.read())\n",
    "PROCESSING_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e975803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_grouping_path_position(cols: Optional[List[str]], prefered_item: str, alternative_index: int = -1) -> int:\n",
    "    res = alternative_index\n",
    "    if cols is not None:\n",
    "        try:\n",
    "            res = cols.index(prefered_item) - len(cols)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1df9537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouping_path_position = find_grouping_path_position(\n",
    "    cols=PROCESSING_INFO['split_value_columns'],\n",
    "    prefered_item='species',\n",
    "    alternative_index=-1,\n",
    ")\n",
    "grouping_path_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73a1f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_char = {int(idx): char for idx, char in PROCESSING_INFO[\"idx_to_char\"].items()}\n",
    "#idx_to_char[-1] = \"[start]\"\n",
    "char_to_idx = {char: idx for idx, char in idx_to_char.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-proceeding",
   "metadata": {},
   "source": [
    "## Loading Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee8aadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_CACHE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b34d7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ee8ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_TYPE = 'Train'\n",
    "TEST_TYPE = 'Test'\n",
    "EVAL_TYPE = 'Eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d696d51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assigned dataset files:\n",
      "#Train = 20\n",
      "e.g.: /scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_17.parquet\n",
      "#Test = 3\n",
      "e.g.: /scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_21.parquet\n",
      "#Eval = 3\n",
      "e.g.: /scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_14.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 11:44:09,566 - mmproteo_attention_model: DEBUG: assigned values:\n",
      "2021-08-16 11:44:09,567 - mmproteo_attention_model: DEBUG: #Train = 20\n",
      "2021-08-16 11:44:09,567 - mmproteo_attention_model: DEBUG: e.g.: file_17.parquet\n",
      "2021-08-16 11:44:09,567 - mmproteo_attention_model: DEBUG: #Test = 3\n",
      "2021-08-16 11:44:09,567 - mmproteo_attention_model: DEBUG: e.g.: file_21.parquet\n",
      "2021-08-16 11:44:09,567 - mmproteo_attention_model: DEBUG: #Eval = 3\n",
      "2021-08-16 11:44:09,568 - mmproteo_attention_model: DEBUG: e.g.: file_14.parquet\n",
      "2021-08-16 11:44:09,568 - mmproteo_attention_model: DEBUG: assigned paths:\n",
      "2021-08-16 11:44:09,568 - mmproteo_attention_model: DEBUG: #Train = 20\n",
      "2021-08-16 11:44:09,568 - mmproteo_attention_model: DEBUG: e.g.: /scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_17.parquet\n",
      "2021-08-16 11:44:09,569 - mmproteo_attention_model: DEBUG: #Test = 3\n",
      "2021-08-16 11:44:09,569 - mmproteo_attention_model: DEBUG: e.g.: /scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_21.parquet\n",
      "2021-08-16 11:44:09,569 - mmproteo_attention_model: DEBUG: #Eval = 3\n",
      "2021-08-16 11:44:09,569 - mmproteo_attention_model: DEBUG: e.g.: /scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_14.parquet\n",
      "2021-08-16 11:44:09,569 - mmproteo_attention_model: dumped file paths into '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/dataset_file_paths.json'\n"
     ]
    }
   ],
   "source": [
    "dataset_file_paths = paths.assign_wildcard_paths_to_splits_grouped_by_path_position_value(\n",
    "    wildcard_path = os.path.join(\n",
    "        DATASET_DUMP_PATH, \n",
    "        '*.parquet',  # filename\n",
    "        *(['*' for _ in PROCESSING_INFO['split_value_columns']] or [])\n",
    "    ),\n",
    "    path_position = grouping_path_position,\n",
    "    splits = {\n",
    "            TRAIN_TYPE: 0.8,\n",
    "            TEST_TYPE: 0.9,\n",
    "            EVAL_TYPE: 1.0\n",
    "        },\n",
    "    paths_dump_file = os.path.join(\n",
    "            DATASET_DUMP_PATH,\n",
    "            \"dataset_file_paths.json\"\n",
    "        ),\n",
    "    skip_existing = KEEP_CACHE,\n",
    "    logger = logger\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"assigned dataset files:\")\n",
    "visualization.print_list_length_in_dict(dataset_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec611252",
   "metadata": {},
   "source": [
    "### Loading corresponding TF datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aeb97f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(89,), dtype=tf.float64, name=None),\n",
       "  TensorSpec(shape=(89,), dtype=tf.float64, name=None)),\n",
       " (TensorSpec(shape=(30,), dtype=tf.int8, name=None),))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_spec = eval(PROCESSING_INFO['element_spec'], {}, {'TensorSpec':tf.TensorSpec, 'tf':tf})\n",
    "element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195bfe9c",
   "metadata": {},
   "source": [
    "**In the following step, Tensorflow starts allocating a GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b996dc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 11:44:09,576 - mmproteo_attention_model: DEBUG: started initializing tensorflow by creating a first dataset\n",
      "2021-08-16 11:44:09,611 - mmproteo_attention_model: finished initializing tensorflow\n"
     ]
    }
   ],
   "source": [
    "# initialize Tensorflow (might take several minutes (~5 minutes per GPU with 40GB VRAM each))\n",
    "logger.debug(\"started initializing tensorflow by creating a first dataset\")\n",
    "tf.data.Dataset.range(5)\n",
    "logger.info(\"finished initializing tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f66eda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_options = tf.data.Options()\n",
    "ds_options.experimental_threading.private_threadpool_size = THREAD_COUNT\n",
    "ds_options.experimental_threading.max_intra_op_parallelism = THREAD_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbef3700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 11:44:09,620 - mmproteo_attention_model: DEBUG: preparing dataset 'Train' with 20 paths\n",
      "2021-08-16 11:44:09,622 - mmproteo_attention_model: DEBUG: applied options to dataset 'Train'\n",
      "2021-08-16 11:44:09,667 - mmproteo_attention_model: DEBUG: loaded dataset 'Train' interleaved\n",
      "2021-08-16 11:44:09,667 - mmproteo_attention_model: DEBUG: shuffled dataset 'Train'\n",
      "2021-08-16 11:44:09,668 - mmproteo_attention_model: DEBUG: batched dataset 'Train'\n",
      "2021-08-16 11:44:09,668 - mmproteo_attention_model: DEBUG: skipped caching dataset 'Train'\n",
      "2021-08-16 11:44:09,669 - mmproteo_attention_model: DEBUG: configured prefetching for dataset 'Train'\n",
      "2021-08-16 11:44:09,669 - mmproteo_attention_model: DEBUG: skipped benchmarking dataset 'Train'\n",
      "2021-08-16 11:44:09,669 - mmproteo_attention_model: prepared dataset 'Train'\n",
      "2021-08-16 11:44:09,669 - mmproteo_attention_model: DEBUG: preparing dataset 'Test' with 3 paths\n",
      "2021-08-16 11:44:09,669 - mmproteo_attention_model: DEBUG: applied options to dataset 'Test'\n",
      "2021-08-16 11:44:09,677 - mmproteo_attention_model: DEBUG: loaded dataset 'Test' interleaved\n",
      "2021-08-16 11:44:09,677 - mmproteo_attention_model: DEBUG: shuffled dataset 'Test'\n",
      "2021-08-16 11:44:09,678 - mmproteo_attention_model: DEBUG: batched dataset 'Test'\n",
      "2021-08-16 11:44:09,678 - mmproteo_attention_model: DEBUG: skipped caching dataset 'Test'\n",
      "2021-08-16 11:44:09,678 - mmproteo_attention_model: DEBUG: configured prefetching for dataset 'Test'\n",
      "2021-08-16 11:44:09,678 - mmproteo_attention_model: DEBUG: skipped benchmarking dataset 'Test'\n",
      "2021-08-16 11:44:09,679 - mmproteo_attention_model: prepared dataset 'Test'\n",
      "2021-08-16 11:44:09,679 - mmproteo_attention_model: DEBUG: preparing dataset 'Eval' with 3 paths\n",
      "2021-08-16 11:44:09,679 - mmproteo_attention_model: DEBUG: applied options to dataset 'Eval'\n",
      "2021-08-16 11:44:09,686 - mmproteo_attention_model: DEBUG: loaded dataset 'Eval' interleaved\n",
      "2021-08-16 11:44:09,686 - mmproteo_attention_model: DEBUG: shuffled dataset 'Eval'\n",
      "2021-08-16 11:44:09,687 - mmproteo_attention_model: DEBUG: batched dataset 'Eval'\n",
      "2021-08-16 11:44:09,687 - mmproteo_attention_model: DEBUG: skipped caching dataset 'Eval'\n",
      "2021-08-16 11:44:09,687 - mmproteo_attention_model: DEBUG: configured prefetching for dataset 'Eval'\n",
      "2021-08-16 11:44:09,688 - mmproteo_attention_model: DEBUG: skipped benchmarking dataset 'Eval'\n",
      "2021-08-16 11:44:09,688 - mmproteo_attention_model: prepared dataset 'Eval'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Train': <PrefetchDataset shapes: (((512, 89), (512, 89)), ((512, 30),)), types: ((tf.float64, tf.float64), (tf.int8,))>,\n",
       " 'Test': <PrefetchDataset shapes: (((512, 89), (512, 89)), ((512, 30),)), types: ((tf.float64, tf.float64), (tf.int8,))>,\n",
       " 'Eval': <PrefetchDataset shapes: (((512, 89), (512, 89)), ((512, 30),)), types: ((tf.float64, tf.float64), (tf.int8,))>}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = DatasetLoader(\n",
    "    element_spec=element_spec,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle_buffer_size=100_000,\n",
    "    thread_count=min(int(os.cpu_count()/4), 4),\n",
    "    keep_cache=KEEP_CACHE,\n",
    "    logger=logger,\n",
    "    run_benchmarks=False,\n",
    "    options=ds_options,\n",
    ").load_datasets_by_type(dataset_file_paths)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1372f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_datasets = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2eb0f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_target_sequences_with_start_token(tensor: tf.Tensor, token: Any = -1) -> tf.Tensor:\n",
    "    return tf.concat(\n",
    "        values=[\n",
    "            tf.broadcast_to(\n",
    "                input=tf.constant(token, dtype=tensor.dtype),\n",
    "                shape=(\n",
    "                    tensor.shape[0],  # batch dimension\n",
    "                    1\n",
    "                )\n",
    "            ),\n",
    "            tensor\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "def _dataset_mapper_for_transformer(trainings: Tuple[tf.Tensor], targets: Tuple[tf.Tensor]) \\\n",
    "-> Tuple[Dict[str, tf.data.Dataset], tf.data.Dataset]:\n",
    "    inputs = tf.stack(trainings, axis=-1)[:, :500, :]  # cut off too long spectra\n",
    "    inputs = tf.cast(x=inputs, dtype=tf.float32)\n",
    "    targets = prefix_target_sequences_with_start_token(targets[0])\n",
    "    targets = tf.cast(\n",
    "        x=targets,\n",
    "        dtype=tf.int32,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        {\n",
    "            \"inputs\": inputs,\n",
    "            \"targets\": targets[:, :-1],\n",
    "        },\n",
    "        targets[:, 1:]\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_dataset_for_transformer_training(dataset: tf.data.Dataset) -> tf.data.Dataset:\n",
    "    return dataset.map(_dataset_mapper_for_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e595d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use these methods if the model shifts the target input itself\n",
    "\n",
    "def _dataset_mapper_for_transformer_unshifted(trainings: Tuple[tf.Tensor], targets: Tuple[tf.Tensor]) \\\n",
    "-> Tuple[Dict[str, tf.data.Dataset], tf.data.Dataset]:\n",
    "    inputs = tf.stack(trainings, axis=-1)[:, :500, :]  # cut off too long spectra\n",
    "    inputs = tf.cast(x=inputs, dtype=tf.float32)\n",
    "\n",
    "    targets = tf.cast(\n",
    "        x=targets[0],\n",
    "        dtype=tf.int32,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        {\n",
    "            \"inputs\": inputs,\n",
    "            \"targets\": targets,\n",
    "        },\n",
    "        targets\n",
    "    )\n",
    "\n",
    "def prepare_dataset_for_transformer_training_unshifted(dataset: tf.data.Dataset) -> tf.data.Dataset:\n",
    "    return dataset.map(_dataset_mapper_for_transformer_unshifted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a08cd1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train': <MapDataset shapes: ({inputs: (512, 89, 2), targets: (512, 30)}, (512, 30)), types: ({inputs: tf.float32, targets: tf.int32}, tf.int32)>,\n",
       " 'Test': <MapDataset shapes: ({inputs: (512, 89, 2), targets: (512, 30)}, (512, 30)), types: ({inputs: tf.float32, targets: tf.int32}, tf.int32)>,\n",
       " 'Eval': <MapDataset shapes: ({inputs: (512, 89, 2), targets: (512, 30)}, (512, 30)), types: ({inputs: tf.float32, targets: tf.int32}, tf.int32)>}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {\n",
    "    t: prepare_dataset_for_transformer_training_unshifted(dataset) for t, dataset in original_datasets.items()\n",
    "}\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "767ec869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original datasets:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61ed5e32fe24a73b307354672cf185e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Summary ************\n",
      "\n",
      "Examples/sec (First included) 223.75 ex/sec (total: 5855 ex, 26.17 sec)\n",
      "Examples/sec (First only) 1.85 ex/sec (total: 1 ex, 0.54 sec)\n",
      "Examples/sec (First excluded) 228.43 ex/sec (total: 5854 ex, 25.63 sec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>BenchmarkResult:</strong><br/><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first+lasts</th>\n",
       "      <td>26.167154</td>\n",
       "      <td>5855</td>\n",
       "      <td>223.753796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>0.540323</td>\n",
       "      <td>1</td>\n",
       "      <td>1.850745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasts</th>\n",
       "      <td>25.626831</td>\n",
       "      <td>5854</td>\n",
       "      <td>228.432460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BenchmarkResult(stats=              duration  num_examples         avg\n",
       "first+lasts  26.167154          5855  223.753796\n",
       "first         0.540323             1    1.850745\n",
       "lasts        25.626831          5854  228.432460, raw_stats=                      duration\n",
       "start_time        4.669757e+06\n",
       "first_batch_time  4.669758e+06\n",
       "end_time          4.669783e+06\n",
       "num_iter          5.855000e+03)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mapped datasets:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb792a43f1d34b21bb087bda854f0c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Summary ************\n",
      "\n",
      "Examples/sec (First included) 229.14 ex/sec (total: 5855 ex, 25.55 sec)\n",
      "Examples/sec (First only) 1.84 ex/sec (total: 1 ex, 0.54 sec)\n",
      "Examples/sec (First excluded) 234.09 ex/sec (total: 5854 ex, 25.01 sec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>BenchmarkResult:</strong><br/><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first+lasts</th>\n",
       "      <td>25.551702</td>\n",
       "      <td>5855</td>\n",
       "      <td>229.143252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>0.544430</td>\n",
       "      <td>1</td>\n",
       "      <td>1.836782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasts</th>\n",
       "      <td>25.007271</td>\n",
       "      <td>5854</td>\n",
       "      <td>234.091915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BenchmarkResult(stats=              duration  num_examples         avg\n",
       "first+lasts  25.551702          5855  229.143252\n",
       "first         0.544430             1    1.836782\n",
       "lasts        25.007271          5854  234.091915, raw_stats=                      duration\n",
       "start_time        4.669783e+06\n",
       "first_batch_time  4.669784e+06\n",
       "end_time          4.669809e+06\n",
       "num_iter          5.855000e+03)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"original datasets:\")\n",
    "display(tfds.benchmark(original_datasets[TEST_TYPE]))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"mapped datasets:\")\n",
    "display(tfds.benchmark(datasets[TEST_TYPE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-company",
   "metadata": {},
   "source": [
    "## Building the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30c0be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from: https://github.com/tensorflow/models/blob/027813d334645d6076a72b41b7b87ec30334cbb1/official/nlp/modeling/layers/position_embedding.py#L91\n",
    "def embed_with_sin_and_cos(positions: Union[tf.Tensor, np.ndarray], embedding_width: int) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    positions: a tensor with the dimensions [batch_size, item count]\n",
    "    \"\"\"\n",
    "    # constants\n",
    "    num_timescales = embedding_width // 2\n",
    "    min_timescale, max_timescale = 1.0, 1.0e4\n",
    "    log_timescale_increment = (\n",
    "        math.log(float(max_timescale) / float(min_timescale)) /\n",
    "        (tf.cast(num_timescales, tf.float32) - 1))\n",
    "    inv_timescales = min_timescale * tf.exp(\n",
    "        tf.cast(tf.range(num_timescales), tf.float32) *\n",
    "        -log_timescale_increment)\n",
    "\n",
    "    # calculations\n",
    "    scaled_time = tf.expand_dims(positions, -1) * tf.expand_dims(\n",
    "        inv_timescales, 0)\n",
    "    position_embeddings = tf.concat(\n",
    "        [tf.sin(scaled_time), tf.cos(scaled_time)], axis=-1)\n",
    "    return position_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae2f619d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_idx[PROCESSING_INFO['padding_characters'][SEQ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ce6bb7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heavily based on:\n",
    "# https://github.com/tensorflow/models/blob/master/official/nlp/modeling/models/seq2seq_transformer.py\n",
    "# (29.06.2021)\n",
    "class MyTransformer(Seq2SeqTransformer):\n",
    "    _eos_id: int = char_to_idx[PROCESSING_INFO['padding_characters'][SEQ]]\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \"\"\"Calculate target logits or inferred target sequences.\n",
    "        Args:\n",
    "          inputs: a dictionary of tensors.\n",
    "            Feature `inputs`: int tensor with shape `[batch_size, input_length]`.\n",
    "            Feature `targets` (optional): None or int tensor with shape\n",
    "              `[batch_size, target_length]`.\n",
    "        Returns:\n",
    "          If targets is defined, then return logits for each word in the target\n",
    "          sequence, which is a float tensor with shape\n",
    "          `(batch_size, target_length, vocab_size)`. If target is `None`, then\n",
    "          generate output sequence one token at a time and\n",
    "          returns a dictionary {\n",
    "              outputs: `(batch_size, decoded_length)`\n",
    "              scores: `(batch_size, 1)`}\n",
    "          Even when `float16` is used, the output tensor(s) are always `float32`.\n",
    "        Raises:\n",
    "          NotImplementedError: If try to use padded decode method on CPU/GPUs.\n",
    "        \"\"\"\n",
    "        sources = inputs[\"inputs\"]\n",
    "        mz = sources[:, :, 0]\n",
    "        intensities = sources[:, :, 1]\n",
    "        targets = inputs.get(\"targets\", None)\n",
    "        \n",
    "        # Prepare inputs to the layer stack by adding positional encodings and applying dropout.\n",
    "\n",
    "        embedded_mz = embed_with_sin_and_cos(mz, self._embedding_width)\n",
    "        embedded_intensities = embedded_mz * tf.expand_dims(intensities, -1)\n",
    "    \n",
    "        sources = embedded_intensities\n",
    "        \n",
    "        # Attention_mask generation.\n",
    "        input_shape = tf_utils.get_shape_list(sources, expected_rank=3)\n",
    "        batch_size = input_shape[0]\n",
    "        input_length = input_shape[1]\n",
    "        channel_count = input_shape[2]\n",
    "        non_padding_sources = tf.not_equal(mz, 0.0)\n",
    "        non_padding_sources = tf.reshape(\n",
    "            tensor=non_padding_sources,\n",
    "            shape=[batch_size, 1, input_length]\n",
    "        )\n",
    "        attention_mask = tf.cast(\n",
    "            x=non_padding_sources,\n",
    "            dtype=sources.dtype\n",
    "        )\n",
    "        broadcast_ones = tf.ones(\n",
    "            shape=[batch_size, input_length, 1],\n",
    "            dtype=sources.dtype\n",
    "        )\n",
    "        attention_mask = broadcast_ones * attention_mask\n",
    "\n",
    "        encoder_inputs = self.encoder_dropout(sources)\n",
    "\n",
    "        encoder_outputs = self.encoder_layer(\n",
    "            encoder_inputs, attention_mask=attention_mask)\n",
    "        \n",
    "        if targets is None:\n",
    "            if self._padded_decode:\n",
    "                max_decode_length = self._decode_max_length\n",
    "            else:\n",
    "                max_decode_length = self._decode_max_length or (\n",
    "                        tf.shape(encoder_outputs)[1] + self._extra_decode_length)\n",
    "            symbols_to_logits_fn = self._get_symbols_to_logits_fn(max_decode_length)\n",
    "\n",
    "            #batch_size = tf.shape(encoder_outputs)[0]\n",
    "            # Create initial set of IDs that will be passed to symbols_to_logits_fn.\n",
    "            initial_ids = tf.zeros([batch_size], dtype=tf.int32)\n",
    "\n",
    "            # Create cache storing decoder attention values for each layer.\n",
    "            init_decode_length = (max_decode_length if self._padded_decode else 0)\n",
    "            num_heads = self.decoder_layer.num_attention_heads\n",
    "            dim_per_head = self._embedding_width // num_heads\n",
    "\n",
    "            # Cache dtype needs to match beam_search dtype.\n",
    "            # pylint: disable=g-complex-comprehension\n",
    "            cache = {\n",
    "                str(layer): {\n",
    "                    \"key\":\n",
    "                        tf.zeros(\n",
    "                            [batch_size, init_decode_length, num_heads, dim_per_head],\n",
    "                            dtype=self.compute_dtype),\n",
    "                    \"value\":\n",
    "                        tf.zeros(\n",
    "                            [batch_size, init_decode_length, num_heads, dim_per_head],\n",
    "                            dtype=self.compute_dtype)\n",
    "                } for layer in range(self.decoder_layer.num_layers)\n",
    "            }\n",
    "            # pylint: enable=g-complex-comprehension\n",
    "\n",
    "            # Add encoder output and attention bias to the cache.\n",
    "            encoder_outputs = tf.cast(encoder_outputs, dtype=self.compute_dtype)\n",
    "            \n",
    "            #attention_mask = tf.cast(\n",
    "            #    tf.reshape(\n",
    "            #        tf.not_equal(sources, 0), [batch_size, 1, input_length]),\n",
    "            #    dtype=self.compute_dtype)\n",
    "            attention_mask = tf.cast(\n",
    "                    tf.not_equal(sources, 0),\n",
    "                dtype=self.compute_dtype)\n",
    "            cache[\"encoder_outputs\"] = encoder_outputs\n",
    "            cache[\"encoder_decoder_attention_mask\"] = attention_mask\n",
    "            \n",
    "            search_parameters = {\n",
    "                \"initial_ids\": initial_ids,\n",
    "                \"initial_cache\": cache,\n",
    "                \"vocab_size\": self._vocab_size,\n",
    "                \"beam_size\": self._beam_size,\n",
    "                \"alpha\": self._alpha,\n",
    "                \"max_decode_length\": max_decode_length,\n",
    "                \"eos_id\": self._eos_id,\n",
    "                \"padded_decode\": self._padded_decode\n",
    "            }\n",
    "            #return search_parameters\n",
    "        \n",
    "            # Use beam search to find the top beam_size sequences and scores.\n",
    "            decoded_ids, scores = beam_search.sequence_beam_search(\n",
    "                symbols_to_logits_fn=symbols_to_logits_fn,\n",
    "                initial_ids=initial_ids,\n",
    "                initial_cache=cache,\n",
    "                vocab_size=self._vocab_size,\n",
    "                beam_size=self._beam_size,\n",
    "                alpha=self._alpha,\n",
    "                max_decode_length=max_decode_length,\n",
    "                eos_id=self._eos_id,\n",
    "                padded_decode=self._padded_decode,\n",
    "                dtype=self.compute_dtype)\n",
    "\n",
    "            # Get the top sequence for each batch element\n",
    "            top_decoded_ids = decoded_ids[:, 0, 1:]\n",
    "            top_scores = scores[:, 0]\n",
    "\n",
    "            return {\"outputs\": top_decoded_ids, \"scores\": top_scores}\n",
    "\n",
    "        decoder_inputs = self.embedding_lookup(targets)\n",
    "        embedding_mask = tf.cast(tf.not_equal(targets, 0), decoder_inputs.dtype)\n",
    "        decoder_inputs *= tf.expand_dims(embedding_mask, -1)\n",
    "        # Shift targets to the right, and remove the last element\n",
    "        # seems smarter than the dataset approach\n",
    "        decoder_inputs = tf.pad(decoder_inputs, [[0, 0], [1, 0], [0, 0]])[:, :-1, :]\n",
    "        \n",
    "        length = tf.shape(decoder_inputs)[1]\n",
    "        pos_encoding = self.position_embedding(decoder_inputs)\n",
    "        pos_encoding = tf.cast(pos_encoding, decoder_inputs.dtype)\n",
    "        decoder_inputs += pos_encoding\n",
    "\n",
    "        decoder_inputs = self.decoder_dropout(decoder_inputs)\n",
    "\n",
    "        decoder_shape = tf_utils.get_shape_list(decoder_inputs, expected_rank=3)\n",
    "        batch_size = decoder_shape[0]\n",
    "        decoder_length = decoder_shape[1]\n",
    "\n",
    "        self_attention_mask = tf.linalg.band_part(tf.ones([length, length]), -1, 0)\n",
    "        self_attention_mask = tf.reshape(self_attention_mask, [1, length, length])\n",
    "        self_attention_mask = tf.tile(self_attention_mask, [batch_size, 1, 1])\n",
    "\n",
    "        attention_mask = tf.cast(\n",
    "            tf.expand_dims(tf.not_equal(sources[:, :, 0], 0), axis=1), dtype=sources.dtype)\n",
    "        attention_mask = tf.tile(attention_mask, [1, decoder_length, 1])\n",
    "\n",
    "        outputs = self.decoder_layer(\n",
    "            decoder_inputs,\n",
    "            encoder_outputs,\n",
    "            memory_mask=self_attention_mask,\n",
    "            target_mask=attention_mask)\n",
    "        \n",
    "        logits = self._embedding_linear(self.embedding_lookup.embeddings, outputs)\n",
    "        # Model outputs should be float32 to avoid numeric issues.\n",
    "        # https://www.tensorflow.org/guide/mixed_precision#building_the_model\n",
    "        logits = tf.cast(logits, tf.float32)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "313e89de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 13:58:01,124 - mmproteo_attention_model: created new model 'mmproteo_transformer_20210816-135801'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: in user code:\n",
      "\n",
      "    <ipython-input-145-c0d4efa2cfca>:122 call  *\n",
      "        decoded_ids, scores = beam_search.sequence_beam_search(\n",
      "    /scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/official/nlp/modeling/ops/beam_search.py:579 sequence_beam_search  *\n",
      "        return sbs.search(initial_ids, initial_cache)\n",
      "    /scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/official/nlp/modeling/ops/beam_search.py:194 _grow_alive_seq  *\n",
      "        flat_logits, flat_cache = self.symbols_to_logits_fn(\n",
      "    /tmp/tmp092427as.py:56 symbols_to_logits_fn  **\n",
      "        attention_bias = ag__.converted_call(ag__.ld(tf).where, ((ag__.ld(attention_bias) < 0), ag__.converted_call(ag__.ld(tf).zeros_like, (ag__.ld(attention_bias),), None, fscope_1), ag__.converted_call(ag__.ld(tf).ones_like, (ag__.ld(attention_bias),), None, fscope_1)), None, fscope_1)\n",
      "\n",
      "    TypeError: '<' not supported between instances of 'NoneType' and 'int'\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\n",
      "    yield\n",
      "  File \"/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 323, in run\n",
      "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
      "  File \"/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\", line 670, in wrapper\n",
      "    raise e.ag_error_metadata.to_exception(e)\n",
      "TypeError: in user code:\n",
      "\n",
      "    <ipython-input-145-c0d4efa2cfca>:122 call  *\n",
      "        decoded_ids, scores = beam_search.sequence_beam_search(\n",
      "    /scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/official/nlp/modeling/ops/beam_search.py:579 sequence_beam_search  *\n",
      "        return sbs.search(initial_ids, initial_cache)\n",
      "    /scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/official/nlp/modeling/ops/beam_search.py:194 _grow_alive_seq  *\n",
      "        flat_logits, flat_cache = self.symbols_to_logits_fn(\n",
      "    /tmp/tmp092427as.py:56 symbols_to_logits_fn  **\n",
      "        attention_bias = ag__.converted_call(ag__.ld(tf).where, ((ag__.ld(attention_bias) < 0), ag__.converted_call(ag__.ld(tf).zeros_like, (ag__.ld(attention_bias),), None, fscope_1), ag__.converted_call(ag__.ld(tf).ones_like, (ag__.ld(attention_bias),), None, fscope_1)), None, fscope_1)\n",
      "\n",
      "    TypeError: '<' not supported between instances of 'NoneType' and 'int'\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    /scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    <ipython-input-145-c0d4efa2cfca>:122 call  *\n        decoded_ids, scores = beam_search.sequence_beam_search(\n    /scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/official/nlp/modeling/ops/beam_search.py:579 sequence_beam_search  *\n        return sbs.search(initial_ids, initial_cache)\n    /scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/official/nlp/modeling/ops/beam_search.py:194 _grow_alive_seq  *\n        flat_logits, flat_cache = self.symbols_to_logits_fn(\n    /tmp/tmp092427as.py:56 symbols_to_logits_fn  **\n        attention_bias = ag__.converted_call(ag__.ld(tf).where, ((ag__.ld(attention_bias) < 0), ag__.converted_call(ag__.ld(tf).zeros_like, (ag__.ld(attention_bias),), None, fscope_1), ag__.converted_call(ag__.ld(tf).ones_like, (ag__.ld(attention_bias),), None, fscope_1)), None, fscope_1)\n\n    TypeError: '<' not supported between instances of 'NoneType' and 'int'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-146-216e63b1a629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_less_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 725\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    726\u001b[0m             *args, **kwds))\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    /scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    <ipython-input-145-c0d4efa2cfca>:122 call  *\n        decoded_ids, scores = beam_search.sequence_beam_search(\n    /scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/official/nlp/modeling/ops/beam_search.py:579 sequence_beam_search  *\n        return sbs.search(initial_ids, initial_cache)\n    /scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/official/nlp/modeling/ops/beam_search.py:194 _grow_alive_seq  *\n        flat_logits, flat_cache = self.symbols_to_logits_fn(\n    /tmp/tmp092427as.py:56 symbols_to_logits_fn  **\n        attention_bias = ag__.converted_call(ag__.ld(tf).where, ((ag__.ld(attention_bias) < 0), ag__.converted_call(ag__.ld(tf).zeros_like, (ag__.ld(attention_bias),), None, fscope_1), ag__.converted_call(ag__.ld(tf).ones_like, (ag__.ld(attention_bias),), None, fscope_1)), None, fscope_1)\n\n    TypeError: '<' not supported between instances of 'NoneType' and 'int'\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "res = model.predict(target_less_input)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c04b0203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 512)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7df3f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(elem):\n",
    "    i_true, i_pred = elem[0], elem[1]\n",
    "    unique_true, _ = tf.unique(i_true)\n",
    "    unique_pred, _ = tf.unique(i_pred)\n",
    "    n_unique_true = tf.shape(unique_true)[0]\n",
    "    n_unique_pred = tf.shape(unique_pred)[0]\n",
    "    unique_all, _ = tf.unique(tf.concat(values=[unique_true, unique_pred], axis=-1))\n",
    "    n_unique_all = tf.shape(unique_all)[0]\n",
    "    n_overlap = n_unique_true + n_unique_pred - n_unique_all\n",
    "    return n_overlap / n_unique_all\n",
    "\n",
    "def jaccard_batch_distance(y_true, y_pred):\n",
    "    y_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)\n",
    "    y_true = ops.convert_to_tensor_v2_with_dispatch(y_true)\n",
    "    y_pred_rank = y_pred.shape.ndims\n",
    "    y_true_rank = y_true.shape.ndims\n",
    "    # If the shape of y_true is (num_samples, 1), squeeze to (num_samples,)\n",
    "    if (y_true_rank is not None) and (y_pred_rank is not None) and (len(\n",
    "            backend.int_shape(y_true)) == len(backend.int_shape(y_pred))):\n",
    "        y_true = array_ops.squeeze(y_true, [-1])\n",
    "    y_pred = math_ops.argmax(y_pred, axis=-1)\n",
    "\n",
    "    # If the predicted output and actual output types don't match, force cast them\n",
    "    # to match.\n",
    "    if backend.dtype(y_pred) != backend.dtype(y_true):\n",
    "        y_pred = math_ops.cast(y_pred, backend.dtype(y_true))\n",
    "    \n",
    "    # 0th dimension is the batch\n",
    "    jaccard = tf.map_fn(fn=jaccard_distance, elems=(y_true, y_pred), fn_output_signature=tf.float64)\n",
    "    return math_ops.cast(jaccard, backend.floatx())\n",
    "    \n",
    "\n",
    "class JaccardBatchDistance(MeanMetricWrapper):\n",
    "    def __init__(self, name='jaccard_batch_distance', dtype=None):\n",
    "        super(JaccardBatchDistance, self).__init__(\n",
    "            jaccard_batch_distance, name, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c19dbcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leuvenshtein_sparse_tensor_batch_distance(y_true: tf.sparse.SparseTensor, y_pred: tf.sparse.SparseTensor) -> tf.Tensor:\n",
    "    return tf.edit_distance(\n",
    "        hypothesis=y_pred,\n",
    "        truth=y_true,\n",
    "        normalize=False,\n",
    "    )\n",
    "\n",
    "def leuvenshtein_batch_distance(y_true: tf.Tensor, y_pred: tf.Tensor, sparse_pred: bool = True) -> tf.Tensor:\n",
    "    y_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)\n",
    "    y_true = ops.convert_to_tensor_v2_with_dispatch(y_true)\n",
    "    \n",
    "    if sparse_pred:\n",
    "        y_pred = math_ops.argmax(y_pred, axis=-1)\n",
    "    \n",
    "    y_pred = tf.sparse.from_dense(y_pred)\n",
    "    y_true = tf.sparse.from_dense(y_true)\n",
    "\n",
    "    # If the predicted output and actual output types don't match, force cast them\n",
    "    # to match.\n",
    "    if backend.dtype(y_pred) != backend.dtype(y_true):\n",
    "        y_pred = math_ops.cast(y_pred, backend.dtype(y_true))\n",
    "    \n",
    "    # 0th dimension is the batch\n",
    "    leuvenshtein = leuvenshtein_sparse_tensor_batch_distance(y_true, y_pred)\n",
    "    return math_ops.cast(leuvenshtein, backend.floatx())\n",
    "    \n",
    "\n",
    "class LeuvenshteinBatchDistance(MeanMetricWrapper):\n",
    "    def __init__(self, name='leuvenshtein_batch_distance', dtype=None):\n",
    "        super(LeuvenshteinBatchDistance, self).__init__(\n",
    "            leuvenshtein_batch_distance, name, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "af57d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from https://github.com/tensorflow/tensorflow/blob/v2.6.0/tensorflow/python/keras/metrics.py\n",
    "\n",
    "def sparse_categorical_accuracy(y_true, y_pred):\n",
    "    y_pred = ops.convert_to_tensor_v2_with_dispatch(y_pred)\n",
    "    y_true = ops.convert_to_tensor_v2_with_dispatch(y_true)\n",
    "    y_pred_rank = y_pred.shape.ndims\n",
    "    y_true_rank = y_true.shape.ndims\n",
    "    # If the shape of y_true is (num_samples, 1), squeeze to (num_samples,)\n",
    "    if (y_true_rank is not None) and (y_pred_rank is not None) and (len(\n",
    "        backend.int_shape(y_true)) == len(backend.int_shape(y_pred))):\n",
    "        y_true = array_ops.squeeze(y_true, [-1])\n",
    "    y_pred = math_ops.argmax(y_pred, axis=-1)\n",
    "\n",
    "    # If the predicted output and actual output types don't match, force cast them\n",
    "    # to match.\n",
    "    if backend.dtype(y_pred) != backend.dtype(y_true):\n",
    "        y_pred = math_ops.cast(y_pred, backend.dtype(y_true))\n",
    "\n",
    "    return math_ops.cast(math_ops.equal(y_true, y_pred), backend.floatx())\n",
    "\n",
    "class SparseCategoricalAccuracy(MeanMetricWrapper):\n",
    "    def __init__(self, name='sparse_categorical_accuracy', dtype=None):\n",
    "        super(SparseCategoricalAccuracy, self).__init__(\n",
    "            sparse_categorical_accuracy, name, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76512ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_LAYERS = 6\n",
    "ATTENTION_HEADS = 16\n",
    "EMBEDDING_WIDTH = 512  # d_model\n",
    "LEARNING_RATE = 10**-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec54b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() -> tf.keras.Model:\n",
    "    encoder_layer = TransformerEncoder(\n",
    "        num_attention_heads=ATTENTION_HEADS,\n",
    "        num_layers=TRANSFORMER_LAYERS,\n",
    "    )\n",
    "    decoder_layer = TransformerDecoder(\n",
    "        num_attention_heads=ATTENTION_HEADS,\n",
    "        num_layers=TRANSFORMER_LAYERS,\n",
    "    )\n",
    "\n",
    "    model = MyTransformer(\n",
    "        vocab_size=len(idx_to_char),\n",
    "        embedding_width=EMBEDDING_WIDTH,\n",
    "        encoder_layer=encoder_layer,\n",
    "        decoder_layer=decoder_layer,\n",
    "        name=f\"mmproteo_transformer_{utils.get_current_time_str()}\",\n",
    "        decode_max_length=PROCESSING_INFO['padding_lengths'][SEQ],\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            beta_2=0.98,  # values taken from the 'Attention is all you need' paper\n",
    "            epsilon=10**-9,\n",
    "        ),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  #masked_loss,\n",
    "        metrics=[\n",
    "            SparseCategoricalAccuracy(),\n",
    "            JaccardBatchDistance(),\n",
    "            LeuvenshteinBatchDistance(),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96a40234",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e8e9b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = os.path.join(DUMP_PATH, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "52b828d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model() -> tf.keras.Model:\n",
    "    with mirrored_strategy.scope():\n",
    "        model = build_model()\n",
    "    global MODEL_PATH\n",
    "    MODEL_PATH = os.path.join(MODELS_PATH, model.name)\n",
    "    utils.ensure_dir_exists(MODEL_PATH)\n",
    "    logger.info(f\"created new model '{model.name}'\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "87aac5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 13:21:43,539 - mmproteo_attention_model: created new model 'mmproteo_transformer_20210816-132143'\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9d4032e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 13:20:17,252 - mmproteo_attention_model: DEBUG: started a first prediction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 19 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faf0041e790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-5.46369970e-01, -2.94575468e-02,  5.36054671e-01,\n",
       "         -4.57240701e-01, -8.84529889e-01,  4.63199854e-01,\n",
       "          1.03020453e+00,  3.76173615e-01,  5.99538684e-02,\n",
       "          7.59980023e-01, -1.22183585e+00, -6.31761998e-02,\n",
       "         -2.79044604e+00,  7.42147863e-02,  7.15529323e-01,\n",
       "          4.42193270e-01,  9.63854790e-01,  9.19787645e-01,\n",
       "          1.58838940e+00,  2.56280929e-01, -1.45377636e+00],\n",
       "        [-5.03546715e-01, -4.77791727e-01,  1.05268431e+00,\n",
       "         -2.73714960e-01, -8.95750880e-01,  6.10152960e-01,\n",
       "          5.77858388e-01, -6.34526253e-01, -6.71691716e-01,\n",
       "          3.63227040e-01, -1.25635278e+00,  2.84575760e-01,\n",
       "         -3.12872076e+00,  3.78127873e-01,  5.57128608e-01,\n",
       "         -5.39517164e-01,  6.09995484e-01,  6.59243536e+00,\n",
       "          1.55339479e+00, -5.16050160e-02, -2.02944541e+00],\n",
       "        [-5.11607289e-01, -6.99810684e-01,  5.56266606e-02,\n",
       "         -2.81834513e-01, -6.11231148e-01,  7.51651525e-01,\n",
       "          6.88955188e-01,  4.22303796e-01, -6.26436710e-01,\n",
       "          1.10447347e+00, -1.37144864e+00,  1.36092678e-01,\n",
       "         -3.25918007e+00,  1.37838274e-01,  6.74657345e-01,\n",
       "         -4.60798144e-02,  7.14144468e+00,  7.26160169e-01,\n",
       "          1.26827669e+00,  3.22636157e-01, -1.78877974e+00],\n",
       "        [-8.03860188e-01, -5.62069893e-01,  8.38183224e-01,\n",
       "         -1.02990949e+00, -1.77743971e-01,  1.18572199e+00,\n",
       "          6.40465641e+00,  5.44926107e-01, -6.33792698e-01,\n",
       "          4.10853952e-01, -1.51820111e+00, -4.03652489e-01,\n",
       "         -2.92935610e+00, -2.82327920e-01,  3.13793302e-01,\n",
       "          2.19085872e-01,  4.34339106e-01, -7.22422153e-02,\n",
       "          2.07003355e+00,  7.19300508e-02, -1.64680672e+00],\n",
       "        [-1.17856240e+00, -5.86490750e-01,  7.07909107e+00,\n",
       "         -4.24426079e-01, -1.11257458e+00,  1.46939158e+00,\n",
       "          1.02773309e+00, -4.27910686e-03, -7.26532757e-01,\n",
       "          9.54060972e-01, -1.36746764e+00,  1.81713551e-01,\n",
       "         -3.08231997e+00,  1.91562653e-01,  9.50943708e-01,\n",
       "         -3.01927447e-01,  6.08393550e-01,  8.58515620e-01,\n",
       "          1.62480509e+00,  6.74502552e-03, -2.01428747e+00],\n",
       "        [-3.93692881e-01, -4.76728261e-01,  1.33380198e+00,\n",
       "         -3.52501482e-01, -3.90919149e-01,  7.04047394e+00,\n",
       "          1.16923726e+00, -9.83704329e-02, -8.15364838e-01,\n",
       "          5.82125783e-01, -1.25812399e+00, -1.26570195e-01,\n",
       "         -3.19219422e+00, -1.09868020e-01,  8.24270725e-01,\n",
       "          1.63379610e-01,  1.20901310e+00,  5.38024962e-01,\n",
       "          1.70334589e+00,  9.92917866e-02, -1.63230073e+00],\n",
       "        [-9.99378800e-01, -6.65864825e-01,  9.93684590e-01,\n",
       "         -5.64031720e-01, -9.02654052e-01,  6.91221178e-01,\n",
       "          1.28638816e+00,  6.76813412e+00, -2.07977116e-01,\n",
       "          7.14213967e-01, -1.49981296e+00, -1.98000193e-01,\n",
       "         -2.25924397e+00,  3.69299501e-01,  1.18384433e+00,\n",
       "          1.52104288e-01,  6.66714430e-01,  5.86398065e-01,\n",
       "          1.50737381e+00,  3.80455971e-01, -2.15524673e+00],\n",
       "        [ 1.51663110e-01, -6.39548779e-01,  1.36732030e+00,\n",
       "         -2.31275380e-01, -1.89341176e+00,  5.03017664e-01,\n",
       "          9.50004101e-01,  2.80904770e-02, -9.57197964e-01,\n",
       "          7.21846628e+00, -9.40169334e-01,  2.63365805e-02,\n",
       "         -2.89093637e+00, -2.61089951e-02,  8.46793532e-01,\n",
       "         -1.86719418e-01,  1.08753002e+00,  4.98147130e-01,\n",
       "          1.34982622e+00, -6.98401034e-02, -2.10860682e+00],\n",
       "        [-4.49875385e-01, -6.86941743e-01,  9.34516370e-01,\n",
       "         -5.39824128e-01, -9.47527170e-01,  8.43611240e-01,\n",
       "          9.23569918e-01,  3.43454927e-01, -7.17366219e-01,\n",
       "          1.10058093e+00, -1.40090871e+00, -5.41814417e-02,\n",
       "         -3.01417112e+00,  1.51300490e-01,  1.00604808e+00,\n",
       "          1.97259456e-01,  1.14274144e+00,  8.63592386e-01,\n",
       "          1.84170341e+00,  5.23147464e-01, -2.15219879e+00],\n",
       "        [-2.89542228e-02, -2.82759815e-01,  7.62474716e-01,\n",
       "         -2.30200455e-01, -8.91873956e-01,  6.85615957e-01,\n",
       "          1.37613863e-01,  8.10544193e-01, -1.18566871e-01,\n",
       "          2.37489223e-01, -1.81328034e+00,  3.25407833e-01,\n",
       "         -3.34136724e+00,  2.87311614e-01,  7.52330399e+00,\n",
       "          3.74660581e-01,  8.65996480e-01,  6.40315652e-01,\n",
       "          1.62681162e+00,  1.91745758e-01, -1.87830448e+00],\n",
       "        [-3.75908554e-01,  3.50878179e-01,  1.20564842e+00,\n",
       "         -2.88916707e-01, -7.74211586e-01,  1.00563276e+00,\n",
       "          6.64613783e-01,  5.14928043e-01, -2.50708520e-01,\n",
       "          1.13067317e+00, -1.68840349e+00,  4.51293975e-01,\n",
       "         -2.66626120e+00,  5.26032543e+00,  1.19786954e+00,\n",
       "          1.92442089e-01,  1.63515019e+00,  9.48958039e-01,\n",
       "          1.71691418e+00,  8.12700808e-01, -1.98976588e+00],\n",
       "        [-3.32383215e-01,  3.81445229e-01,  1.28958023e+00,\n",
       "         -8.64686072e-02, -7.35983133e-01,  1.01598299e+00,\n",
       "          6.21866345e-01,  4.68380481e-01, -2.84149766e-01,\n",
       "          1.05773973e+00, -1.64491320e+00,  4.41070825e-01,\n",
       "         -2.70414686e+00,  5.30235767e+00,  1.19799519e+00,\n",
       "          1.04968369e-01,  1.62224698e+00,  9.92821217e-01,\n",
       "          1.65839720e+00,  8.81470323e-01, -2.02107239e+00],\n",
       "        [ 2.25581944e-01,  2.92596817e-01,  1.00901234e+00,\n",
       "          3.86817753e-01, -7.21147954e-01,  1.14924145e+00,\n",
       "          6.02910221e-01, -1.29501149e-01, -7.95486689e-01,\n",
       "          5.75658083e-01, -1.09683549e+00, -7.16230571e-02,\n",
       "         -3.10163689e+00,  3.64688039e-03,  1.18837488e+00,\n",
       "          5.93295765e+00,  1.05782497e+00,  5.82566798e-01,\n",
       "          1.98286259e+00,  7.71627724e-01, -1.92597687e+00],\n",
       "        [-1.87231869e-01, -4.14714813e-01,  1.52884579e+00,\n",
       "          2.55701661e-01, -8.10099304e-01,  7.28324831e-01,\n",
       "          3.19391966e-01, -3.52424443e-01, -1.00182402e+00,\n",
       "          7.41135240e-01, -1.21717691e+00,  2.36725062e-01,\n",
       "         -3.09213567e+00,  9.25063133e-01,  4.90964144e-01,\n",
       "         -3.89799178e-01,  7.32740521e-01,  7.23059273e+00,\n",
       "          1.97961450e+00,  5.72510481e-01, -2.56404924e+00],\n",
       "        [ 2.17750967e-02,  3.39100778e-01,  1.18728256e+00,\n",
       "          6.78662395e+00, -9.79981244e-01,  8.49874854e-01,\n",
       "          5.33721566e-01,  1.25925809e-01, -7.60800242e-01,\n",
       "          1.17995858e+00, -7.34072208e-01, -3.10393304e-01,\n",
       "         -3.18045974e+00,  5.56591034e-01,  1.22802758e+00,\n",
       "          4.69498903e-01,  1.02608824e+00,  1.22312808e+00,\n",
       "          1.88769484e+00,  9.35000300e-01, -2.25247908e+00],\n",
       "        [ 2.42590189e-01,  7.01645195e-01,  8.54816318e-01,\n",
       "          3.90844285e-01, -5.17098010e-01,  1.41982007e+00,\n",
       "          5.17909348e-01, -3.30866009e-01, -8.43918324e-01,\n",
       "          7.18730152e-01, -1.12749243e+00, -9.74227488e-02,\n",
       "         -3.10205913e+00, -1.09583110e-01,  1.11364472e+00,\n",
       "          6.07623196e+00,  9.91429746e-01,  5.52708030e-01,\n",
       "          1.87218630e+00,  7.55080700e-01, -1.96677375e+00],\n",
       "        [ 4.67516392e-01,  1.32939816e-01,  1.53621817e+00,\n",
       "          2.99842119e-01, -1.94126987e+00,  7.56236970e-01,\n",
       "          8.49097490e-01,  9.68403369e-03, -9.50445712e-01,\n",
       "          7.43919468e+00, -8.85077298e-01,  9.62069035e-02,\n",
       "         -2.81483150e+00,  3.24335545e-02,  8.16176772e-01,\n",
       "          6.09207153e-02,  9.55265939e-01,  6.96144104e-01,\n",
       "          1.02977252e+00,  4.15523231e-01, -2.33350253e+00],\n",
       "        [ 7.18927085e-02,  1.81759432e-01,  1.32742405e+00,\n",
       "         -2.17542171e-01, -1.02931380e+00,  1.10145211e+00,\n",
       "          8.39765429e-01, -8.41537043e-02, -7.78645039e-01,\n",
       "          1.43538189e+00, -1.15107846e+00,  1.27547115e-01,\n",
       "         -2.92108178e+00,  1.54189050e-01,  9.30577278e-01,\n",
       "          5.40182769e-01,  9.56035852e-01,  9.54024196e-01,\n",
       "          1.53693783e+00,  8.05319548e-01, -2.19440556e+00],\n",
       "        [ 2.78871894e-01,  4.66958851e-01,  1.21227932e+00,\n",
       "          6.42599821e+00, -1.30419540e+00,  9.57201838e-01,\n",
       "          7.10532248e-01, -9.91033688e-02, -7.72614777e-01,\n",
       "          1.45687330e+00, -6.46032751e-01, -1.84210151e-01,\n",
       "         -3.31838918e+00,  4.10786331e-01,  1.12984133e+00,\n",
       "          5.65082908e-01,  1.10295630e+00,  1.03657520e+00,\n",
       "          1.87455773e+00,  8.70681882e-01, -2.09701896e+00],\n",
       "        [ 3.03521961e-01,  3.20451766e-01,  1.23731732e+00,\n",
       "          6.38869667e+00, -1.35778522e+00,  9.04978991e-01,\n",
       "          5.86971998e-01, -1.45620331e-01, -7.06897080e-01,\n",
       "          1.44732690e+00, -6.85990512e-01, -1.88599676e-01,\n",
       "         -3.35817957e+00,  4.67005581e-01,  1.16470885e+00,\n",
       "          5.00576913e-01,  1.20231509e+00,  1.00904822e+00,\n",
       "          1.91975307e+00,  8.39303613e-01, -2.14834881e+00],\n",
       "        [-9.95367616e-02, -4.08657610e-01,  1.62034774e+00,\n",
       "         -4.65505421e-02, -1.08600295e+00,  9.25751209e-01,\n",
       "          1.79972857e-01, -6.08353794e-01, -9.64732647e-01,\n",
       "          8.92301679e-01, -1.17248619e+00,  3.93494487e-01,\n",
       "         -3.24662519e+00,  8.34634721e-01,  3.92150164e-01,\n",
       "         -2.56557286e-01,  8.04344237e-01,  7.04482651e+00,\n",
       "          1.92431200e+00,  4.33489263e-01, -2.52174234e+00],\n",
       "        [-7.83215165e-02, -8.99731278e-01,  1.01020765e+00,\n",
       "         -3.42820466e-01, -1.01980245e+00,  1.05198729e+00,\n",
       "          5.82606196e-01,  2.99536467e-01,  5.67364788e+00,\n",
       "          6.59428418e-01, -1.26757622e+00,  5.04718125e-02,\n",
       "         -3.46670985e+00,  6.13837481e-01,  1.58288622e+00,\n",
       "          1.12381935e-01,  9.49579120e-01,  3.84304523e-01,\n",
       "          1.59202051e+00,  7.83166528e-01, -2.67207909e+00],\n",
       "        [ 2.10262656e-01, -4.35286760e-01,  8.81722569e-01,\n",
       "         -1.01629034e-01, -3.91884893e-01,  1.70646286e+00,\n",
       "          8.95078480e-01,  2.89852381e-01, -1.00922668e+00,\n",
       "          9.82572079e-01, -1.09433937e+00,  5.79048395e-01,\n",
       "         -3.21324110e+00,  1.82995498e-01,  1.32586169e+00,\n",
       "          6.79027915e-01,  1.37531030e+00,  5.72274029e-01,\n",
       "          1.39968586e+00,  5.13819337e-01,  4.07923222e+00],\n",
       "        [ 6.05448931e-02, -4.03373778e-01,  8.86391640e-01,\n",
       "         -1.14036188e-01, -3.42874318e-01,  1.72451282e+00,\n",
       "          1.02851236e+00,  3.46793234e-01, -1.05675459e+00,\n",
       "          1.01276922e+00, -1.03868592e+00,  5.92571199e-01,\n",
       "         -3.22958708e+00,  1.54346585e-01,  1.31746113e+00,\n",
       "          6.90004826e-01,  1.27751565e+00,  5.97139418e-01,\n",
       "          1.41175532e+00,  4.80204612e-01,  4.08752251e+00],\n",
       "        [-7.84502178e-02, -3.90814036e-01,  9.31176722e-01,\n",
       "         -1.02578431e-01, -3.34149778e-01,  1.64018440e+00,\n",
       "          1.14410555e+00,  3.96385401e-01, -1.10904515e+00,\n",
       "          1.01654637e+00, -9.13310409e-01,  6.21406794e-01,\n",
       "         -3.24926448e+00,  1.25408158e-01,  1.30179679e+00,\n",
       "          7.04489470e-01,  1.27823269e+00,  6.71664476e-01,\n",
       "          1.43098450e+00,  4.64601278e-01,  4.14980268e+00],\n",
       "        [-1.67461187e-01, -4.10709143e-01,  1.01357579e+00,\n",
       "         -6.55132607e-02, -3.95794809e-01,  1.49996436e+00,\n",
       "          1.17702043e+00,  4.37917173e-01, -1.14646041e+00,\n",
       "          9.70393777e-01, -7.74130225e-01,  6.72403336e-01,\n",
       "         -3.23900223e+00,  1.20907903e-01,  1.28230941e+00,\n",
       "          7.20226288e-01,  1.35158670e+00,  7.40701318e-01,\n",
       "          1.43036389e+00,  4.82489884e-01,  4.25711250e+00],\n",
       "        [-1.61185995e-01, -4.31518137e-01,  1.08635509e+00,\n",
       "         -4.26700562e-02, -4.64917451e-01,  1.38926125e+00,\n",
       "          1.11513591e+00,  4.73717928e-01, -1.18584132e+00,\n",
       "          9.00362194e-01, -6.59450889e-01,  7.15180933e-01,\n",
       "         -3.19151354e+00,  1.24866128e-01,  1.28227067e+00,\n",
       "          7.18794525e-01,  1.44953668e+00,  7.71924734e-01,\n",
       "          1.39637280e+00,  5.15402079e-01,  4.37570286e+00],\n",
       "        [-8.78780633e-02, -4.00901407e-01,  1.12727845e+00,\n",
       "         -5.84094822e-02, -4.92838800e-01,  1.39155674e+00,\n",
       "          9.98648107e-01,  5.34333110e-01, -1.20517457e+00,\n",
       "          8.66632700e-01, -5.90025485e-01,  7.28046119e-01,\n",
       "         -3.10556531e+00,  1.29934743e-01,  1.29396296e+00,\n",
       "          7.16683507e-01,  1.49652863e+00,  7.43730068e-01,\n",
       "          1.34544885e+00,  4.99289811e-01,  4.47055340e+00],\n",
       "        [ 2.87102163e-03, -3.09760213e-01,  1.13800621e+00,\n",
       "         -1.26313716e-01, -4.76015180e-01,  1.48452902e+00,\n",
       "          9.27123725e-01,  6.33399367e-01, -1.17867279e+00,\n",
       "          8.95667791e-01, -5.71555018e-01,  7.11186886e-01,\n",
       "         -3.02007890e+00,  1.50740832e-01,  1.30736232e+00,\n",
       "          6.65922165e-01,  1.46030021e+00,  6.63698673e-01,\n",
       "          1.29862213e+00,  4.24781919e-01,  4.49764109e+00],\n",
       "        [ 4.33976501e-02, -2.01179385e-01,  1.14279342e+00,\n",
       "         -1.98123336e-01, -4.53519821e-01,  1.61011457e+00,\n",
       "          9.54760194e-01,  7.48272538e-01, -1.12067890e+00,\n",
       "          9.95254993e-01, -5.48826456e-01,  6.68821752e-01,\n",
       "         -2.97425437e+00,  1.67422429e-01,  1.30464077e+00,\n",
       "          5.60707033e-01,  1.34172833e+00,  5.60158610e-01,\n",
       "          1.31236935e+00,  3.29920292e-01,  4.45860386e+00]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.debug(\"started a first prediction\")\n",
    "model.predict(datasets[EVAL_TYPE].unbatch().batch(1).take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28df9a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 11:45:07,916 - mmproteo_attention_model: finished a first prediction - Tensorflow should be ready now\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"finished a first prediction - Tensorflow should be ready now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "456b69eb",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/mirko.krause/pdeep/models/mmproteo_transformer_20210816-114501'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04bbca25",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model=model,\n",
    "    to_file=os.path.join(MODEL_PATH, \"model.png\"),\n",
    "    show_shapes=True,\n",
    "    expand_nested=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fd410eda",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mmproteo_transformer_20210816-114501\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "on_device_embedding (OnDevic multiple                  10752     \n",
      "_________________________________________________________________\n",
      "transformer_encoder (Transfo multiple                  18903040  \n",
      "_________________________________________________________________\n",
      "transformer_decoder (Transfo multiple                  25200640  \n",
      "_________________________________________________________________\n",
      "relative_position_embedding  multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 44,114,432\n",
      "Trainable params: 44,114,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(MODEL_PATH, \"summary.txt\"), 'w') as file:\n",
    "    def write_lines(line: str) -> None:\n",
    "        file.write(line)\n",
    "        file.write(\"\\n\")\n",
    "    model.summary(print_fn=write_lines)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2842ef24",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not implemented\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(os.path.join(MODEL_PATH, \"model.json\"), 'w') as file:\n",
    "        file.write(model.to_json())\n",
    "\n",
    "    with open(os.path.join(MODEL_PATH, \"model.yaml\"), 'w') as file:\n",
    "        file.write(model.to_yaml())\n",
    "except NotImplementedError as e:\n",
    "    print(\"not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-queue",
   "metadata": {},
   "source": [
    "## Training the Tensorflow Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3231a086",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e5e4d479",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "TENSORBOARD_LOG_DIR = os.path.join(MODEL_PATH, \"tensorboard\")\n",
    "os.path.realpath(TENSORBOARD_LOG_DIR)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "119f380b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "source": [
    "%tensorboard --logdir $MODELS_PATH --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aafc1c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': 1e-05,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.98,\n",
       " 'epsilon': 1e-09,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3013c477",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "decode_idx: Callable[[np.ndarray], np.ndarray] = np.vectorize(idx_to_char.get)\n",
    "\n",
    "eval_evaluator = evaluation.SequenceEvaluator(\n",
    "    dataset=datasets[EVAL_TYPE],\n",
    "    decode_func=decode_idx,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    separator=\" \",\n",
    "    padding_character=PROCESSING_INFO['padding_characters'][SEQ],\n",
    ")\n",
    "\n",
    "train_evaluator = evaluation.SequenceEvaluator(\n",
    "    dataset=datasets[TRAIN_TYPE],\n",
    "    decode_func=decode_idx,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    separator=\" \",\n",
    "    padding_character=PROCESSING_INFO['padding_characters'][SEQ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5046459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = callbacks.create_callbacks(\n",
    "            tensorboard=True,\n",
    "            progressbar=False,\n",
    "            reduce_lr=False,\n",
    "            early_stopping=False,\n",
    "            checkpoints=True,\n",
    "            csv=False,\n",
    "            base_path=MODEL_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a6d0a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "WARMUP_STEPS = 3000\n",
    "STEPS_PER_EPOCH = 1  # 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "funded-commons",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 11:50:18,065 - mmproteo_attention_model: epoch 1:\n",
      "2021-08-16 11:50:18,069 - mmproteo_attention_model: DEBUG: {'name': 'Adam', 'learning_rate': 2.6895717e-07, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.98, 'epsilon': 1e-09, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 37s 37s/step - loss: 2.6033 - sparse_categorical_accuracy: 0.5653 - jaccard_batch_distance: 0.8598 - leuvenshtein_batch_distance: 2.8613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 11:50:58,109 - mmproteo_attention_model: DEBUG: {'loss': [2.6033127307891846], 'sparse_categorical_accuracy': [0.5652994513511658], 'jaccard_batch_distance': [0.8597973585128784], 'leuvenshtein_batch_distance': [2.861328125]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M V M R N E Q R _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _</td>\n",
       "      <td>N S S V A P T P Q R T V S T S S S S S S A A T S A R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H R H V H I H L R _</td>\n",
       "      <td>A V L E W M K S K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H L H K _ H Y V L M</td>\n",
       "      <td>K Y S I Q G L G K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H L L V R S L R _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _</td>\n",
       "      <td>M A V I C N T C G L P E D L C A C G D L A K D S T K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M M K M F M Y R</td>\n",
       "      <td>E A N Q L R R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               predicted  \\\n",
       "0  M V M R N E Q R _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _   \n",
       "1                                    H R H V H I H L R _   \n",
       "2                                    H L H K _ H Y V L M   \n",
       "3  H L L V R S L R _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _   \n",
       "4                                        M M K M F M Y R   \n",
       "\n",
       "                                                  true  \n",
       "0  N S S V A P T P Q R T V S T S S S S S S A A T S A R  \n",
       "1                                    A V L E W M K S K  \n",
       "2                                    K Y S I Q G L G K  \n",
       "3  M A V I C N T C G L P E D L C A C G D L A K D S T K  \n",
       "4                                        E A N Q L R R  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M S L M M M T G K Q E L M K _ _ _ _ _ _ _ _</td>\n",
       "      <td>L Y P F L K A E L F M H L P P E A L R E K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>H M Q E M C Q Y L E G T H D</td>\n",
       "      <td>G V H V V T V N D Y L A K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>H T V S G H N L T Q L T E N</td>\n",
       "      <td>K Y S T G H S E A I V T R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>H D E L P D L V L S G I N R _ _ _ _ _ _ _ _</td>\n",
       "      <td>L D I V D P D G N L H H G N A K E F A M K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>H S M T I S H I E F L M G K</td>\n",
       "      <td>T F A G K Q G D I Q A L K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     predicted  \\\n",
       "0  M S L M M M T G K Q E L M K _ _ _ _ _ _ _ _   \n",
       "1                  H M Q E M C Q Y L E G T H D   \n",
       "2                  H T V S G H N L T Q L T E N   \n",
       "3  H D E L P D L V L S G I N R _ _ _ _ _ _ _ _   \n",
       "4                  H S M T I S H I E F L M G K   \n",
       "\n",
       "                                        true  \n",
       "0  L Y P F L K A E L F M H L P P E A L R E K  \n",
       "1                  G V H V V T V N D Y L A K  \n",
       "2                  K Y S T G H S E A I V T R  \n",
       "3  L D I V D P D G N L H H G N A K E F A M K  \n",
       "4                  T F A G K Q G D I Q A L K  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-16 11:51:01,500 - mmproteo_attention_model: created new model 'mmproteo_transformer_20210816-115101'\n"
     ]
    }
   ],
   "source": [
    "last_model = None\n",
    "\n",
    "learning_rate = 10**-6\n",
    "slowing_factor = 1\n",
    "\n",
    "first_epoch = 1\n",
    "\n",
    "while True:\n",
    "    error_count = 0\n",
    "    training_dataset = datasets[TRAIN_TYPE].repeat()\n",
    "    validation_dataset = datasets[TEST_TYPE].repeat()\n",
    "    \n",
    "    aborted = False\n",
    "    \n",
    "    for epoch in range(first_epoch, 2):\n",
    "        logger.info(f\"epoch {epoch}:\")\n",
    "        learning_rate = EMBEDDING_WIDTH**-0.5 * min((epoch * STEPS_PER_EPOCH)**-0.5, (epoch * STEPS_PER_EPOCH) * WARMUP_STEPS**-1.5) / slowing_factor\n",
    "        tf.keras.backend.set_value(model.optimizer.learning_rate, learning_rate)\n",
    "        logger.debug(str(model.optimizer.get_config()))\n",
    "\n",
    "        try:\n",
    "            history = model.fit(\n",
    "                x=training_dataset,\n",
    "                validation_data=validation_dataset,\n",
    "                validation_steps=STEPS_PER_EPOCH//5,\n",
    "                epochs=epoch,\n",
    "                steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                callbacks=callback_list,\n",
    "                initial_epoch=epoch-1,\n",
    "            )\n",
    "            logger.debug(str(history.history))\n",
    "        except tf.errors.InvalidArgumentError as e:\n",
    "            logger.warning(f\"Training error: {e}\")\n",
    "            error_count += 1\n",
    "            if error_count > 10:\n",
    "                logger.warning(\"abort training, because of too many NaN loss results\")\n",
    "                break\n",
    "\n",
    "        print(\"Train:\")\n",
    "        eval_df, (x_eval, y_eval, y_pred) = train_evaluator.evaluate_model_visually(\n",
    "            model=model,\n",
    "            sample_size=5,\n",
    "            keep_separator=True,\n",
    "        )\n",
    "        display(eval_df)\n",
    "        \n",
    "        print(\"Eval:\")\n",
    "        eval_df, (x_eval, y_eval, y_pred) = eval_evaluator.evaluate_model_visually(\n",
    "            model=model,\n",
    "            sample_size=5,\n",
    "            keep_separator=True,\n",
    "        )\n",
    "        display(eval_df)\n",
    "        \n",
    "    else:\n",
    "        aborted = True\n",
    "    \n",
    "    if not aborted:\n",
    "        break\n",
    "    \n",
    "    last_model = model\n",
    "    model = create_model()\n",
    "    learning_rate *= 0.5\n",
    "    slowing_factor *= 2\n",
    "    first_epoch = 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "34095f4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I H S K T S K H S K _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _</td>\n",
       "      <td>L S T E D G T S A Y A M T K L L D E F Q S T R Y E R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I Q L T V I R E N R _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _</td>\n",
       "      <td>L M E R P Q I I V A N K M D M P D S E E N L A A F K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               predicted  \\\n",
       "0  I H S K T S K H S K _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _   \n",
       "1  I Q L T V I R E N R _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _   \n",
       "\n",
       "                                                  true  \n",
       "0  L S T E D G T S A Y A M T K L L D E F Q S T R Y E R  \n",
       "1  L M E R P Q I I V A N K M D M P D S E E N L A A F K  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df, _ = train_evaluator.evaluate_model_visually(\n",
    "    model=model,\n",
    "    sample_size=2,\n",
    "    keep_separator=True,\n",
    ")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-laser",
   "metadata": {},
   "source": [
    "## Evaluating the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a30b848",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/78 [========>.....................] - ETA: 7:34 - loss: 2.4821 - sparse_categorical_accuracy: 0.5838 - jaccard_batch_distance: 0.8504 - leuvenshtein_batch_distance: 2.8770"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-ca8fc8509b89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_evaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/hpi/fs00/home/mirko.krause/masterthesis/pride-downloader/mmproteo/src/mmproteo/utils/ml/evaluation.py\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(self, model, steps)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40000\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     def _shorten_sequences_to_lengths_of_other_sequences_with_separator(\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1387\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_evaluator.evaluate_model(model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "caa5592a",
   "metadata": {},
   "source": [
    "target_less_input = {\n",
    "    'inputs': ds[0]['inputs'],\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a151bd1d",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "model.predict(target_less_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

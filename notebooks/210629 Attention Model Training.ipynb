{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lovely-landing",
   "metadata": {},
   "source": [
    "# Training an Attention Model on Tensorflow Datasets\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worth-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Any, Callable, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from IPython.core.display import display\n",
    "from mmproteo.utils import log, paths, utils, visualization\n",
    "from mmproteo.utils.formats.tf_dataset import DatasetLoader\n",
    "from mmproteo.utils.ml import callbacks, evaluation\n",
    "from official.modeling import tf_utils\n",
    "from official.nlp.modeling.models.seq2seq_transformer import Seq2SeqTransformer, TransformerDecoder, TransformerEncoder\n",
    "from official.nlp.modeling.ops import beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "circular-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c53d832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1,3,4,7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6a88dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.debugging.set_log_device_placement(True)\n",
    "GPUs = tf.config.list_physical_devices('GPU')\n",
    "GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-playlist",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "norwegian-therapist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpi/fs00/home/mirko.krause/masterthesis/pride-downloader/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deed6b25",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if os.getcwd() == \"/tf\":\n",
    "    os.chdir(os.path.join('workspace', 'notebooks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987d32ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpi/fs00/home/mirko.krause/masterthesis/pride-downloader/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9012190",
   "metadata": {},
   "source": [
    "PROJECT = \"PXD010000\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d85591d",
   "metadata": {},
   "source": [
    "DUMP_PATH = os.path.join(\"..\", \"dumps\", PROJECT)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7c71bd1",
   "metadata": {},
   "source": [
    "DUMP_PATH = os.path.join(\"/scratch/mirko.krause/dumps/\", PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b98848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMP_PATH = \"/scratch/mirko.krause/pdeep\"\n",
    "TRAINING_COLUMNS_DUMP_PATH = os.path.join(DUMP_PATH, \"training_columns\")\n",
    "FILES_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"file_*.parquet\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b9c4b705",
   "metadata": {},
   "source": [
    "TRAINING_COLUMNS_DUMP_PATH = os.path.join(DUMP_PATH, \"training_columns\")\n",
    "FILES_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"*_mzmlid.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "genuine-dealing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dump path = /scratch/mirko.krause/pdeep\n"
     ]
    }
   ],
   "source": [
    "print(f\"dump path = {DUMP_PATH}\")\n",
    "THREAD_COUNT = min(int(os.cpu_count()/2), 16)\n",
    "STATISTICS_FILE_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"statistics.parquet\")\n",
    "DATASET_DUMP_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"tf_datasets\")\n",
    "PROCESSING_FILE_PATH = os.path.join(DATASET_DUMP_PATH, \"processing_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "interesting-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ = 'peptide_sequence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "certified-gibson",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-08 14:47:06,697 - mmproteo_attention_model: Logging to file '/scratch/mirko.krause/pdeep/mmproteo_attention_model.log' and to stderr\n"
     ]
    }
   ],
   "source": [
    "logger = log.create_logger(\n",
    "    name='mmproteo_attention_model',\n",
    "    verbose=True,\n",
    "    log_dir=DUMP_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93c29d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'padding_characters': {'peptide_sequence': '_',\n",
       "  'mz_array': 0.0,\n",
       "  'intensity_array': 0.0},\n",
       " 'padding_lengths': {'mz_array': 89,\n",
       "  'intensity_array': 89,\n",
       "  'peptide_sequence': 30},\n",
       " 'idx_to_char': {'0': 'A',\n",
       "  '1': 'C',\n",
       "  '2': 'D',\n",
       "  '3': 'E',\n",
       "  '4': 'F',\n",
       "  '5': 'G',\n",
       "  '6': 'H',\n",
       "  '7': 'I',\n",
       "  '8': 'K',\n",
       "  '9': 'L',\n",
       "  '10': 'M',\n",
       "  '11': 'N',\n",
       "  '12': 'P',\n",
       "  '13': 'Q',\n",
       "  '14': 'R',\n",
       "  '15': 'S',\n",
       "  '16': 'T',\n",
       "  '17': 'V',\n",
       "  '18': 'W',\n",
       "  '19': 'Y',\n",
       "  '20': '_'},\n",
       " 'normalization': {'intensity_array': '<function base_peak_normalize at 0x7f9e3ee96af0>'},\n",
       " 'split_value_columns': None,\n",
       " 'training_data_columns': ['mz_array', 'intensity_array'],\n",
       " 'target_data_columns': ['peptide_sequence'],\n",
       " 'element_spec': '((TensorSpec(shape=(89,), dtype=tf.float64, name=None), TensorSpec(shape=(89,), dtype=tf.float64, name=None)), (TensorSpec(shape=(30,), dtype=tf.int8, name=None),))'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(PROCESSING_FILE_PATH, 'r') as file:\n",
    "    PROCESSING_INFO = json.loads(file.read())\n",
    "PROCESSING_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e975803",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_grouping_path_position(cols: Optional[List[str]], prefered_item: str, alternative_index: int = -1) -> int:\n",
    "    res = alternative_index\n",
    "    if cols is not None:\n",
    "        try:\n",
    "            res = cols.index(prefered_item) - len(cols)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1df9537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouping_path_position = find_grouping_path_position(\n",
    "    cols=PROCESSING_INFO['split_value_columns'],\n",
    "    prefered_item='species',\n",
    "    alternative_index=-1,\n",
    ")\n",
    "grouping_path_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73a1f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_char = {int(idx): char for idx, char in PROCESSING_INFO[\"idx_to_char\"].items()}\n",
    "idx_to_char[-1] = \"[start]\"\n",
    "char_to_idx = {char: idx for idx, char in idx_to_char.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-proceeding",
   "metadata": {},
   "source": [
    "## Loading Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee8aadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_CACHE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b34d7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ee8ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_TYPE = 'Train'\n",
    "TEST_TYPE = 'Test'\n",
    "EVAL_TYPE = 'Eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d696d51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assigned dataset files:\n",
      "#Train = 20\n",
      "e.g.: /scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_15.parquet\n",
      "#Test = 3\n",
      "e.g.: /scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_21.parquet\n",
      "#Eval = 3\n",
      "e.g.: /scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_9.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-08 14:47:06,724 - mmproteo_attention_model: DEBUG: assigned values:\n",
      "2021-08-08 14:47:06,724 - mmproteo_attention_model: DEBUG: #Train = 20\n",
      "2021-08-08 14:47:06,724 - mmproteo_attention_model: DEBUG: e.g.: file_15.parquet\n",
      "2021-08-08 14:47:06,724 - mmproteo_attention_model: DEBUG: #Test = 3\n",
      "2021-08-08 14:47:06,725 - mmproteo_attention_model: DEBUG: e.g.: file_21.parquet\n",
      "2021-08-08 14:47:06,725 - mmproteo_attention_model: DEBUG: #Eval = 3\n",
      "2021-08-08 14:47:06,725 - mmproteo_attention_model: DEBUG: e.g.: file_9.parquet\n",
      "2021-08-08 14:47:06,725 - mmproteo_attention_model: DEBUG: assigned paths:\n",
      "2021-08-08 14:47:06,726 - mmproteo_attention_model: DEBUG: #Train = 20\n",
      "2021-08-08 14:47:06,726 - mmproteo_attention_model: DEBUG: e.g.: /scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_15.parquet\n",
      "2021-08-08 14:47:06,726 - mmproteo_attention_model: DEBUG: #Test = 3\n",
      "2021-08-08 14:47:06,726 - mmproteo_attention_model: DEBUG: e.g.: /scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_21.parquet\n",
      "2021-08-08 14:47:06,726 - mmproteo_attention_model: DEBUG: #Eval = 3\n",
      "2021-08-08 14:47:06,726 - mmproteo_attention_model: DEBUG: e.g.: /scratch/mirko.krause/pdeep/training_columns/tf_datasets/file_9.parquet\n",
      "2021-08-08 14:47:06,727 - mmproteo_attention_model: dumped file paths into '/scratch/mirko.krause/pdeep/training_columns/tf_datasets/dataset_file_paths.json'\n"
     ]
    }
   ],
   "source": [
    "dataset_file_paths = paths.assign_wildcard_paths_to_splits_grouped_by_path_position_value(\n",
    "    wildcard_path = os.path.join(\n",
    "        DATASET_DUMP_PATH, \n",
    "        '*.parquet',  # filename\n",
    "        *(PROCESSING_INFO['split_value_columns'] or [])\n",
    "    ),\n",
    "    path_position = grouping_path_position,\n",
    "    splits = {\n",
    "            TRAINING_TYPE: 0.8,\n",
    "            TEST_TYPE: 0.9,\n",
    "            EVAL_TYPE: 1.0\n",
    "        },\n",
    "    paths_dump_file = os.path.join(\n",
    "            DATASET_DUMP_PATH,\n",
    "            \"dataset_file_paths.json\"\n",
    "        ),\n",
    "    skip_existing = KEEP_CACHE,\n",
    "    logger = logger\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"assigned dataset files:\")\n",
    "visualization.print_list_length_in_dict(dataset_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec611252",
   "metadata": {},
   "source": [
    "### Loading corresponding TF datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aeb97f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(89,), dtype=tf.float64, name=None),\n",
       "  TensorSpec(shape=(89,), dtype=tf.float64, name=None)),\n",
       " (TensorSpec(shape=(30,), dtype=tf.int8, name=None),))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_spec = eval(PROCESSING_INFO['element_spec'], {}, {'TensorSpec':tf.TensorSpec, 'tf':tf})\n",
    "element_spec"
   ]
  },
  {
   "cell_type": "raw",
   "id": "facf1aad",
   "metadata": {},
   "source": [
    "element_spec = (\n",
    "    tuple(tf.TensorSpec(shape=(PROCESSING_INFO['padding_lengths'][col],), dtype=tf.float32, name=col)\n",
    "          for col in PROCESSING_INFO['training_data_columns']),\n",
    "    tuple(tf.TensorSpec(shape=(PROCESSING_INFO['padding_lengths'][col],), dtype=tf.int8, name=col)\n",
    "          for col in PROCESSING_INFO['target_data_columns'])\n",
    ")\n",
    "element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195bfe9c",
   "metadata": {},
   "source": [
    "**In the following step, Tensorflow starts allocating a GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b996dc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-08 14:47:06,734 - mmproteo_attention_model: DEBUG: started initializing tensorflow by creating a first dataset\n",
      "2021-08-08 15:11:19,521 - mmproteo_attention_model: finished initializing tensorflow\n"
     ]
    }
   ],
   "source": [
    "# initialize Tensorflow (might take several minutes (~5))\n",
    "logger.debug(\"started initializing tensorflow by creating a first dataset\")\n",
    "tf.data.Dataset.range(5)\n",
    "logger.info(\"finished initializing tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f66eda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_options = tf.data.Options()\n",
    "ds_options.experimental_threading.private_threadpool_size = THREAD_COUNT\n",
    "ds_options.experimental_threading.max_intra_op_parallelism = THREAD_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fbef3700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-08 15:11:19,536 - mmproteo_attention_model: DEBUG: preparing dataset 'Train' with 20 paths\n",
      "2021-08-08 15:11:19,538 - mmproteo_attention_model: DEBUG: applied options to dataset 'Train'\n",
      "2021-08-08 15:11:19,582 - mmproteo_attention_model: DEBUG: loaded dataset 'Train' interleaved\n",
      "2021-08-08 15:11:19,582 - mmproteo_attention_model: DEBUG: shuffled dataset 'Train'\n",
      "2021-08-08 15:11:19,583 - mmproteo_attention_model: DEBUG: batched dataset 'Train'\n",
      "2021-08-08 15:11:19,583 - mmproteo_attention_model: DEBUG: skipped caching dataset 'Train'\n",
      "2021-08-08 15:11:19,583 - mmproteo_attention_model: DEBUG: configured prefetching for dataset 'Train'\n",
      "2021-08-08 15:11:19,584 - mmproteo_attention_model: DEBUG: skipped benchmarking dataset 'Train'\n",
      "2021-08-08 15:11:19,584 - mmproteo_attention_model: prepared dataset 'Train'\n",
      "2021-08-08 15:11:19,584 - mmproteo_attention_model: DEBUG: preparing dataset 'Test' with 3 paths\n",
      "2021-08-08 15:11:19,584 - mmproteo_attention_model: DEBUG: applied options to dataset 'Test'\n",
      "2021-08-08 15:11:19,592 - mmproteo_attention_model: DEBUG: loaded dataset 'Test' interleaved\n",
      "2021-08-08 15:11:19,592 - mmproteo_attention_model: DEBUG: shuffled dataset 'Test'\n",
      "2021-08-08 15:11:19,593 - mmproteo_attention_model: DEBUG: batched dataset 'Test'\n",
      "2021-08-08 15:11:19,593 - mmproteo_attention_model: DEBUG: skipped caching dataset 'Test'\n",
      "2021-08-08 15:11:19,593 - mmproteo_attention_model: DEBUG: configured prefetching for dataset 'Test'\n",
      "2021-08-08 15:11:19,593 - mmproteo_attention_model: DEBUG: skipped benchmarking dataset 'Test'\n",
      "2021-08-08 15:11:19,593 - mmproteo_attention_model: prepared dataset 'Test'\n",
      "2021-08-08 15:11:19,594 - mmproteo_attention_model: DEBUG: preparing dataset 'Eval' with 3 paths\n",
      "2021-08-08 15:11:19,594 - mmproteo_attention_model: DEBUG: applied options to dataset 'Eval'\n",
      "2021-08-08 15:11:19,601 - mmproteo_attention_model: DEBUG: loaded dataset 'Eval' interleaved\n",
      "2021-08-08 15:11:19,601 - mmproteo_attention_model: DEBUG: shuffled dataset 'Eval'\n",
      "2021-08-08 15:11:19,602 - mmproteo_attention_model: DEBUG: batched dataset 'Eval'\n",
      "2021-08-08 15:11:19,602 - mmproteo_attention_model: DEBUG: skipped caching dataset 'Eval'\n",
      "2021-08-08 15:11:19,602 - mmproteo_attention_model: DEBUG: configured prefetching for dataset 'Eval'\n",
      "2021-08-08 15:11:19,602 - mmproteo_attention_model: DEBUG: skipped benchmarking dataset 'Eval'\n",
      "2021-08-08 15:11:19,603 - mmproteo_attention_model: prepared dataset 'Eval'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Train': <PrefetchDataset shapes: (((512, 89), (512, 89)), ((512, 30),)), types: ((tf.float64, tf.float64), (tf.int8,))>,\n",
       " 'Test': <PrefetchDataset shapes: (((512, 89), (512, 89)), ((512, 30),)), types: ((tf.float64, tf.float64), (tf.int8,))>,\n",
       " 'Eval': <PrefetchDataset shapes: (((512, 89), (512, 89)), ((512, 30),)), types: ((tf.float64, tf.float64), (tf.int8,))>}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = DatasetLoader(\n",
    "    element_spec=element_spec,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle_buffer_size=100_000,\n",
    "    thread_count=min(int(os.cpu_count()/4), 4),\n",
    "    keep_cache=KEEP_CACHE,\n",
    "    logger=logger,\n",
    "    run_benchmarks=False,\n",
    "    options=ds_options,\n",
    ").load_datasets_by_type(dataset_file_paths)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1372f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_datasets = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2eb0f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_target_sequences_with_start_token(tensor: tf.Tensor, token: Any = char_to_idx[\"[start]\"]) -> tf.Tensor:\n",
    "    return tf.concat(\n",
    "        values=[\n",
    "            tf.broadcast_to(\n",
    "                input=tf.constant(token, dtype=tensor.dtype),\n",
    "                shape=(\n",
    "                    tensor.shape[0],  # batch dimension\n",
    "                    1\n",
    "                )\n",
    "            ),\n",
    "            tensor\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "def _dataset_mapper_for_transformer(trainings: Tuple[tf.Tensor], targets: Tuple[tf.Tensor]):\n",
    "    inputs = tf.stack(trainings, axis=-1)[:, :500, :]  # cut off too long spectra\n",
    "    inputs = tf.cast(x=inputs, dtype=tf.float32)\n",
    "    targets = prefix_target_sequences_with_start_token(targets[0])\n",
    "    targets = tf.cast(\n",
    "        x=targets,\n",
    "        dtype=tf.int32,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        {\n",
    "            \"inputs\": inputs,\n",
    "            \"targets\": targets[:, :-1],\n",
    "        },\n",
    "        targets[:, 1:]\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_dataset_for_transformer_training(dataset: tf.data.Dataset) -> tf.data.Dataset:\n",
    "    return dataset.map(_dataset_mapper_for_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a08cd1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train': <MapDataset shapes: ({inputs: (512, 89, 2), targets: (512, 30)}, (512, 30)), types: ({inputs: tf.float32, targets: tf.int32}, tf.int32)>,\n",
       " 'Test': <MapDataset shapes: ({inputs: (512, 89, 2), targets: (512, 30)}, (512, 30)), types: ({inputs: tf.float32, targets: tf.int32}, tf.int32)>,\n",
       " 'Eval': <MapDataset shapes: ({inputs: (512, 89, 2), targets: (512, 30)}, (512, 30)), types: ({inputs: tf.float32, targets: tf.int32}, tf.int32)>}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {\n",
    "    t: prepare_dataset_for_transformer_training(dataset) for t, dataset in original_datasets.items()\n",
    "}\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "375b64be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'inputs': array([[[1.14091339e+02, 3.01591037e-08],\n",
       "           [1.47112808e+02, 3.97747666e-01],\n",
       "           [2.28134262e+02, 2.60805488e-01],\n",
       "           [2.60196869e+02, 1.95804238e-01],\n",
       "           [3.52175812e+02, 3.15665284e-06],\n",
       "           [3.56229218e+02, 1.13708057e-01],\n",
       "           [3.68207092e+02, 1.44059986e-05],\n",
       "           [3.88291840e+02, 2.60961384e-01],\n",
       "           [4.16223297e+02, 7.17253890e-04],\n",
       "           [4.32254578e+02, 4.51065809e-01],\n",
       "           [4.72765320e+02, 5.32167554e-02],\n",
       "           [4.87269714e+02, 1.70016393e-01],\n",
       "           [4.89276062e+02, 9.18137014e-01],\n",
       "           [5.03318787e+02, 1.03451699e-01],\n",
       "           [5.88317383e+02, 2.66146045e-02],\n",
       "           [6.04366455e+02, 4.93628949e-01],\n",
       "           [7.03344360e+02, 1.19832374e-01],\n",
       "           [7.35406921e+02, 1.00000000e+00],\n",
       "           [8.31439270e+02, 1.11871444e-01],\n",
       "           [8.63501892e+02, 5.70329070e-01],\n",
       "           [9.44523376e+02, 1.24598801e-01],\n",
       "           [9.77544800e+02, 2.09261268e-01],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00],\n",
       "           [0.00000000e+00, 0.00000000e+00]]], dtype=float32),\n",
       "   'targets': array([[-1,  7, 11,  8, 10, 16,  2,  8,  9,  8, 20, 20, 20, 20, 20, 20,\n",
       "           20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]],\n",
       "         dtype=int32)},\n",
       "  array([[ 7, 11,  8, 10, 16,  2,  8,  9,  8, 20, 20, 20, 20, 20, 20, 20,\n",
       "          20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]],\n",
       "        dtype=int32))]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(datasets['Train'].unbatch().batch(1).take(1).as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "767ec869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original datasets:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a83a3c3c70b4330a8893706a91d36f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Summary ************\n",
      "\n",
      "Examples/sec (First included) 225.50 ex/sec (total: 5856 ex, 25.97 sec)\n",
      "Examples/sec (First only) 1.53 ex/sec (total: 1 ex, 0.65 sec)\n",
      "Examples/sec (First excluded) 231.29 ex/sec (total: 5855 ex, 25.31 sec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>BenchmarkResult:</strong><br/><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first+lasts</th>\n",
       "      <td>25.968448</td>\n",
       "      <td>5856</td>\n",
       "      <td>225.504427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>0.653664</td>\n",
       "      <td>1</td>\n",
       "      <td>1.529837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasts</th>\n",
       "      <td>25.314784</td>\n",
       "      <td>5855</td>\n",
       "      <td>231.287775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BenchmarkResult(stats=              duration  num_examples         avg\n",
       "first+lasts  25.968448          5856  225.504427\n",
       "first         0.653664             1    1.529837\n",
       "lasts        25.314784          5855  231.287775, raw_stats=                      duration\n",
       "start_time        3.990987e+06\n",
       "first_batch_time  3.990988e+06\n",
       "end_time          3.991013e+06\n",
       "num_iter          5.856000e+03)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mapped datasets:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cdfbe99be64686954713b42d81ccb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Summary ************\n",
      "\n",
      "Examples/sec (First included) 230.34 ex/sec (total: 5856 ex, 25.42 sec)\n",
      "Examples/sec (First only) 1.84 ex/sec (total: 1 ex, 0.54 sec)\n",
      "Examples/sec (First excluded) 235.33 ex/sec (total: 5855 ex, 24.88 sec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>BenchmarkResult:</strong><br/><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first+lasts</th>\n",
       "      <td>25.423216</td>\n",
       "      <td>5856</td>\n",
       "      <td>230.340648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>0.543703</td>\n",
       "      <td>1</td>\n",
       "      <td>1.839240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasts</th>\n",
       "      <td>24.879513</td>\n",
       "      <td>5855</td>\n",
       "      <td>235.334188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BenchmarkResult(stats=              duration  num_examples         avg\n",
       "first+lasts  25.423216          5856  230.340648\n",
       "first         0.543703             1    1.839240\n",
       "lasts        24.879513          5855  235.334188, raw_stats=                      duration\n",
       "start_time        3.991013e+06\n",
       "first_batch_time  3.991014e+06\n",
       "end_time          3.991038e+06\n",
       "num_iter          5.856000e+03)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"original datasets:\")\n",
    "display(tfds.benchmark(original_datasets[TEST_TYPE]))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"mapped datasets:\")\n",
    "display(tfds.benchmark(datasets[TEST_TYPE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-company",
   "metadata": {},
   "source": [
    "## Building the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ce6bb7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heavily based on:\n",
    "# https://github.com/tensorflow/models/blob/061c58a3937953c79819fd4e8826af1570cb6024/official/nlp/transformer/transformer.py\n",
    "# (29.06.2021)\n",
    "class MyTransformer(Seq2SeqTransformer):\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Calculate target logits or inferred target sequences.\n",
    "        Args:\n",
    "          inputs: a dictionary of tensors.\n",
    "            Feature `inputs`: int tensor with shape `[batch_size, input_length]`.\n",
    "            Feature `targets` (optional): None or int tensor with shape\n",
    "              `[batch_size, target_length]`.\n",
    "        Returns:\n",
    "          If targets is defined, then return logits for each word in the target\n",
    "          sequence, which is a float tensor with shape\n",
    "          `(batch_size, target_length, vocab_size)`. If target is `None`, then\n",
    "          generate output sequence one token at a time and\n",
    "          returns a dictionary {\n",
    "              outputs: `(batch_size, decoded_length)`\n",
    "              scores: `(batch_size, 1)`}\n",
    "          Even when `float16` is used, the output tensor(s) are always `float32`.\n",
    "        Raises:\n",
    "          NotImplementedError: If try to use padded decode method on CPU/GPUs.\n",
    "        \"\"\"\n",
    "        sources = inputs[\"inputs\"]\n",
    "        targets = inputs.get(\"targets\", None)\n",
    "        # Prepare inputs to the layer stack by adding positional encodings and\n",
    "        # applying dropout.\n",
    "\n",
    "        \n",
    "        # maybe just transform the MZ values in the same way as the positional embedding, \n",
    "        # multiply it with the broadcasted intensities\n",
    "        # from: https://github.com/tensorflow/models/blob/027813d334645d6076a72b41b7b87ec30334cbb1/official/nlp/modeling/layers/position_embedding.py#L91\n",
    "        sources = self.source_embedding(sources)\n",
    "        # Attention_mask generation.\n",
    "        input_shape = tf_utils.get_shape_list(sources, expected_rank=3)\n",
    "        batch_size = input_shape[0]\n",
    "        input_length = input_shape[1]\n",
    "        channel_count = input_shape[2]\n",
    "        non_padding_sources = tf.not_equal(sources[:, :, 0], 0.0)\n",
    "        non_padding_sources = tf.reshape(\n",
    "            tensor=non_padding_sources,\n",
    "            shape=[batch_size, 1, input_length]\n",
    "        )\n",
    "        attention_mask = tf.cast(\n",
    "            x=non_padding_sources,\n",
    "            dtype=sources.dtype\n",
    "        )\n",
    "        broadcast_ones = tf.ones(\n",
    "            shape=[batch_size, input_length, 1],\n",
    "            dtype=sources.dtype\n",
    "        )\n",
    "        attention_mask = broadcast_ones * attention_mask\n",
    "\n",
    "#        pos_encoding = self.position_embedding(sources)\n",
    "#        pos_encoding = tf.cast(pos_encoding, sources.dtype)\n",
    "#        encoder_inputs = sources + pos_encoding\n",
    "#        encoder_inputs = self.encoder_dropout(encoder_inputs)\n",
    "        encoder_inputs = self.encoder_dropout(sources)\n",
    "\n",
    "        encoder_outputs = self.encoder_layer(\n",
    "            encoder_inputs, attention_mask=attention_mask)\n",
    "\n",
    "        if targets is None:\n",
    "            if self._padded_decode:\n",
    "                max_decode_length = self._decode_max_length\n",
    "            else:\n",
    "                max_decode_length = self._decode_max_length or (\n",
    "                        tf.shape(encoder_outputs)[1] + self._extra_decode_length)\n",
    "            symbols_to_logits_fn = self._get_symbols_to_logits_fn(max_decode_length)\n",
    "\n",
    "            batch_size = tf.shape(encoder_outputs)[0]\n",
    "            # Create initial set of IDs that will be passed to symbols_to_logits_fn.\n",
    "            initial_ids = tf.zeros([batch_size], dtype=tf.int32)\n",
    "\n",
    "            # Create cache storing decoder attention values for each layer.\n",
    "            init_decode_length = (max_decode_length if self._padded_decode else 0)\n",
    "            num_heads = self.decoder_layer.num_attention_heads\n",
    "            dim_per_head = self._embedding_width // num_heads\n",
    "\n",
    "            # Cache dtype needs to match beam_search dtype.\n",
    "            # pylint: disable=g-complex-comprehension\n",
    "            cache = {\n",
    "                str(layer): {\n",
    "                    \"key\":\n",
    "                        tf.zeros(\n",
    "                            [batch_size, init_decode_length, num_heads, dim_per_head],\n",
    "                            dtype=self.compute_dtype),\n",
    "                    \"value\":\n",
    "                        tf.zeros(\n",
    "                            [batch_size, init_decode_length, num_heads, dim_per_head],\n",
    "                            dtype=self.compute_dtype)\n",
    "                } for layer in range(self.decoder_layer.num_layers)\n",
    "            }\n",
    "            # pylint: enable=g-complex-comprehension\n",
    "\n",
    "            # Add encoder output and attention bias to the cache.\n",
    "            encoder_outputs = tf.cast(encoder_outputs, dtype=self.compute_dtype)\n",
    "            attention_mask = tf.cast(\n",
    "                tf.reshape(\n",
    "                    tf.not_equal(sources, 0), [input_shape[0], 1, input_shape[1]]),\n",
    "                dtype=self.compute_dtype)\n",
    "            cache[\"encoder_outputs\"] = encoder_outputs\n",
    "            cache[\"encoder_decoder_attention_mask\"] = attention_mask\n",
    "\n",
    "            # Use beam search to find the top beam_size sequences and scores.\n",
    "            decoded_ids, scores = beam_search.sequence_beam_search(\n",
    "                symbols_to_logits_fn=symbols_to_logits_fn,\n",
    "                initial_ids=initial_ids,\n",
    "                initial_cache=cache,\n",
    "                vocab_size=self._vocab_size,\n",
    "                beam_size=self._beam_size,\n",
    "                alpha=self._alpha,\n",
    "                max_decode_length=max_decode_length,\n",
    "                eos_id=self._eos_id,\n",
    "                padded_decode=self._padded_decode,\n",
    "                dtype=self.compute_dtype)\n",
    "\n",
    "            # Get the top sequence for each batch element\n",
    "            top_decoded_ids = decoded_ids[:, 0, 1:]\n",
    "            top_scores = scores[:, 0]\n",
    "\n",
    "            return {\"outputs\": top_decoded_ids, \"scores\": top_scores}\n",
    "\n",
    "        decoder_inputs = self.embedding_lookup(targets)\n",
    "        embedding_mask = tf.cast(tf.not_equal(targets, 0), decoder_inputs.dtype)\n",
    "        decoder_inputs *= tf.expand_dims(embedding_mask, -1)\n",
    "        # Shift targets to the right, and remove the last element\n",
    "        decoder_inputs = tf.pad(decoder_inputs, [[0, 0], [1, 0], [0, 0]])[:, :-1, :]\n",
    "        \n",
    "        length = tf.shape(decoder_inputs)[1]\n",
    "        pos_encoding = self.position_embedding(decoder_inputs)\n",
    "        pos_encoding = tf.cast(pos_encoding, decoder_inputs.dtype)\n",
    "        decoder_inputs += pos_encoding\n",
    "\n",
    "        decoder_inputs = self.decoder_dropout(decoder_inputs)\n",
    "\n",
    "        decoder_shape = tf_utils.get_shape_list(decoder_inputs, expected_rank=3)\n",
    "        batch_size = decoder_shape[0]\n",
    "        decoder_length = decoder_shape[1]\n",
    "\n",
    "        self_attention_mask = tf.linalg.band_part(tf.ones([length, length]), -1, 0)\n",
    "        self_attention_mask = tf.reshape(self_attention_mask, [1, length, length])\n",
    "        self_attention_mask = tf.tile(self_attention_mask, [batch_size, 1, 1])\n",
    "\n",
    "        attention_mask = tf.cast(\n",
    "            tf.expand_dims(tf.not_equal(sources[:, :, 0], 0), axis=1), dtype=sources.dtype)\n",
    "        attention_mask = tf.tile(attention_mask, [1, decoder_length, 1])\n",
    "\n",
    "        outputs = self.decoder_layer(\n",
    "            decoder_inputs,\n",
    "            encoder_outputs,\n",
    "            memory_mask=self_attention_mask,\n",
    "            target_mask=attention_mask)\n",
    "        \n",
    "        logits = self._embedding_linear(self.embedding_lookup.embeddings, outputs)\n",
    "        # Model outputs should be float32 to avoid numeric issues.\n",
    "        # https://www.tensorflow.org/guide/mixed_precision#building_the_model\n",
    "        logits = tf.cast(logits, tf.float32)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ca01dcb",
   "metadata": {},
   "source": [
    "TRANSFORMER_LAYERS = 8\n",
    "ATTENTION_HEADS = 2\n",
    "EMBEDDING_WIDTH = 32\n",
    "LEARNING_RATE=10**-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76512ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_LAYERS = 5\n",
    "ATTENTION_HEADS = 16\n",
    "EMBEDDING_WIDTH = 512  # d_model\n",
    "LEARNING_RATE = 10**-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e8a95a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.training.Model"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f33aa872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model() -> tf.keras.Model:\n",
    "    encoder_layer = TransformerEncoder(\n",
    "        num_attention_heads=ATTENTION_HEADS,\n",
    "        num_layers=TRANSFORMER_LAYERS,\n",
    "    )\n",
    "    decoder_layer = TransformerDecoder(\n",
    "        num_attention_heads=ATTENTION_HEADS,\n",
    "        num_layers=TRANSFORMER_LAYERS,\n",
    "    )\n",
    "\n",
    "    model = MyTransformer(\n",
    "        vocab_size=len(idx_to_char),\n",
    "        embedding_width=EMBEDDING_WIDTH,\n",
    "        encoder_layer=encoder_layer,\n",
    "        decoder_layer=decoder_layer,\n",
    "        name=f\"mmproteo_transformer_{utils.get_current_time_str()}\",\n",
    "        decode_max_length=PROCESSING_INFO['padding_lengths'][SEQ],\n",
    "    )\n",
    "    # create a new embedding layer that will be used in the overridden call method\n",
    "    model.source_embedding = tf.keras.layers.Conv1D(\n",
    "        filters=EMBEDDING_WIDTH,\n",
    "        kernel_size=1,\n",
    "        activation=None,\n",
    "        padding='same',\n",
    "        name=\"source_embedding\",\n",
    "        use_bias=False,\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(\n",
    "            #clipvalue=1.0,\n",
    "            learning_rate=LEARNING_RATE,\n",
    "            beta_2=0.98,\n",
    "            epsilon=10**-9,\n",
    "        ),\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),  #masked_loss,\n",
    "        metrics=[\n",
    "            tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96a40234",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    }
   ],
   "source": [
    "mirrored_strategy = tf.distribute.MirroredStrategy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfb3c229",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_PATH = os.path.join(DUMP_PATH, \"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a9c2155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model() -> tf.keras.Model:\n",
    "    with mirrored_strategy.scope():\n",
    "        model = build_model()\n",
    "    global MODEL_PATH\n",
    "    MODEL_PATH = os.path.join(MODELS_PATH, model.name)\n",
    "    utils.ensure_dir_exists(MODEL_PATH)\n",
    "    logger.info(f\"created new model '{model.name}'\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "470528b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-08 16:27:06,006 - mmproteo_attention_model: created new model 'mmproteo_transformer_20210808-162705'\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9d4032e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-08 16:27:06,176 - mmproteo_attention_model: DEBUG: started a first prediction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 30 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2838220c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "         nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.debug(\"started a first prediction\")\n",
    "model.predict(datasets[EVAL_TYPE].unbatch().batch(1).take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "101d135c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-08 16:27:16,097 - mmproteo_attention_model: finished a first prediction - Tensorflow should be ready now\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"finished a first prediction - Tensorflow should be ready now\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59911047",
   "metadata": {},
   "source": [
    "# to define an input for the model because of a missing input layer\n",
    "model.fit(\n",
    "    x=datasets[TRAINING_TYPE].repeat(),\n",
    "    epochs=1,\n",
    "    steps_per_epoch=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "456b69eb",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/mirko.krause/pdeep/models/mmproteo_transformer_20210808-151211'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04bbca25",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbUAAAA8CAIAAABuALMuAAAABmJLR0QA/wD/AP+gvaeTAAAN/0lEQVR4nO3dfUwT5x8A8G9pC7RdKYisvNUNGS8DsWxMB2OmCDIg0BAbGNuUzESBZfE9kLm5MJMtMxrD5qIJE8wyjW4giTgC0yniNqHNGAoTDYhb3Ka8rAVkvJVRuN8fl9/tbK/Xa3uKi9/PX9zDc9/n5dovd89di4AgCEAIIWTDY6E7gBBCjyjMjwghxAzzI0IIMcP8iBBCzET0Db1eX1FRsVBdQQihhZWUlLRz505q877zxz///LOuru6hdwkhhBaewWDQ6/X0EpFtpVOnTj2s/iCE0KMiPz/fqgTXHxFCiBnmR4QQYob5ESGEmGF+RAghZpgfEUKIGeZHhBBihvkRIYSYYX5ECCFmmB8RQogZ5keEEGKG+REhhJhhfkQIIWaYHxFCiBnmR3Sfmpqa+Ph4iUQiEAgEAkF3d/dC94gfo6OjlZWVqampixYtkkgkERER69at6+rqsq3Z2dmZnZ3t6+srl8vXrFnT2trqWhwAaGpqioyMFIkYviWLS1sAYLFYjh49unLlSn9/fz8/v4SEhEOHDv3zzz8PKI4Lo3j55ZcFNrZv3+5UHH5nlWMdTgiampoaqxL0WLl8+bJAICgrKxsfH79161ZoaOi1a9cWulP82Lhxo0gk+vTTTwcGBiYnJ3/44YeYmBihUHj69Gl6NYPBIJFICgoK+vv7jUZjUVGRSCQ6d+6cs3Fu3bql1WqXL1/u4+MjFAoZu+SwLYIg1q9fDwDvvvvu0NCQyWTat28fAOTk5DyIOLa4jCI5Odk2q2zbts2pODzOKpc69uTl5eXl5dFLMD8SMpksOTn5cWjUoW3btgHAnTt3Froj/Nu4cWNxcTG9pLOzEwAiIiKokrm5udjY2KCgoKmpKbLEYrFERUWpVCqz2cw9DkEQr7/++t69e2dnZ0NCQhjfpVza+vXXXwHgueeeo++Ynp4OAD/99BO/cRg5HAVBEMnJye3t7SxBuMTha1Y51rEH8yMDzI8UnU4HANPT0wvdkYdEIpF4eHjMz8+Tmy0tLQCwZcsWep09e/YAQF1dHfc4BEFQ2creu5RLW5cuXQKAN954g15ny5Yt9Dp8xWHkcBQEt/zIJY4tF2bV5bZItvkR1x/Rv+bm5ha6Cw/P5OTk9PT0smXLBAIBWXLx4kUAeOGFF+jVyM3m5mbucQBAIpGwt86lrejoaLFY3NPTQ6/T09MjEAji4uL4jcPI4Sg4ciGOa7PqWlssnM6P9fX11Crs77//XlBQIJfL/f39CwsLR0dHb9++rdVq5XJ5UFBQUVHR+Pi4O3sdOHCA3CU0NLS9vT0tLU0ul0ul0tWrV1Mr0PTIvb29r776qr+/P7lpMpkAYHh4eOfOneHh4Z6enn5+fllZWeSfXCr+5ORka2sruQt9QddoNG7duvXpp5/29PQMCAjQ6XTkOT+FJTILe42yD8RisdTU1KSnpwcGBkokkri4uIMHD87Pz9tOwu3btwsKCnx9ff39/XNycshrK9LMzEx5eXl0dLRUKl20aJFWq/3mm2/InEhGOHPmDACQN2cSExMdDpOlz9XV1S4ccYcz7/Bwc0f+H5Hdu3dTJWQGCQ0NpVcLCQkBgJs3b3KPwwWXtpRK5YEDB7q6ut577z2j0TgyMrJ///4LFy6Ul5dHRkbyG8cdx48fj4+Pl8lkCoVi1apVJ0+edD+ma7PKP/rJJPfr69zcXADQ6XQ///zzxMTEsWPHACArKys3N/fq1avj4+OVlZUAsGPHDvf3UqvVMpksKSmpra1tYmKivb19+fLlnp6ely5dsoqs0WhaWlomJycNBoNQKDQajQMDA2FhYUqlsqGhYWxsrLe3V6fTCQSCqqoqal/GS93+/v6nnnpKqVQ2NjaOj493d3drNBpvb++2tjayApfILOxdX9sbSENDAwB8/PHHIyMjRqPxs88+8/DwKC0ttd03NzeXnKjz589LJJIVK1ZQFTZt2qRQKL777rupqanBwcHS0lIAaGlpsYpAv77mMkx7fSZcOuIOZ569RY4GBweVSuWmTZvoheSSnMFgoBf29fUBwPPPP889Dp29qzzubdXW1lLpb/HixUePHn0QcdixX18XFhZ2dHRMTEz09PQUFhaCzfU+lzh0Ls+qC23R8bb+SL5AGxsbqZLY2FgA+P7776mSsLCwqKgo9/dSq9UAcPXqVarkl19+AQC1Wm0VuampyaqfGzZsAICvvvqKKjGbzcHBwRKJZHBwkCxhTFVvvvkmAJw4cYIqGRgY8PLySkhI4B6ZBXt+tB1IQ0NDSkoKvWT9+vVisXhsbMxq34aGBqokLy8PAKjEERYW9tJLL9GDREZGsudHLsO012fCpSPucObZW+TCZDLFx8cXFBRYLBZ6OWOuIc/C6K07jEPnVH60amt+fr6oqEgsFldUVAwODhqNxs8//5y8VT07O8tvHHZO5ZqVK1fadol7HHdm1dk6Vnhef6SvegQHB1uVhISE9Pf387KXTCaLj4+nNuPi4oKDg7u6ugYGBujVyANDd/r0aQDIzs6mSry8vNLS0qanp8+dO8cytPr6eg8Pj5ycHKokMDAwNja2o6Pjzp077kTmwnYgOTk5VhfvarV6dnb2+vXrVjVXrFhB/axSqQCAms/MzMy2trbi4mKDwUBeVvf29qakpLD0hPswbftMceqIO5x5Li2ymJyczMjIiImJOXHihFAopP/K19eXrGBVn/oVxzhccGnr+PHjVVVVb7311o4dO5RK5eLFi4uLi3ft2lVTU3Po0CEe43R3d9OfXty8ebOzw6Ej/yqTVzzOcnNWeedWfvTx8fk3kIeHUCiUSqVUiVAopBbI3NzL9tX55JNPAsBff/1FL5TJZPTNmZmZsbExb29vuVxOL1cqlQAwODhob1zkjvPz8wqFgv66uXLlCgD09fW5HJkjq4EAwNjYWHl5eVxcnJ+fH9mZsrIyAJiamrKqqVAoqJ89PT0BgJrPw4cPHzt27LfffktLS/Px8cnMzCTTnz1ODdO2zxTuR9zhzHNs0R6LxZKfnx8SEvLll1/avv2io6MBwCoL3717FwCs1unY43DBpa2zZ88CwJo1a+h10tLSAODbb7/lMc6yZcvoJ01U8nVNUFAQ2Lw3uXB/Vnn337h/PTw8TBAEvYScfTJL2uPl5aVQKMxms9Xy/9DQEAAEBgaSm/QbZNSOvr6+IpGI8epj9erVHCOzsG2UnVar/fDDD4uKim7evEk+8fDJJ58AgNW0OGy0sLDwwoUL9+7dq6+vJwhCp9NVVFTYq+/+MJ3lcObdjF9SUjIzM1NbW0vdiHvmmWcMBgP5Mxm/o6ODvgu5SWYTjnG44NKW1Vkh3cTEBL9xeEReDbC/Nxm5P6u8+2/kR7PZ3N7eTm1eu3atv79frVaTf6lYrF27FgAaGxupkpmZmebmZolEkpGRQZZIpVLqg1ZRUVFHjhwBAJ1OZ7FYrD6ntW/fviVLllgsFo6RWTA2as/c3Fxra2tgYODWrVsDAgLI3Do9Pe2wFSu+vr7k7U6xWJyenk7eC6YPwZabw3SBw5l32Z49e65fv37mzBkvLy/GChqNJiYmpq6uzmw2kyVzc3Nff/21SqWirzA4jMMFl7ZefPFFsHm0iHygh3q6gK84rqmurk5ISKCXEARRW1sLAFqt1qlQvMwq/+h/n529P0NfyM/IyLBaDdVoNDKZzP291Gq1QqFIS0tzeP/a9sFm+u3Xv//+m7r9euTIEapOZmamQqH4448/2traRCLRjRs3CIIYGhoKDw9funRpU1PTvXv3hoeHKysrpVJpTU0N98gsGBtlGUhqaioA7N+/32g0Tk1NXbx4ccmSJQBw/vx5lkl45513gHZrS6FQaDSarq4us9k8NDREPkX80UcfsUTgMkx7fWb8lcMj7nDm2Vu054svvrD3FtDr9VQ1vV7v7e392muvDQwMmEymkpISkUh09uxZZ+NQWO4SOGxrdHQ0IiJCLBYfPHiQ/FxgdXW1VColV2x5j8PC3iiqqqoA4O233+7r65uenu7p6Vm3bh04f/+ax1l1qo4VHu5f6/V6eu93795NP7MDgL179/7444/0kg8++MC1vcgW1Wp1SEjIjRs3MjIy5HK5RCLRaDSXL19m7I9t/00m0/bt28PCwsRisUKhyMjIaG5uplfo6elZtWqVTCZTqVSHDx+mysnn/pYuXSoWiwMCAl555RV6MuISmYVto+wDMRqNJSUlKpVKLBYrlcoNGzbs2rWLrJaQkGA7vcT9193Z2dkEQXR2dpaUlDz77LPk84+JiYlVVVXk1brtQiT1umQZJkuf3TniLDPv8HDbQz8BtDdS0pUrV7Kysnx8fJ544onU1FTqleZUHMa7E7bPfrG3RRDEyMhIWVlZdHS0l5eXp6dneHj45s2bbR+Q4CuOFYejMJvNp06dWrt2bXh4OLkak5KScvLkSWfj8DirHGeekW1+FBC0N1JtbW1BQQHhzJLWQxAfH28ymaxWoBFCiF/5+fnw/0fTSf+N9UeEEHr4MD8ihBCzRzo/kh9V7urqunv3rkAgeP/99xe6R1wJ7CPviiDe4Zwj3rn9/boPUmlpKfkZ4f+cR20N93GAc45490ifPyKE0ALC/IgQQswwPyKEEDPMjwghxAzzI0IIMcP8iBBCzDA/IoQQM8yPCCHEDPMjQggxw/yIEELMMD8ihBAzzI8IIcQM8yNCCDFj+P4e8kt0EULosWIwGKz+Ydl9548qlYr8394IIfS4SUxMTEpKopcI8FvzEEKIEa4/IoQQM8yPCCHEDPMjQggxw/yIEELM/gfjIYob+MjJpgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model=model,\n",
    "    to_file=os.path.join(MODEL_PATH, \"model.png\"),\n",
    "    show_shapes=True,\n",
    "    expand_nested=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd410eda",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mmproteo_transformer_20210808-151211\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "on_device_embedding (OnDevic multiple                  11264     \n",
      "_________________________________________________________________\n",
      "transformer_encoder (Transfo multiple                  15752704  \n",
      "_________________________________________________________________\n",
      "transformer_decoder (Transfo multiple                  21000704  \n",
      "_________________________________________________________________\n",
      "relative_position_embedding  multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "source_embedding (Conv1D)    multiple                  1024      \n",
      "=================================================================\n",
      "Total params: 36,765,696\n",
      "Trainable params: 36,765,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(MODEL_PATH, \"summary.txt\"), 'w') as file:\n",
    "    def write_lines(line: str) -> None:\n",
    "        file.write(line)\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "\n",
    "    model.summary(print_fn=write_lines)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2842ef24",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not implemented\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(os.path.join(MODEL_PATH, \"model.json\"), 'w') as file:\n",
    "        file.write(model.to_json())\n",
    "\n",
    "    with open(os.path.join(MODEL_PATH, \"model.yaml\"), 'w') as file:\n",
    "        file.write(model.to_yaml())\n",
    "except NotImplementedError as e:\n",
    "    print(\"not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-queue",
   "metadata": {},
   "source": [
    "## Training the Tensorflow Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc3828bd",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75be20b6",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "source": [
    "TENSORBOARD_LOG_DIR = os.path.join(MODEL_PATH, \"tensorboard\")\n",
    "os.path.realpath(TENSORBOARD_LOG_DIR)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "119f380b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "source": [
    "%tensorboard --logdir $MODELS_PATH --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aafc1c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': 1e-05,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.98,\n",
       " 'epsilon': 1e-09,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5751664a",
   "metadata": {},
   "source": [
    "model.optimizer.amsgrad = False\n",
    "model.optimizer.clipvalue = None"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ec52183",
   "metadata": {},
   "source": [
    "# to reset the learning_rate after it has been decreased by the reduce_lr callback\n",
    "tf.keras.backend.set_value(model.optimizer.learning_rate, 10**-3)\n",
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3013c477",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "decode_idx: Callable[[np.ndarray], np.ndarray] = np.vectorize(idx_to_char.get)\n",
    "\n",
    "evaluator = evaluation.SequenceEvaluator(\n",
    "    dataset=datasets[EVAL_TYPE],\n",
    "    decode_func=decode_idx,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    separator=\" \",\n",
    "    padding_character=PROCESSING_INFO['padding_characters'][SEQ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5046459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = callbacks.create_callbacks(\n",
    "            tensorboard=True,\n",
    "            progressbar=False,\n",
    "            reduce_lr=False,\n",
    "            early_stopping=False,\n",
    "            checkpoints=True,\n",
    "            csv=False,\n",
    "            base_path=MODEL_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a6d0a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "WARMUP_STEPS = 4000\n",
    "STEPS_PER_EPOCH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "funded-commons",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-08 16:24:34,881 - mmproteo_attention_model: epoch 1:\n",
      "2021-08-08 16:24:34,890 - mmproteo_attention_model: DEBUG: {'name': 'Adam', 'learning_rate': 1e-07, 'decay': 0.0, 'beta_1': 0.9, 'beta_2': 0.98, 'epsilon': 1e-09, 'amsgrad': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 156 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 156 all-reduces with algorithm = nccl, num_packs = 1\n",
      "  4/200 [..............................] - ETA: 5:06 - loss: nan - sparse_categorical_accuracy: 0.2101"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-17de9f77d053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             history = model.fit(\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "last_model = None\n",
    "\n",
    "learning_rate = 10**-6#EMBEDDING_WIDTH**-0.5 * min(epoch**-0.5, epoch * WARMUP_STEPS**-1.5)\n",
    "\n",
    "while True:\n",
    "    error_count = 0\n",
    "    training_dataset = datasets[TRAINING_TYPE].repeat()\n",
    "    validation_dataset = datasets[TEST_TYPE].repeat()\n",
    "    \n",
    "    for epoch in range(1, 10000):\n",
    "        logger.info(f\"epoch {epoch}:\")\n",
    "\n",
    "        tf.keras.backend.set_value(model.optimizer.learning_rate, learning_rate)\n",
    "        logger.debug(str(model.optimizer.get_config()))\n",
    "\n",
    "        try:\n",
    "            history = model.fit(\n",
    "                x=training_dataset,\n",
    "                validation_data=validation_dataset,\n",
    "                validation_steps=STEPS_PER_EPOCH//10,\n",
    "                epochs=epoch,\n",
    "                steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                callbacks=callback_list,\n",
    "                initial_epoch=epoch-1,\n",
    "            )\n",
    "            logger.debug(str(history))\n",
    "        except tf.errors.InvalidArgumentError as e:\n",
    "            logger.warning(f\"Training error: {e}\")\n",
    "            error_count += 1\n",
    "            if error_count > 10:\n",
    "                logger.warning(\"abort training, because of too many NaN loss results\")\n",
    "                break\n",
    "\n",
    "        eval_df, (x_eval, y_eval, y_pred) = evaluator.evaluate_model_visually(\n",
    "            model=model,\n",
    "            sample_size=20,\n",
    "            keep_separator=True,\n",
    "        )\n",
    "        display(eval_df)\n",
    "    last_model = model\n",
    "    model = create_model()\n",
    "    learning_rate *= 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-laser",
   "metadata": {},
   "source": [
    "## Evaluating the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a30b848",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluator.evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917eb62e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "eval_df, (x_eval, y_eval, y_pred) = evaluator.evaluate_model_visually(\n",
    "    model=model,\n",
    "    sample_size=20,\n",
    "    keep_separator=True,\n",
    ")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf7530",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "eval_df.predicted.map(print)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d87b01",
   "metadata": {},
   "source": [
    "broken loss function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caff47e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "np.argmax(y_pred[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65719a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[EVAL_TYPE].take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dfcd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(datasets[EVAL_TYPE].unbatch().batch(1).take(1).as_numpy_iterator())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9fb39f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.predict(datasets[EVAL_TYPE].unbatch().batch(1).take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900bef38",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515599e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052447fc",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

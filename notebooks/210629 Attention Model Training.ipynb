{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "lovely-landing",
   "metadata": {},
   "source": [
    "# Training an Attention Model on Tensorflow Datasets\n",
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worth-excuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from typing import Any, Callable, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from IPython.core.display import display\n",
    "from mmproteo.utils import log, paths, utils, visualization\n",
    "from mmproteo.utils.formats.tf_dataset import DatasetLoader\n",
    "from mmproteo.utils.ml import callbacks, evaluation\n",
    "from official.modeling import tf_utils\n",
    "from official.nlp.modeling.models.seq2seq_transformer import Seq2SeqTransformer, TransformerDecoder, TransformerEncoder\n",
    "from official.nlp.modeling.ops import beam_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "circular-latin",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c53d832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6a88dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tf.debugging.set_log_device_placement(True)\n",
    "GPUs = tf.config.list_physical_devices('GPU')\n",
    "GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "essential-playlist",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "norwegian-therapist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpi/fs00/home/mirko.krause/masterthesis/pride-downloader/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deed6b25",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if os.getcwd() == \"/tf\":\n",
    "    os.chdir(os.path.join('workspace', 'notebooks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "987d32ad",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/hpi/fs00/home/mirko.krause/masterthesis/pride-downloader/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4927b8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"PXD010000\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "6d85591d",
   "metadata": {},
   "source": [
    "DUMP_PATH = os.path.join(\"..\", \"dumps\", PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44d781aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DUMP_PATH = os.path.join(\"/scratch/mirko.krause/dumps/\", PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "genuine-dealing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dump path = /scratch/mirko.krause/dumps/PXD010000\n"
     ]
    }
   ],
   "source": [
    "print(f\"dump path = {DUMP_PATH}\")\n",
    "THREAD_COUNT = min(int(os.cpu_count()/2), 16)\n",
    "TRAINING_COLUMNS_DUMP_PATH = os.path.join(DUMP_PATH, \"training_columns\")\n",
    "FILES_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"*_mzmlid.parquet\")\n",
    "STATISTICS_FILE_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"statistics.parquet\")\n",
    "DATASET_DUMP_PATH = os.path.join(TRAINING_COLUMNS_DUMP_PATH, \"tf_datasets\")\n",
    "PROCESSING_FILE_PATH = os.path.join(DATASET_DUMP_PATH, \"processing_info.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interesting-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ = 'peptide_sequence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "certified-gibson",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 18:21:42,956 - mmproteo_attention_model: Logging to file '/scratch/mirko.krause/dumps/PXD010000/mmproteo_attention_model.log' and to stderr\n"
     ]
    }
   ],
   "source": [
    "logger = log.create_logger(\n",
    "    name='mmproteo_attention_model',\n",
    "    verbose=True,\n",
    "    log_dir=DUMP_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c29d41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'padding_characters': {'peptide_sequence': '_',\n",
       "  'mz_array': 0.0,\n",
       "  'intensity_array': 0.0},\n",
       " 'padding_lengths': {'mz_array': 2354,\n",
       "  'intensity_array': 2354,\n",
       "  'peptide_sequence': 50},\n",
       " 'idx_to_char': {'0': 'A',\n",
       "  '1': 'C',\n",
       "  '2': 'D',\n",
       "  '3': 'E',\n",
       "  '4': 'F',\n",
       "  '5': 'G',\n",
       "  '6': 'H',\n",
       "  '7': 'I',\n",
       "  '8': 'K',\n",
       "  '9': 'L',\n",
       "  '10': 'M',\n",
       "  '11': 'M(Oxidation)',\n",
       "  '12': 'N',\n",
       "  '13': 'P',\n",
       "  '14': 'Q',\n",
       "  '15': 'R',\n",
       "  '16': 'S',\n",
       "  '17': 'T',\n",
       "  '18': 'V',\n",
       "  '19': 'W',\n",
       "  '20': 'Y',\n",
       "  '21': '_'},\n",
       " 'normalization': {'intensity_array': '<function base_peak_normalize at 0x7f8e5c0cf550>'},\n",
       " 'split_value_columns': ['species', 'istrain'],\n",
       " 'training_data_columns': ['mz_array', 'intensity_array'],\n",
       " 'target_data_columns': ['peptide_sequence']}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(PROCESSING_FILE_PATH, 'r') as file:\n",
    "    PROCESSING_INFO = json.loads(file.read())\n",
    "PROCESSING_INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73a1f075",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_char = {int(idx): char for idx, char in PROCESSING_INFO[\"idx_to_char\"].items()}\n",
    "idx_to_char[-1] = \"[start]\"\n",
    "char_to_idx = {char: idx for idx, char in idx_to_char.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-proceeding",
   "metadata": {},
   "source": [
    "## Loading Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee8aadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEEP_CACHE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b34d7bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ee8ccc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_TYPE = 'Train'\n",
    "TEST_TYPE = 'Test'\n",
    "EVAL_TYPE = 'Eval'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d696d51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assigned dataset files:\n",
      "#Train = 89\n",
      "e.g.: /scratch/mirko.krause/dumps/PXD010000/training_columns/tf_datasets/Biodiversity_P_polymyxa_TBS_aerobic_1_17July16_Samwise_16-04-10_mzmlid.parquet/Paenibacillus_polymyxa_ATCC842/Train\n",
      "#Test = 27\n",
      "e.g.: /scratch/mirko.krause/dumps/PXD010000/training_columns/tf_datasets/Cj_media_MH_R3_23Feb15_Arwen_14-12-03_mzmlid.parquet/Campylobacter_jejuni/Train\n",
      "#Eval = 38\n",
      "e.g.: /scratch/mirko.krause/dumps/PXD010000/training_columns/tf_datasets/M_alcali_copp_CH4_B3_T1_11_QE_23Mar18_Oak_18-01-07_mzmlid.parquet/Methylomicrobium_alcaliphilum/Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 18:21:42,975 - mmproteo_attention_model: found file paths dump '/scratch/mirko.krause/dumps/PXD010000/training_columns/tf_datasets/dataset_file_paths.json'\n"
     ]
    }
   ],
   "source": [
    "dataset_file_paths = paths.assign_wildcard_paths_to_splits_grouped_by_path_position_value(\n",
    "    wildcard_path=os.path.join(\n",
    "        DATASET_DUMP_PATH,\n",
    "        '*',  # filename\n",
    "        '*',  # species\n",
    "        '*'  # istrain\n",
    "    ),\n",
    "    path_position=-2,\n",
    "    splits={\n",
    "        TRAINING_TYPE: 0.4,\n",
    "        TEST_TYPE: 0.5,\n",
    "        EVAL_TYPE: 0.6\n",
    "    },\n",
    "    paths_dump_file=os.path.join(\n",
    "        DATASET_DUMP_PATH,\n",
    "        \"dataset_file_paths.json\"\n",
    "    ),\n",
    "    skip_existing=KEEP_CACHE,\n",
    "    logger=logger\n",
    ")\n",
    "\n",
    "print()\n",
    "print(\"assigned dataset files:\")\n",
    "visualization.print_list_length_in_dict(dataset_file_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec611252",
   "metadata": {},
   "source": [
    "### Loading corresponding TF datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0d829d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(2354,), dtype=tf.float32, name='mz_array'),\n",
       "  TensorSpec(shape=(2354,), dtype=tf.float32, name='intensity_array')),\n",
       " (TensorSpec(shape=(50,), dtype=tf.int8, name='peptide_sequence'),))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_spec = (\n",
    "    tuple(tf.TensorSpec(shape=(PROCESSING_INFO['padding_lengths'][col],), dtype=tf.float32, name=col)\n",
    "          for col in PROCESSING_INFO['training_data_columns']),\n",
    "    tuple(tf.TensorSpec(shape=(PROCESSING_INFO['padding_lengths'][col],), dtype=tf.int8, name=col)\n",
    "          for col in PROCESSING_INFO['target_data_columns'])\n",
    ")\n",
    "element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195bfe9c",
   "metadata": {},
   "source": [
    "**In the following step, Tensorflow starts allocating a GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b996dc59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RangeDataset shapes: (), types: tf.int64>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize Tensorflow (might take several minutes (~5))\n",
    "tf.data.Dataset.range(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f66eda04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_options = tf.data.Options()\n",
    "ds_options.experimental_threading.private_threadpool_size = THREAD_COUNT\n",
    "ds_options.experimental_threading.max_intra_op_parallelism = THREAD_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbef3700",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-17 18:27:52,375 - mmproteo_attention_model: DEBUG: preparing dataset 'Train' with 89 paths\n",
      "2021-07-17 18:27:52,379 - mmproteo_attention_model: DEBUG: applied options to dataset 'Train'\n",
      "2021-07-17 18:27:52,451 - mmproteo_attention_model: DEBUG: loaded dataset 'Train' interleaved\n",
      "2021-07-17 18:27:52,452 - mmproteo_attention_model: DEBUG: shuffled dataset 'Train'\n",
      "2021-07-17 18:27:52,453 - mmproteo_attention_model: DEBUG: batched dataset 'Train'\n",
      "2021-07-17 18:27:52,453 - mmproteo_attention_model: DEBUG: skipped caching dataset 'Train'\n",
      "2021-07-17 18:27:52,453 - mmproteo_attention_model: DEBUG: configured prefetching for dataset 'Train'\n",
      "2021-07-17 18:27:52,454 - mmproteo_attention_model: DEBUG: skipped benchmarking dataset 'Train'\n",
      "2021-07-17 18:27:52,454 - mmproteo_attention_model: prepared dataset 'Train'\n",
      "2021-07-17 18:27:52,454 - mmproteo_attention_model: DEBUG: preparing dataset 'Test' with 27 paths\n",
      "2021-07-17 18:27:52,455 - mmproteo_attention_model: DEBUG: applied options to dataset 'Test'\n",
      "2021-07-17 18:27:52,462 - mmproteo_attention_model: DEBUG: loaded dataset 'Test' interleaved\n",
      "2021-07-17 18:27:52,462 - mmproteo_attention_model: DEBUG: shuffled dataset 'Test'\n",
      "2021-07-17 18:27:52,463 - mmproteo_attention_model: DEBUG: batched dataset 'Test'\n",
      "2021-07-17 18:27:52,463 - mmproteo_attention_model: DEBUG: skipped caching dataset 'Test'\n",
      "2021-07-17 18:27:52,463 - mmproteo_attention_model: DEBUG: configured prefetching for dataset 'Test'\n",
      "2021-07-17 18:27:52,464 - mmproteo_attention_model: DEBUG: skipped benchmarking dataset 'Test'\n",
      "2021-07-17 18:27:52,464 - mmproteo_attention_model: prepared dataset 'Test'\n",
      "2021-07-17 18:27:52,464 - mmproteo_attention_model: DEBUG: preparing dataset 'Eval' with 38 paths\n",
      "2021-07-17 18:27:52,465 - mmproteo_attention_model: DEBUG: applied options to dataset 'Eval'\n",
      "2021-07-17 18:27:52,473 - mmproteo_attention_model: DEBUG: loaded dataset 'Eval' interleaved\n",
      "2021-07-17 18:27:52,473 - mmproteo_attention_model: DEBUG: shuffled dataset 'Eval'\n",
      "2021-07-17 18:27:52,474 - mmproteo_attention_model: DEBUG: batched dataset 'Eval'\n",
      "2021-07-17 18:27:52,474 - mmproteo_attention_model: DEBUG: skipped caching dataset 'Eval'\n",
      "2021-07-17 18:27:52,474 - mmproteo_attention_model: DEBUG: configured prefetching for dataset 'Eval'\n",
      "2021-07-17 18:27:52,475 - mmproteo_attention_model: DEBUG: skipped benchmarking dataset 'Eval'\n",
      "2021-07-17 18:27:52,475 - mmproteo_attention_model: prepared dataset 'Eval'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Train': <PrefetchDataset shapes: (((8, 2354), (8, 2354)), ((8, 50),)), types: ((tf.float32, tf.float32), (tf.int8,))>,\n",
       " 'Test': <PrefetchDataset shapes: (((8, 2354), (8, 2354)), ((8, 50),)), types: ((tf.float32, tf.float32), (tf.int8,))>,\n",
       " 'Eval': <PrefetchDataset shapes: (((8, 2354), (8, 2354)), ((8, 50),)), types: ((tf.float32, tf.float32), (tf.int8,))>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = DatasetLoader(\n",
    "    element_spec=element_spec,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle_buffer_size=100_000,\n",
    "    thread_count=min(int(os.cpu_count()/4), 4),\n",
    "    keep_cache=KEEP_CACHE,\n",
    "    logger=logger,\n",
    "    run_benchmarks=False,\n",
    "    options=ds_options,\n",
    ").load_datasets_by_type(dataset_file_paths)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1372f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_datasets = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2eb0f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prefix_target_sequences_with_start_token(tensor: tf.Tensor, token: Any = char_to_idx[\"[start]\"]) -> tf.Tensor:\n",
    "    return tf.concat(\n",
    "        values=[\n",
    "            tf.broadcast_to(\n",
    "                input=tf.constant(token, dtype=tensor.dtype),\n",
    "                shape=(\n",
    "                    tensor.shape[0],  # batch dimension\n",
    "                    1\n",
    "                )\n",
    "            ),\n",
    "            tensor\n",
    "        ],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "def _dataset_mapper_for_transformer(trainings: Tuple[tf.Tensor], targets: Tuple[tf.Tensor]):\n",
    "    inputs = tf.stack(trainings, axis=-1)[:, :500, :]  # cut off too long spectra\n",
    "    targets = prefix_target_sequences_with_start_token(targets[0])\n",
    "    targets = tf.cast(\n",
    "        x=targets,\n",
    "        dtype=tf.int32,\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        {\n",
    "            \"inputs\": inputs,\n",
    "            \"targets\": targets[:, :-1],\n",
    "        },\n",
    "        targets[:, 1:]\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_dataset_for_transformer_training(dataset: tf.data.Dataset) -> tf.data.Dataset:\n",
    "    return dataset.map(_dataset_mapper_for_transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a08cd1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train': <MapDataset shapes: ({inputs: (8, 500, 2), targets: (8, 50)}, (8, 50)), types: ({inputs: tf.float32, targets: tf.int32}, tf.int32)>,\n",
       " 'Test': <MapDataset shapes: ({inputs: (8, 500, 2), targets: (8, 50)}, (8, 50)), types: ({inputs: tf.float32, targets: tf.int32}, tf.int32)>,\n",
       " 'Eval': <MapDataset shapes: ({inputs: (8, 500, 2), targets: (8, 50)}, (8, 50)), types: ({inputs: tf.float32, targets: tf.int32}, tf.int32)>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = {\n",
    "    t: prepare_dataset_for_transformer_training(dataset) for t, dataset in original_datasets.items()\n",
    "}\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "767ec869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original datasets:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84fd79d9052e46ca86eb6a5632e2df23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Summary ************\n",
      "\n",
      "Examples/sec (First included) 4998.72 ex/sec (total: 74217 ex, 14.85 sec)\n",
      "Examples/sec (First only) 0.45 ex/sec (total: 1 ex, 2.23 sec)\n",
      "Examples/sec (First excluded) 5883.33 ex/sec (total: 74216 ex, 12.61 sec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>BenchmarkResult:</strong><br/><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first+lasts</th>\n",
       "      <td>14.847190</td>\n",
       "      <td>74217</td>\n",
       "      <td>4998.723667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2.232567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.447915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasts</th>\n",
       "      <td>12.614623</td>\n",
       "      <td>74216</td>\n",
       "      <td>5883.330594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BenchmarkResult(stats=              duration  num_examples          avg\n",
       "first+lasts  14.847190         74217  4998.723667\n",
       "first         2.232567             1     0.447915\n",
       "lasts        12.614623         74216  5883.330594, raw_stats=                      duration\n",
       "start_time        2.101980e+06\n",
       "first_batch_time  2.101982e+06\n",
       "end_time          2.101995e+06\n",
       "num_iter          7.421700e+04)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mapped datasets:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8e9b43834d42c3b59f8d36fc41e856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************ Summary ************\n",
      "\n",
      "Examples/sec (First included) 3778.46 ex/sec (total: 74217 ex, 19.64 sec)\n",
      "Examples/sec (First only) 0.47 ex/sec (total: 1 ex, 2.14 sec)\n",
      "Examples/sec (First excluded) 4240.32 ex/sec (total: 74216 ex, 17.50 sec)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<strong>BenchmarkResult:</strong><br/><div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>first+lasts</th>\n",
       "      <td>19.642144</td>\n",
       "      <td>74217</td>\n",
       "      <td>3778.457089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>2.139696</td>\n",
       "      <td>1</td>\n",
       "      <td>0.467356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasts</th>\n",
       "      <td>17.502448</td>\n",
       "      <td>74216</td>\n",
       "      <td>4240.321129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "BenchmarkResult(stats=              duration  num_examples          avg\n",
       "first+lasts  19.642144         74217  3778.457089\n",
       "first         2.139696             1     0.467356\n",
       "lasts        17.502448         74216  4240.321129, raw_stats=                      duration\n",
       "start_time        2.101995e+06\n",
       "first_batch_time  2.101997e+06\n",
       "end_time          2.102014e+06\n",
       "num_iter          7.421700e+04)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"original datasets:\")\n",
    "display(tfds.benchmark(original_datasets[TEST_TYPE]))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"mapped datasets:\")\n",
    "display(tfds.benchmark(datasets[TEST_TYPE]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-company",
   "metadata": {},
   "source": [
    "## Building the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce6bb7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heavily based on:\n",
    "# https://github.com/tensorflow/models/blob/061c58a3937953c79819fd4e8826af1570cb6024/official/nlp/transformer/transformer.py\n",
    "# (29.06.2021)\n",
    "class MyTransformer(Seq2SeqTransformer):\n",
    "    def call(self, inputs):\n",
    "        \"\"\"Calculate target logits or inferred target sequences.\n",
    "        Args:\n",
    "          inputs: a dictionary of tensors.\n",
    "            Feature `inputs`: int tensor with shape `[batch_size, input_length]`.\n",
    "            Feature `targets` (optional): None or int tensor with shape\n",
    "              `[batch_size, target_length]`.\n",
    "        Returns:\n",
    "          If targets is defined, then return logits for each word in the target\n",
    "          sequence, which is a float tensor with shape\n",
    "          `(batch_size, target_length, vocab_size)`. If target is `None`, then\n",
    "          generate output sequence one token at a time and\n",
    "          returns a dictionary {\n",
    "              outputs: `(batch_size, decoded_length)`\n",
    "              scores: `(batch_size, 1)`}\n",
    "          Even when `float16` is used, the output tensor(s) are always `float32`.\n",
    "        Raises:\n",
    "          NotImplementedError: If try to use padded decode method on CPU/GPUs.\n",
    "        \"\"\"\n",
    "        sources = inputs[\"inputs\"]\n",
    "        targets = inputs.get(\"targets\", None)\n",
    "        # Prepare inputs to the layer stack by adding positional encodings and\n",
    "        # applying dropout.\n",
    "\n",
    "        sources = self.source_embedding(sources)\n",
    "        # Attention_mask generation.\n",
    "        input_shape = tf_utils.get_shape_list(sources, expected_rank=3)\n",
    "        batch_size = input_shape[0]\n",
    "        input_length = input_shape[1]\n",
    "        channel_count = input_shape[2]\n",
    "        non_padding_sources = tf.not_equal(sources[:, :, 0], 0.0)\n",
    "        non_padding_sources = tf.reshape(\n",
    "            tensor=non_padding_sources,\n",
    "            shape=[batch_size, 1, input_length]\n",
    "        )\n",
    "        attention_mask = tf.cast(\n",
    "            x=non_padding_sources,\n",
    "            dtype=sources.dtype\n",
    "        )\n",
    "        broadcast_ones = tf.ones(\n",
    "            shape=[batch_size, input_length, 1],\n",
    "            dtype=sources.dtype\n",
    "        )\n",
    "        attention_mask = broadcast_ones * attention_mask\n",
    "\n",
    "        pos_encoding = self.position_embedding(sources)\n",
    "        pos_encoding = tf.cast(pos_encoding, sources.dtype)\n",
    "        encoder_inputs = sources + pos_encoding\n",
    "\n",
    "        encoder_inputs = self.encoder_dropout(encoder_inputs)\n",
    "\n",
    "        encoder_outputs = self.encoder_layer(\n",
    "            encoder_inputs, attention_mask=attention_mask)\n",
    "\n",
    "        if targets is None:\n",
    "            if self._padded_decode:\n",
    "                max_decode_length = self._decode_max_length\n",
    "            else:\n",
    "                max_decode_length = self._decode_max_length or (\n",
    "                        tf.shape(encoder_outputs)[1] + self._extra_decode_length)\n",
    "            symbols_to_logits_fn = self._get_symbols_to_logits_fn(max_decode_length)\n",
    "\n",
    "            batch_size = tf.shape(encoder_outputs)[0]\n",
    "            # Create initial set of IDs that will be passed to symbols_to_logits_fn.\n",
    "            initial_ids = tf.zeros([batch_size], dtype=tf.int32)\n",
    "\n",
    "            # Create cache storing decoder attention values for each layer.\n",
    "            init_decode_length = (max_decode_length if self._padded_decode else 0)\n",
    "            num_heads = self.decoder_layer.num_attention_heads\n",
    "            dim_per_head = self._embedding_width // num_heads\n",
    "\n",
    "            # Cache dtype needs to match beam_search dtype.\n",
    "            # pylint: disable=g-complex-comprehension\n",
    "            cache = {\n",
    "                str(layer): {\n",
    "                    \"key\":\n",
    "                        tf.zeros(\n",
    "                            [batch_size, init_decode_length, num_heads, dim_per_head],\n",
    "                            dtype=self.compute_dtype),\n",
    "                    \"value\":\n",
    "                        tf.zeros(\n",
    "                            [batch_size, init_decode_length, num_heads, dim_per_head],\n",
    "                            dtype=self.compute_dtype)\n",
    "                } for layer in range(self.decoder_layer.num_layers)\n",
    "            }\n",
    "            # pylint: enable=g-complex-comprehension\n",
    "\n",
    "            # Add encoder output and attention bias to the cache.\n",
    "            encoder_outputs = tf.cast(encoder_outputs, dtype=self.compute_dtype)\n",
    "            attention_mask = tf.cast(\n",
    "                tf.reshape(\n",
    "                    tf.not_equal(sources, 0), [input_shape[0], 1, input_shape[1]]),\n",
    "                dtype=self.compute_dtype)\n",
    "            cache[\"encoder_outputs\"] = encoder_outputs\n",
    "            cache[\"encoder_decoder_attention_mask\"] = attention_mask\n",
    "\n",
    "            # Use beam search to find the top beam_size sequences and scores.\n",
    "            decoded_ids, scores = beam_search.sequence_beam_search(\n",
    "                symbols_to_logits_fn=symbols_to_logits_fn,\n",
    "                initial_ids=initial_ids,\n",
    "                initial_cache=cache,\n",
    "                vocab_size=self._vocab_size,\n",
    "                beam_size=self._beam_size,\n",
    "                alpha=self._alpha,\n",
    "                max_decode_length=max_decode_length,\n",
    "                eos_id=self._eos_id,\n",
    "                padded_decode=self._padded_decode,\n",
    "                dtype=self.compute_dtype)\n",
    "\n",
    "            # Get the top sequence for each batch element\n",
    "            top_decoded_ids = decoded_ids[:, 0, 1:]\n",
    "            top_scores = scores[:, 0]\n",
    "\n",
    "            return {\"outputs\": top_decoded_ids, \"scores\": top_scores}\n",
    "\n",
    "        decoder_inputs = self.embedding_lookup(targets)\n",
    "        embedding_mask = tf.cast(tf.not_equal(targets, 0), decoder_inputs.dtype)\n",
    "        decoder_inputs *= tf.expand_dims(embedding_mask, -1)\n",
    "        # Shift targets to the right, and remove the last element\n",
    "        decoder_inputs = tf.pad(decoder_inputs, [[0, 0], [1, 0], [0, 0]])[:, :-1, :]\n",
    "        \n",
    "        length = tf.shape(decoder_inputs)[1]\n",
    "        pos_encoding = self.position_embedding(decoder_inputs)\n",
    "        pos_encoding = tf.cast(pos_encoding, decoder_inputs.dtype)\n",
    "        decoder_inputs += pos_encoding\n",
    "\n",
    "        decoder_inputs = self.decoder_dropout(decoder_inputs)\n",
    "\n",
    "        decoder_shape = tf_utils.get_shape_list(decoder_inputs, expected_rank=3)\n",
    "        batch_size = decoder_shape[0]\n",
    "        decoder_length = decoder_shape[1]\n",
    "\n",
    "        self_attention_mask = tf.linalg.band_part(tf.ones([length, length]), -1, 0)\n",
    "        self_attention_mask = tf.reshape(self_attention_mask, [1, length, length])\n",
    "        self_attention_mask = tf.tile(self_attention_mask, [batch_size, 1, 1])\n",
    "\n",
    "        attention_mask = tf.cast(\n",
    "            tf.expand_dims(tf.not_equal(sources[:, :, 0], 0), axis=1), dtype=sources.dtype)\n",
    "        attention_mask = tf.tile(attention_mask, [1, decoder_length, 1])\n",
    "\n",
    "        outputs = self.decoder_layer(\n",
    "            decoder_inputs,\n",
    "            encoder_outputs,\n",
    "            memory_mask=self_attention_mask,\n",
    "            target_mask=attention_mask)\n",
    "        \n",
    "        logits = self._embedding_linear(self.embedding_lookup.embeddings, outputs)\n",
    "        # Model outputs should be float32 to avoid numeric issues.\n",
    "        # https://www.tensorflow.org/guide/mixed_precision#building_the_model\n",
    "        logits = tf.cast(logits, tf.float32)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ca01dcb",
   "metadata": {},
   "source": [
    "TRANSFORMER_LAYERS = 8\n",
    "ATTENTION_HEADS = 2\n",
    "EMBEDDING_WIDTH = 32\n",
    "LEARNING_RATE=10**-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76512ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORMER_LAYERS = 8\n",
    "ATTENTION_HEADS = 16\n",
    "EMBEDDING_WIDTH = 512\n",
    "LEARNING_RATE=10**-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "96a40234",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "encoder_layer = TransformerEncoder(\n",
    "    num_attention_heads=ATTENTION_HEADS,\n",
    "    num_layers=TRANSFORMER_LAYERS,\n",
    ")\n",
    "decoder_layer = TransformerDecoder(\n",
    "    num_attention_heads=ATTENTION_HEADS,\n",
    "    num_layers=TRANSFORMER_LAYERS,\n",
    ")\n",
    "\n",
    "model = MyTransformer(\n",
    "    vocab_size=len(idx_to_char),\n",
    "    embedding_width=EMBEDDING_WIDTH,\n",
    "    encoder_layer=encoder_layer,\n",
    "    decoder_layer=decoder_layer,\n",
    "    name=f\"mmproteo_transformer_{utils.get_current_time_str()}\",\n",
    "    decode_max_length=PROCESSING_INFO['padding_lengths'][SEQ],\n",
    ")\n",
    "# create a new embedding layer that will be used in the overridden call method\n",
    "model.source_embedding = tf.keras.layers.Conv1D(\n",
    "    filters=EMBEDDING_WIDTH,\n",
    "    kernel_size=1,\n",
    "    activation=None,\n",
    "    padding='same',\n",
    "    name=\"source_embedding\",\n",
    "    use_bias=False,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "        clipvalue=1.0,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "    ),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),  #masked_loss,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.SparseCategoricalAccuracy(),\n",
    "        tf.keras.metrics.SparseCategoricalCrossentropy()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d4032e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.9293694 ,  0.19426323,  0.787314  , ..., -0.5484189 ,\n",
       "          0.89359534, -1.4485174 ],\n",
       "        [-1.9883614 ,  0.13863903,  0.6828624 , ..., -0.5114371 ,\n",
       "          0.91365963, -1.4382948 ],\n",
       "        [-1.8059468 , -0.36835906,  0.61709356, ..., -0.8088014 ,\n",
       "          1.2649332 , -1.6012948 ],\n",
       "        ...,\n",
       "        [-1.6588717 , -0.2622395 ,  0.5649077 , ..., -1.213761  ,\n",
       "          6.151469  , -2.3794758 ],\n",
       "        [-1.6085639 , -0.24182785,  0.5679928 , ..., -1.2426987 ,\n",
       "          6.0788584 , -2.3005118 ],\n",
       "        [-1.562601  , -0.25035125,  0.55838585, ..., -1.2691    ,\n",
       "          6.0054083 , -2.1804748 ]]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(datasets[EVAL_TYPE].unbatch().batch(1).take(1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "59911047",
   "metadata": {},
   "source": [
    "# to define an input for the model because of a missing input layer\n",
    "model.fit(\n",
    "    x=datasets[TRAINING_TYPE].repeat(),\n",
    "    epochs=1,\n",
    "    steps_per_epoch=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "456b69eb",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/mirko.krause/dumps/PXD010000/models/mmproteo_transformer_20210717-182827'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODELS_PATH = os.path.join(DUMP_PATH, \"models\")\n",
    "MODEL_PATH = os.path.join(MODELS_PATH, model.name)\n",
    "MODEL_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5481a85",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "utils.ensure_dir_exists(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04bbca25",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(\n",
    "    model=model,\n",
    "    to_file=os.path.join(MODEL_PATH, \"model.png\"),\n",
    "    show_shapes=True,\n",
    "    expand_nested=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fd410eda",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mmproteo_transformer_20210717-182827\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "on_device_embedding (OnDevic multiple                  11776     \n",
      "_________________________________________________________________\n",
      "transformer_encoder (Transfo multiple                  25203712  \n",
      "_________________________________________________________________\n",
      "transformer_decoder (Transfo multiple                  33600512  \n",
      "_________________________________________________________________\n",
      "relative_position_embedding  multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          multiple                  0         \n",
      "_________________________________________________________________\n",
      "source_embedding (Conv1D)    multiple                  1024      \n",
      "=================================================================\n",
      "Total params: 58,817,024\n",
      "Trainable params: 58,817,024\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(MODEL_PATH, \"summary.txt\"), 'w') as file:\n",
    "    def write_lines(line: str) -> None:\n",
    "        file.write(line)\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "\n",
    "    model.summary(print_fn=write_lines)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2842ef24",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not implemented\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with open(os.path.join(MODEL_PATH, \"model.json\"), 'w') as file:\n",
    "        file.write(model.to_json())\n",
    "\n",
    "    with open(os.path.join(MODEL_PATH, \"model.yaml\"), 'w') as file:\n",
    "        file.write(model.to_yaml())\n",
    "except NotImplementedError as e:\n",
    "    print(\"not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-queue",
   "metadata": {},
   "source": [
    "## Training the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "630d443e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05152e65",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/mirko.krause/dumps/PXD010000/models/mmproteo_transformer_20210717-182827/tensorboard'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSORBOARD_LOG_DIR = os.path.join(MODEL_PATH, \"tensorboard\")\n",
    "os.path.realpath(TENSORBOARD_LOG_DIR)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "119f380b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": true
   },
   "source": [
    "%tensorboard --logdir $MODELS_PATH --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "175be54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = datasets[TRAINING_TYPE].repeat()\n",
    "validation_dataset = datasets[TEST_TYPE].repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2b0ce97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.clipvalue = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aafc1c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': 0.01,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c7c76c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimizer.amsgrad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6af42793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Adam',\n",
       " 'learning_rate': 0.001,\n",
       " 'decay': 0.0,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'epsilon': 1e-07,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to reset the learning_rate after it has been decreased by the reduce_lr callback\n",
    "tf.keras.backend.set_value(model.optimizer.learning_rate, 10**-3)\n",
    "model.optimizer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "funded-commons",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 207/1000\n",
      "1000/1000 [==============================] - 262s 260ms/step - loss: 6.0314 - sparse_categorical_accuracy: 0.6516 - sparse_categorical_crossentropy: 6.0314 - val_loss: 6.0175 - val_sparse_categorical_accuracy: 0.6586 - val_sparse_categorical_crossentropy: 6.0175\n",
      "Epoch 208/1000\n",
      "1000/1000 [==============================] - 259s 259ms/step - loss: 6.1908 - sparse_categorical_accuracy: 0.6413 - sparse_categorical_crossentropy: 6.1908 - val_loss: 5.9422 - val_sparse_categorical_accuracy: 0.6634 - val_sparse_categorical_crossentropy: 5.9422\n",
      "Epoch 209/1000\n",
      "1000/1000 [==============================] - 259s 259ms/step - loss: 6.3155 - sparse_categorical_accuracy: 0.6321 - sparse_categorical_crossentropy: 6.3155 - val_loss: 5.8189 - val_sparse_categorical_accuracy: 0.6731 - val_sparse_categorical_crossentropy: 5.8189\n",
      "Epoch 210/1000\n",
      " 500/1000 [==============>...............] - ETA: 2:04 - loss: 6.3362 - sparse_categorical_accuracy: 0.6313 - sparse_categorical_crossentropy: 6.3362"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.3917 - sparse_categorical_accuracy: 0.6217 - sparse_categorical_crossentropy: 6.3917 - val_loss: 5.8096 - val_sparse_categorical_accuracy: 0.6738 - val_sparse_categorical_crossentropy: 5.8096\n",
      "Epoch 222/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.4182 - sparse_categorical_accuracy: 0.6193 - sparse_categorical_crossentropy: 6.4182 - val_loss: 5.9526 - val_sparse_categorical_accuracy: 0.6614 - val_sparse_categorical_crossentropy: 5.9526\n",
      "Epoch 223/1000\n",
      "1000/1000 [==============================] - 259s 259ms/step - loss: 6.4189 - sparse_categorical_accuracy: 0.6194 - sparse_categorical_crossentropy: 6.4189 - val_loss: 5.8048 - val_sparse_categorical_accuracy: 0.6723 - val_sparse_categorical_crossentropy: 5.8048\n",
      "Epoch 224/1000\n",
      " 242/1000 [======>.......................] - ETA: 3:09 - loss: 6.3363 - sparse_categorical_accuracy: 0.6274 - sparse_categorical_crossentropy: 6.3363"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.1509 - sparse_categorical_accuracy: 0.6432 - sparse_categorical_crossentropy: 6.1509 - val_loss: 5.8833 - val_sparse_categorical_accuracy: 0.6659 - val_sparse_categorical_crossentropy: 5.8833\n",
      "Epoch 236/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.0217 - sparse_categorical_accuracy: 0.6534 - sparse_categorical_crossentropy: 6.0217 - val_loss: 5.7935 - val_sparse_categorical_accuracy: 0.6726 - val_sparse_categorical_crossentropy: 5.7935\n",
      "Epoch 237/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.0404 - sparse_categorical_accuracy: 0.6512 - sparse_categorical_crossentropy: 6.0404 - val_loss: 5.8837 - val_sparse_categorical_accuracy: 0.6681 - val_sparse_categorical_crossentropy: 5.8837\n",
      "Epoch 238/1000\n",
      " 701/1000 [====================>.........] - ETA: 1:14 - loss: 6.0242 - sparse_categorical_accuracy: 0.6528 - sparse_categorical_crossentropy: 6.0242"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.0906 - sparse_categorical_accuracy: 0.6499 - sparse_categorical_crossentropy: 6.0906 - val_loss: 5.9236 - val_sparse_categorical_accuracy: 0.6618 - val_sparse_categorical_crossentropy: 5.9236\n",
      "Epoch 251/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.0079 - sparse_categorical_accuracy: 0.6566 - sparse_categorical_crossentropy: 6.0078 - val_loss: 5.7975 - val_sparse_categorical_accuracy: 0.6744 - val_sparse_categorical_crossentropy: 5.7975\n",
      "Epoch 252/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 5.9002 - sparse_categorical_accuracy: 0.6637 - sparse_categorical_crossentropy: 5.9002 - val_loss: 5.7890 - val_sparse_categorical_accuracy: 0.6739 - val_sparse_categorical_crossentropy: 5.7890\n",
      "Epoch 253/1000\n",
      " 147/1000 [===>..........................] - ETA: 3:33 - loss: 5.9764 - sparse_categorical_accuracy: 0.6591 - sparse_categorical_crossentropy: 5.9764"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.0791 - sparse_categorical_accuracy: 0.6535 - sparse_categorical_crossentropy: 6.0791 - val_loss: 5.8600 - val_sparse_categorical_accuracy: 0.6694 - val_sparse_categorical_crossentropy: 5.8600\n",
      "Epoch 264/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 5.9411 - sparse_categorical_accuracy: 0.6627 - sparse_categorical_crossentropy: 5.9411 - val_loss: 5.8999 - val_sparse_categorical_accuracy: 0.6653 - val_sparse_categorical_crossentropy: 5.8999\n",
      "Epoch 265/1000\n",
      " 817/1000 [=======================>......] - ETA: 45s - loss: 5.9156 - sparse_categorical_accuracy: 0.6640 - sparse_categorical_crossentropy: 5.9156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 260s 260ms/step - loss: 5.8526 - sparse_categorical_accuracy: 0.6683 - sparse_categorical_crossentropy: 5.8526 - val_loss: 5.8696 - val_sparse_categorical_accuracy: 0.6697 - val_sparse_categorical_crossentropy: 5.8696\n",
      "Epoch 267/1000\n",
      " 750/1000 [=====================>........] - ETA: 1:02 - loss: 5.8929 - sparse_categorical_accuracy: 0.6652 - sparse_categorical_crossentropy: 5.8929"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.0373 - sparse_categorical_accuracy: 0.6518 - sparse_categorical_crossentropy: 6.0373 - val_loss: 5.9393 - val_sparse_categorical_accuracy: 0.6618 - val_sparse_categorical_crossentropy: 5.9393\n",
      "Epoch 279/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 5.9932 - sparse_categorical_accuracy: 0.6547 - sparse_categorical_crossentropy: 5.9932 - val_loss: 5.8954 - val_sparse_categorical_accuracy: 0.6682 - val_sparse_categorical_crossentropy: 5.8954\n",
      "Epoch 280/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 5.9668 - sparse_categorical_accuracy: 0.6566 - sparse_categorical_crossentropy: 5.9668 - val_loss: 5.8547 - val_sparse_categorical_accuracy: 0.6690 - val_sparse_categorical_crossentropy: 5.8547\n",
      "Epoch 281/1000\n",
      " 370/1000 [==========>...................] - ETA: 2:37 - loss: 5.9831 - sparse_categorical_accuracy: 0.6538 - sparse_categorical_crossentropy: 5.9831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 263s 263ms/step - loss: 6.0809 - sparse_categorical_accuracy: 0.6436 - sparse_categorical_crossentropy: 6.0809 - val_loss: 5.9067 - val_sparse_categorical_accuracy: 0.6647 - val_sparse_categorical_crossentropy: 5.9067\n",
      "Epoch 293/1000\n",
      "1000/1000 [==============================] - 263s 263ms/step - loss: 6.0413 - sparse_categorical_accuracy: 0.6467 - sparse_categorical_crossentropy: 6.0413 - val_loss: 5.7798 - val_sparse_categorical_accuracy: 0.6742 - val_sparse_categorical_crossentropy: 5.7798\n",
      "Epoch 294/1000\n",
      "1000/1000 [==============================] - 263s 263ms/step - loss: 6.0167 - sparse_categorical_accuracy: 0.6483 - sparse_categorical_crossentropy: 6.0167 - val_loss: 5.9857 - val_sparse_categorical_accuracy: 0.6581 - val_sparse_categorical_crossentropy: 5.9857\n",
      "Epoch 295/1000\n",
      "  69/1000 [=>............................] - ETA: 3:56 - loss: 6.0064 - sparse_categorical_accuracy: 0.6506 - sparse_categorical_crossentropy: 6.0064"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.1735 - sparse_categorical_accuracy: 0.6410 - sparse_categorical_crossentropy: 6.1735 - val_loss: 5.8946 - val_sparse_categorical_accuracy: 0.6643 - val_sparse_categorical_crossentropy: 5.8946\n",
      "Epoch 307/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.0944 - sparse_categorical_accuracy: 0.6482 - sparse_categorical_crossentropy: 6.0944 - val_loss: 5.8970 - val_sparse_categorical_accuracy: 0.6665 - val_sparse_categorical_crossentropy: 5.8970\n",
      "Epoch 308/1000\n",
      "1000/1000 [==============================] - 261s 261ms/step - loss: 6.0515 - sparse_categorical_accuracy: 0.6510 - sparse_categorical_crossentropy: 6.0515 - val_loss: 5.8789 - val_sparse_categorical_accuracy: 0.6687 - val_sparse_categorical_crossentropy: 5.8789\n",
      "Epoch 309/1000\n",
      " 193/1000 [====>.........................] - ETA: 3:22 - loss: 6.1069 - sparse_categorical_accuracy: 0.6459 - sparse_categorical_crossentropy: 6.1069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 889/1000 [=========================>....] - ETA: 28s - loss: 6.2417 - sparse_categorical_accuracy: 0.6415 - sparse_categorical_crossentropy: 6.2417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 262s 262ms/step - loss: 6.1596 - sparse_categorical_accuracy: 0.6478 - sparse_categorical_crossentropy: 6.1596 - val_loss: 5.8330 - val_sparse_categorical_accuracy: 0.6705 - val_sparse_categorical_crossentropy: 5.8330\n",
      "Epoch 322/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.0348 - sparse_categorical_accuracy: 0.6558 - sparse_categorical_crossentropy: 6.0348 - val_loss: 5.8640 - val_sparse_categorical_accuracy: 0.6695 - val_sparse_categorical_crossentropy: 5.8640\n",
      "Epoch 323/1000\n",
      " 227/1000 [=====>........................] - ETA: 3:13 - loss: 5.9881 - sparse_categorical_accuracy: 0.6602 - sparse_categorical_crossentropy: 5.9881"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 944/1000 [===========================>..] - ETA: 13s - loss: 6.1392 - sparse_categorical_accuracy: 0.6489 - sparse_categorical_crossentropy: 6.1393"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.0491 - sparse_categorical_accuracy: 0.6552 - sparse_categorical_crossentropy: 6.0492 - val_loss: 5.9434 - val_sparse_categorical_accuracy: 0.6633 - val_sparse_categorical_crossentropy: 5.9434\n",
      "Epoch 336/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 5.9370 - sparse_categorical_accuracy: 0.6641 - sparse_categorical_crossentropy: 5.9370 - val_loss: 5.9478 - val_sparse_categorical_accuracy: 0.6627 - val_sparse_categorical_crossentropy: 5.9478\n",
      "Epoch 337/1000\n",
      " 348/1000 [=========>....................] - ETA: 2:42 - loss: 5.9704 - sparse_categorical_accuracy: 0.6627 - sparse_categorical_crossentropy: 5.9704"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.0405 - sparse_categorical_accuracy: 0.6561 - sparse_categorical_crossentropy: 6.0405 - val_loss: 5.7516 - val_sparse_categorical_accuracy: 0.6771 - val_sparse_categorical_crossentropy: 5.7516\n",
      "Epoch 348/1000\n",
      "   4/1000 [..............................] - ETA: 4:07 - loss: 5.5090 - sparse_categorical_accuracy: 0.6975 - sparse_categorical_crossentropy: 5.5090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.0348 - sparse_categorical_accuracy: 0.6557 - sparse_categorical_crossentropy: 6.0348 - val_loss: 6.0224 - val_sparse_categorical_accuracy: 0.6578 - val_sparse_categorical_crossentropy: 6.0224\n",
      "Epoch 350/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 5.9662 - sparse_categorical_accuracy: 0.6596 - sparse_categorical_crossentropy: 5.9662 - val_loss: 5.8003 - val_sparse_categorical_accuracy: 0.6725 - val_sparse_categorical_crossentropy: 5.8003\n",
      "Epoch 351/1000\n",
      " 305/1000 [========>.....................] - ETA: 2:54 - loss: 5.9334 - sparse_categorical_accuracy: 0.6609 - sparse_categorical_crossentropy: 5.9334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 855/1000 [========================>.....] - ETA: 36s - loss: 6.2178 - sparse_categorical_accuracy: 0.6353 - sparse_categorical_crossentropy: 6.2178"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 259s 259ms/step - loss: 6.2626 - sparse_categorical_accuracy: 0.6322 - sparse_categorical_crossentropy: 6.2626 - val_loss: 5.8459 - val_sparse_categorical_accuracy: 0.6690 - val_sparse_categorical_crossentropy: 5.8459\n",
      "Epoch 363/1000\n",
      "1000/1000 [==============================] - 259s 259ms/step - loss: 6.3165 - sparse_categorical_accuracy: 0.6275 - sparse_categorical_crossentropy: 6.3165 - val_loss: 5.9825 - val_sparse_categorical_accuracy: 0.6624 - val_sparse_categorical_crossentropy: 5.9825\n",
      "Epoch 364/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.1295 - sparse_categorical_accuracy: 0.6416 - sparse_categorical_crossentropy: 6.1295 - val_loss: 5.8499 - val_sparse_categorical_accuracy: 0.6714 - val_sparse_categorical_crossentropy: 5.8499\n",
      "Epoch 365/1000\n",
      " 154/1000 [===>..........................] - ETA: 3:31 - loss: 6.1078 - sparse_categorical_accuracy: 0.6432 - sparse_categorical_crossentropy: 6.1078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.2254 - sparse_categorical_accuracy: 0.6342 - sparse_categorical_crossentropy: 6.2254 - val_loss: 5.8588 - val_sparse_categorical_accuracy: 0.6695 - val_sparse_categorical_crossentropy: 5.8588\n",
      "Epoch 375/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.2205 - sparse_categorical_accuracy: 0.6346 - sparse_categorical_crossentropy: 6.2205 - val_loss: 5.9950 - val_sparse_categorical_accuracy: 0.6580 - val_sparse_categorical_crossentropy: 5.9950\n",
      "Epoch 376/1000\n",
      "1000/1000 [==============================] - 260s 260ms/step - loss: 6.1477 - sparse_categorical_accuracy: 0.6404 - sparse_categorical_crossentropy: 6.1477 - val_loss: 5.9402 - val_sparse_categorical_accuracy: 0.6642 - val_sparse_categorical_crossentropy: 5.9402\n",
      "Epoch 377/1000\n",
      " 123/1000 [==>...........................] - ETA: 3:39 - loss: 6.0686 - sparse_categorical_accuracy: 0.6444 - sparse_categorical_crossentropy: 6.0686"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-6f47b181dff0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mirko.krause/anaconda3/envs/mmproteo/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=training_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    validation_steps=100,\n",
    "    epochs=1000,\n",
    "    steps_per_epoch=1000,\n",
    "    callbacks=callbacks.create_callbacks(\n",
    "        tensorboard=True,\n",
    "        progressbar=False,\n",
    "        reduce_lr=False,\n",
    "        early_stopping=False,\n",
    "        checkpoints=True,\n",
    "        csv=False,\n",
    "        base_path=MODEL_PATH,\n",
    "    ),\n",
    "    initial_epoch=206,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-laser",
   "metadata": {},
   "source": [
    "## Evaluating the Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aab9299",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "decode_idx: Callable[[np.ndarray], np.ndarray] = np.vectorize(idx_to_char.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013c477",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluator = evaluation.SequenceEvaluator(\n",
    "    dataset=datasets[EVAL_TYPE],\n",
    "    decode_func=decode_idx,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    separator=\" \",\n",
    "    padding_character=PROCESSING_INFO['padding_characters'][SEQ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a30b848",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "evaluator.evaluate_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917eb62e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "eval_df, (x_eval, y_eval, y_pred) = evaluator.evaluate_model_visually(\n",
    "    model=model,\n",
    "    sample_size=20,\n",
    "    keep_separator=True,\n",
    ")\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf7530",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "eval_df.predicted.map(print)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d87b01",
   "metadata": {},
   "source": [
    "broken loss function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caff47e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "np.argmax(y_pred[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65719a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[EVAL_TYPE].take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9fb39f",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.predict(datasets[EVAL_TYPE].unbatch().batch(1).take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900bef38",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9515599e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052447fc",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
